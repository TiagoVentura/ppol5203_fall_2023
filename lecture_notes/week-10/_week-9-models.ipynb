{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e380a95",
   "metadata": {},
   "source": [
    "<h1><center> PPOL 5203 Data Science I: Foundations <br><br> \n",
    "<font color='grey'> Inferential Models and Machine Learning<br><br>\n",
    "Tiago Ventura </center> <h1> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4eed89",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "In the class today, we will learn about model in Python. We will cover:\n",
    "\n",
    "- Inferential models using `statsmodels`\n",
    "    - Ordinary Least Squares\n",
    "    - Logistic Regression\n",
    "    - retrieving parameters of interest\n",
    "   \n",
    "- Statistical learning with `sklearn`\n",
    "    - an workflow to rule them all\n",
    "    - iterating through many models\n",
    "    - model selection\n",
    "    - cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ae231",
   "metadata": {},
   "source": [
    "## Introdutory notes\n",
    "\n",
    "In Data Science II, you will learn all there is to be learned about predictive modeling and machine learning. You will spend every week going through a different type of model and understanding the mathematics behind it. \n",
    "\n",
    "The purpose of this class is to provide you with a agnostic overview of inferential and predictive workflow of building models in Python. These are my broader goals on having this class in DS I: \n",
    "\n",
    "- For inferential models, my goal is to show you how to use Python to estimate the models you are learning at Statistics I. \n",
    "\n",
    "- For the predictive modeling, I want to go give you a foundational introduction to Machine Learning. In case you get an interview for an internship before you start Data Science II, this class should make you feel confortable describing the components of a machine learning pipeline, even though you have not been properly introduced properly to each different model. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f5277",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We will work with a Diabetes dataset provided by the `sklearn` library. [Here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) you can find a full description of the dataset. \n",
    "\n",
    "Some basic information: \n",
    "\n",
    "- Number of cases: 442\n",
    "\n",
    "- Number of variables: First 10 columns are numeric predictive values\n",
    "\n",
    "- Outcome (Target in ML): Column 11 is a quantitative measure of disease progression one year after baseline\n",
    "\n",
    "- Attribute Information:\n",
    "\n",
    "    - `age:` age in years\n",
    "\n",
    "    - `sex:`\n",
    "\n",
    "    - `bmi:` body mass index\n",
    "\n",
    "    - `bp:` average blood pressure\n",
    "\n",
    "    - `s1 tc:`, total serum cholesterol\n",
    "\n",
    "    - `s2 ldl:`, low-density lipoproteins\n",
    "\n",
    "    - `s3 hdl:`, high-density lipoproteins\n",
    "\n",
    "    - `s4 tch:`, total cholesterol / HDL\n",
    "\n",
    "    - `s5 ltg:`, possibly log of serum triglycerides level\n",
    "\n",
    "    - `s6 glu:`, blood sugar level\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9fb9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# load the dataset as a pandas dataframe\n",
    "diabetes = datasets.load_diabetes(as_frame=True)[\"frame\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88cc0c",
   "metadata": {},
   "source": [
    "#### Notice: \n",
    "\n",
    "- ten features (independent variables)\n",
    "- one outcome (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c7edb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032984c",
   "metadata": {},
   "source": [
    "## Inferential Models\n",
    "\n",
    "As we discussed in class, the goal of inferential models is **_interpretation_**. These are the models we often build on social science problems. We often ask: \n",
    "  \n",
    "- _Which predictors are associated with the response?_\n",
    "- _What is the relationship (parameters) between the response and the predictors?_\n",
    "- _Is the relationship causal?_\n",
    "\n",
    "To work with inference, we will use the library `statsmodels` which will allow us to estimate and easily retrive parameters for a wide set of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd933c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# library for plotting\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175f97a",
   "metadata": {},
   "source": [
    "#### Fitting a OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b9fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the model using R style formula\n",
    "model_ols_r = smf.ols(formula='target ~ age + sex + bmi + bp', data=diabetes).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c75a7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using a more pythonic way\n",
    "X = sm.add_constant(diabetes[[\"age\", \"sex\", \"bmi\", \"bp\"]])\n",
    "y = diabetes[[\"target\"]]\n",
    "model_ols = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072ae7f",
   "metadata": {},
   "source": [
    "#### See outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efe98424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.400\n",
      "Model:                            OLS   Adj. R-squared:                  0.395\n",
      "Method:                 Least Squares   F-statistic:                     72.91\n",
      "Date:                Mon, 06 Nov 2023   Prob (F-statistic):           2.70e-47\n",
      "Time:                        16:58:14   Log-Likelihood:                -2434.2\n",
      "No. Observations:                 442   AIC:                             4878.\n",
      "Df Residuals:                     437   BIC:                             4899.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        152.1335      2.853     53.329      0.000     146.527     157.740\n",
      "age           37.2406     64.117      0.581      0.562     -88.776     163.258\n",
      "sex         -106.5762     62.125     -1.716      0.087    -228.677      15.525\n",
      "bmi          787.1817     65.424     12.032      0.000     658.597     915.766\n",
      "bp           416.6725     69.495      5.996      0.000     280.087     553.258\n",
      "==============================================================================\n",
      "Omnibus:                        9.858   Durbin-Watson:                   1.933\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):                6.464\n",
      "Skew:                           0.146   Prob(JB):                       0.0395\n",
      "Kurtosis:                       2.485   Cond. No.                         28.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model_ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a0eb8",
   "metadata": {},
   "source": [
    "#### Fitting OLS models with interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11df15f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.407\n",
      "Model:                            OLS   Adj. R-squared:                  0.400\n",
      "Method:                 Least Squares   F-statistic:                     59.77\n",
      "Date:                Mon, 06 Nov 2023   Prob (F-statistic):           2.40e-47\n",
      "Time:                        16:57:16   Log-Likelihood:                -2431.8\n",
      "No. Observations:                 442   AIC:                             4876.\n",
      "Df Residuals:                     436   BIC:                             4900.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    150.9570      2.892     52.203      0.000     145.274     156.640\n",
      "age           52.4516     64.228      0.817      0.415     -73.783     178.686\n",
      "sex         -102.7047     61.887     -1.660      0.098    -224.339      18.930\n",
      "bmi          813.1607     66.233     12.277      0.000     682.985     943.336\n",
      "bp           413.1195     69.219      5.968      0.000     277.075     549.164\n",
      "age:bmi     2809.4786   1291.944      2.175      0.030     270.265    5348.692\n",
      "==============================================================================\n",
      "Omnibus:                        8.252   Durbin-Watson:                   1.934\n",
      "Prob(Omnibus):                  0.016   Jarque-Bera (JB):                6.273\n",
      "Skew:                           0.184   Prob(JB):                       0.0434\n",
      "Kurtosis:                       2.547   Cond. No.                         455.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_ols_int= smf.ols(formula='target ~ age + sex + bmi + bp + age*bmi', data=diabetes).fit()\n",
    "print(model_ols_int.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb3567",
   "metadata": {},
   "source": [
    "#### Logit models\n",
    "\n",
    "The API for `stats.model` is the same for different types of models. So the learning costs of estimating different models are quite low. Let's estimate a logit model now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478860f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536502\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             target_bin   No. Observations:                  442\n",
      "Model:                          Logit   Df Residuals:                      437\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 06 Nov 2023   Pseudo R-squ.:                  0.2182\n",
      "Time:                        16:57:01   Log-Likelihood:                -237.13\n",
      "converged:                       True   LL-Null:                       -303.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.229e-27\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2809      0.113     -2.495      0.013      -0.502      -0.060\n",
      "age            1.1068      2.569      0.431      0.667      -3.929       6.142\n",
      "sex           -3.7533      2.459     -1.526      0.127      -8.573       1.066\n",
      "bmi           19.5943      2.852      6.871      0.000      14.005      25.183\n",
      "bp            14.6430      2.875      5.092      0.000       9.007      20.279\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# estimate the model using R style formula\n",
    "diabetes[\"target_bin\"] = np.where(diabetes[\"target\"]> np.mean(diabetes[\"target\"]), 1, 0)\n",
    "\n",
    "# model\n",
    "model_logit = smf.logit(formula='target_bin ~ age + sex + bmi + bp', data=diabetes).fit()\n",
    "\n",
    "# see output\n",
    "print(model_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9def05",
   "metadata": {},
   "source": [
    "### Understand the Model Quantities\n",
    "\n",
    "If we are interested in understanding relationships, a huge part of fitting inferential models consists on presenting the results as understanble quantities of interests. `statsmodels` has a set of functions that allow us to easily analyze the model. \n",
    "\n",
    "#### Retrieving model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5b0db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>152.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>37.240607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-106.576199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>787.181650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>416.672511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef\n",
       "const  152.133484\n",
       "age     37.240607\n",
       "sex   -106.576199\n",
       "bmi    787.181650\n",
       "bp     416.672511"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get parameters\n",
    "params = model_ols.params\n",
    "pd.DataFrame(params).rename(columns={0:\"coef\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2daecb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>146.526670</td>\n",
       "      <td>157.740298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-88.776333</td>\n",
       "      <td>163.257546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-228.677180</td>\n",
       "      <td>15.524781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>658.596846</td>\n",
       "      <td>915.766454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>280.087493</td>\n",
       "      <td>553.257528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lower       upper\n",
       "const  146.526670  157.740298\n",
       "age    -88.776333  163.257546\n",
       "sex   -228.677180   15.524781\n",
       "bmi    658.596846  915.766454\n",
       "bp     280.087493  553.257528"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confidence intervals\n",
    "model_ols.conf_int().rename(columns={0:\"lower\", 1:\"upper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb4542cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>2.048854e-193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>5.616622e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>8.696030e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>5.342370e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>4.245775e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p-values\n",
       "const  2.048854e-193\n",
       "age     5.616622e-01\n",
       "sex     8.696030e-02\n",
       "bmi     5.342370e-29\n",
       "bp      4.245775e-09"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-values\n",
    "pd.DataFrame(model_ols.pvalues).rename(columns={0:\"p-values\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cf43147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get a tidy data frame with results\n",
    "\n",
    "def tidy_ols(model):\n",
    "    \"\"\"\n",
    "    input: ols stats model\n",
    "    output: tidy pandas dataframe with models parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    params = pd.DataFrame(model.params).rename(columns={0:\"coef\"})\n",
    "    \n",
    "    # confidence intervals\n",
    "    coinf = model.conf_int().rename(columns={0:\"lower\", 1:\"upper\"})\n",
    "    \n",
    "    # p-values\n",
    "    pvalues = pd.DataFrame(model.pvalues).rename(columns={0:\"p-values\"})\n",
    "    \n",
    "    return pd.concat([params, coinf, pvalues], axis=1).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a1b03dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>coef</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>152.133484</td>\n",
       "      <td>146.526670</td>\n",
       "      <td>157.740298</td>\n",
       "      <td>2.048854e-193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>37.240607</td>\n",
       "      <td>-88.776333</td>\n",
       "      <td>163.257546</td>\n",
       "      <td>5.616622e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sex</td>\n",
       "      <td>-106.576199</td>\n",
       "      <td>-228.677180</td>\n",
       "      <td>15.524781</td>\n",
       "      <td>8.696030e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bmi</td>\n",
       "      <td>787.181650</td>\n",
       "      <td>658.596846</td>\n",
       "      <td>915.766454</td>\n",
       "      <td>5.342370e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bp</td>\n",
       "      <td>416.672511</td>\n",
       "      <td>280.087493</td>\n",
       "      <td>553.257528</td>\n",
       "      <td>4.245775e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        coef       lower       upper       p-values\n",
       "0  const  152.133484  146.526670  157.740298  2.048854e-193\n",
       "1    age   37.240607  -88.776333  163.257546   5.616622e-01\n",
       "2    sex -106.576199 -228.677180   15.524781   8.696030e-02\n",
       "3    bmi  787.181650  658.596846  915.766454   5.342370e-29\n",
       "4     bp  416.672511  280.087493  553.257528   4.245775e-09"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the function\n",
    "ols_tidy = tidy_ols(model_ols)\n",
    "\n",
    "# see\n",
    "ols_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e85f61",
   "metadata": {},
   "source": [
    "#### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e79adc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 480,
       "width": 640
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure Size: (640 x 480)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot\n",
    "plot = (ggplot(ols_tidy, aes(y='coef', x='index'))\n",
    "        + geom_point(aes(y='coef'), size=3, fill=\"red\", color=\"\")\n",
    "        + geom_errorbar(aes(ymin=\"lower\", ymax=\"upper\"), width=0.01, size=2, alpha=.3)\n",
    "        + theme_light()\n",
    "       )\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb83a4a",
   "metadata": {},
   "source": [
    "#### See more in the [documentation of statsmodels](https://www.statsmodels.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3d008",
   "metadata": {},
   "source": [
    "## Pratice\n",
    "\n",
    "Time for you to practice. \n",
    "\n",
    "- Estimate a different OLS model using the stats.models api. Add any variable you want to examine the effects\n",
    "- Build a plot with: \n",
    "    - Points with the predicted outcomes for all observations based on your model (y-axis)\n",
    "    - Points with observed valeus (x-axis)\n",
    "    - Line with the perfect fit between y and x\n",
    "    \n",
    "Tips:\n",
    "\n",
    "- You can get the fitted values with `model.fittedvalues`\n",
    "- the perfect fit comes with a 45 degree line `geom_abline(intercept = 0, slope = 1, size = 0.5)`\n",
    "\n",
    "\n",
    "Read more here for other diagnostics: https://www.statsmodels.org/stable/examples/notebooks/generated/ols.html    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917272c3",
   "metadata": {},
   "source": [
    "## Statistical learning with sklearn\n",
    "\n",
    "As we discussed in the lecture, in the macinhe learning tradition, we are interest in predictive modeling, instead of understanding relationship. This is the key feature on machine learning. \n",
    "\n",
    "- The goal i is to **_predict_** values of the outcome, $\\hat{y}$\n",
    "  \n",
    "- Models are treated as a **_black box_**\n",
    "\n",
    "- the model doesn't need to be interpretable as long as it provides an accurate prediction of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5060b1",
   "metadata": {},
   "source": [
    "## Machine Learning Workflow\n",
    "\n",
    "The figure below from Jorge Cimentada's book _Machine Learning for Social Science_ provides a nice summary of the traditional machine learning workiflow. \n",
    "\n",
    "![](https://cimentadaj.github.io/ml_socsci/img/socsci_wflow3_smaller.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8ee9b",
   "metadata": {},
   "source": [
    "In words: \n",
    "    \n",
    "- Start with a dataset\n",
    "- Split between training and test\n",
    "- Do some pre-processing\n",
    "- Train the model (with or without cross-validation)\n",
    "- Select best parameters (fine-tuning the model)\n",
    "- Evaluate the model in the **test set.**\n",
    "\n",
    "All these steps will be performed using the `sklearn` library. The documentation for `sklearn` is super rich. So I strongly encourage you to check their website and their tutorials: https://scikit-learn.org/stable/tutorial/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c5b71",
   "metadata": {},
   "source": [
    "### Simple Example: OLS just to learn the mechanics of the sklearn API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4472a",
   "metadata": {},
   "source": [
    "#### Open the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdf3822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# load the dataset as a pandas dataframe\n",
    "diabetes = datasets.load_diabetes(as_frame=True)[\"frame\"]\n",
    "\n",
    "# features\n",
    "X = diabetes.drop(columns=\"target\")\n",
    "\n",
    "# target\n",
    "y = diabetes[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c5dbb",
   "metadata": {},
   "source": [
    "#### Split between training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55539526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state = 417)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9accc772",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5125ca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    0\n",
       "sex    0\n",
       "bmi    0\n",
       "bp     0\n",
       "s1     0\n",
       "s2     0\n",
       "s3     0\n",
       "s4     0\n",
       "s5     0\n",
       "s6     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any missing? \n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5d75581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.511817e-19</td>\n",
       "      <td>1.230790e-17</td>\n",
       "      <td>-2.245564e-16</td>\n",
       "      <td>-4.797570e-17</td>\n",
       "      <td>-1.381499e-17</td>\n",
       "      <td>3.918434e-17</td>\n",
       "      <td>-5.777179e-18</td>\n",
       "      <td>-9.042540e-18</td>\n",
       "      <td>9.293722e-17</td>\n",
       "      <td>1.130318e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age           sex           bmi            bp            s1  \\\n",
       "mean -2.511817e-19  1.230790e-17 -2.245564e-16 -4.797570e-17 -1.381499e-17   \n",
       "std   4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
       "\n",
       "                s2            s3            s4            s5            s6  \n",
       "mean  3.918434e-17 -5.777179e-18 -9.042540e-18  9.293722e-17  1.130318e-17  \n",
       "std   4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stardandization?\n",
    "X.describe().loc[[\"mean\", \"std\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "619c8505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    float64\n",
       "sex    float64\n",
       "bmi    float64\n",
       "bp     float64\n",
       "s1     float64\n",
       "s2     float64\n",
       "s3     float64\n",
       "s4     float64\n",
       "s5     float64\n",
       "s6     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any categorical?\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef9e9d",
   "metadata": {},
   "source": [
    "this dataset is pretty much cleaned for us, we can skip pre-processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3ec82",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "\n",
    "**IMPORTANT**: The modeling API follows the same frame work (despite the model). You can fit many different models with very similar code. Let's start with a simple OLS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2cb4257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the modeling object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b205a",
   "metadata": {},
   "source": [
    "#### Evaluate the model - use the test set!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd0d751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4799898648936971"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit statistic (metric for how wrong we are) -- R^2\n",
    "model.score(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf04418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3325.658847637309"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## if you want to calculate the mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# predicted values\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "## estimate\n",
    "mean_squared_error(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288f0d7",
   "metadata": {},
   "source": [
    "### Many, many models, and an API to rule them all!\n",
    "\n",
    "Our performance with the simple linear regression was not great. Let's see if we get better using more complex models. We will try three different families of models. Again, you will learn about these models in DS II\n",
    "\n",
    "- Elastic-net: linear model with regularization parameters. \n",
    "- Support Vector Machines: a supervised model that allows more non-linearity between the parametes\n",
    "- Decision Tree: A model that uses a set of boolean rules in a non-parametric fashion that splits your data in multiple groups for supervised tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52a6f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for models\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# setup for metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# setup for dataset\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "212b15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset as a pandas dataframe\n",
    "diabetes = datasets.load_diabetes(as_frame=True)[\"frame\"]\n",
    "\n",
    "# features\n",
    "X = diabetes.drop(columns=\"target\")\n",
    "\n",
    "# target\n",
    "y = diabetes[\"target\"]\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state = 417)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb242a0d",
   "metadata": {},
   "source": [
    "### linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "727167d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "# Instantiate the modeling object\n",
    "model_ols = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_ols.fit(X_train,y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_ols = model_ols.predict(X_test)\n",
    "mse_ols = mean_squared_error(y_test, y_pred_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6fadf",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "380df35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Elastic Net model\n",
    "# alpha and l1_ratio are hyper parameter (learning is here!)\n",
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=1)  \n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_en = elastic_net.predict(X_test)\n",
    "mse_en = mean_squared_error(y_test, y_pred_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f5cb8",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "942e80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm = SVR(kernel='linear')  # Using linear kernel for demonstration\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca6f43",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d4cccc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Decision Tree model\n",
    "tree = DecisionTreeRegressor(random_state=0,  max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c1000cb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3324.324519</td>\n",
       "      <td>elastic-net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3325.658848</td>\n",
       "      <td>ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5184.585555</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7071.125649</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        values       models\n",
       "1  3324.324519  elastic-net\n",
       "0  3325.658848          ols\n",
       "3  5184.585555         tree\n",
       "2  7071.125649          svm"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"values\":[mse_ols, mse_en,mse_svm, mse_tree], \n",
    "               \"models\":[\"ols\", \"elastic-net\", \"svm\", \"tree\"]}).sort_values(\"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb34951",
   "metadata": {},
   "source": [
    "### Let's see the fit in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f5c10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "# Instantiate the modeling object\n",
    "model_ols = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_ols.fit(X_train,y_train)\n",
    "\n",
    "# predic and calculate MSE\n",
    "y_pred_ols = model_ols.predict(X_train)\n",
    "mse_ols = mean_squared_error(y_train, y_pred_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32450ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Elastic Net model\n",
    "# alpha is a hyper parameter (learning is here!)\n",
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=1)  \n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "y_pred_en = elastic_net.predict(X_train)\n",
    "mse_en = mean_squared_error(y_train, y_pred_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e99ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm = SVR(kernel='linear')  # Using linear kernel for demonstration\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "y_pred_svm = svm.predict(X_train)\n",
    "mse_svm = mean_squared_error(y_train, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f80b0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Decision Tree model\n",
    "tree = DecisionTreeRegressor(random_state=0,  max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "y_pred_tree = tree.predict(X_train)\n",
    "mse_tree = mean_squared_error(y_train, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "568fc5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005.933021</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2793.124358</td>\n",
       "      <td>ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2802.447120</td>\n",
       "      <td>elastic-net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5765.841372</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        values       models\n",
       "3  2005.933021         tree\n",
       "0  2793.124358          ols\n",
       "1  2802.447120  elastic-net\n",
       "2  5765.841372          svm"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"values\":[mse_ols, mse_en,mse_svm, mse_tree], \n",
    "               \"models\":[\"ols\", \"elastic-net\", \"svm\", \"tree\"]}).sort_values(\"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d7c57",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tunning and Cross Validation\n",
    "\n",
    "As you saw above, more advanced machine learning models have hyper-parameters. \n",
    "\n",
    "Hyperparameters are parameters that are not learned directly from the data but are set in advance before the training process begins, bur their best-values can be learned with training. Examples include the learning rate in gradient descent in deep-learning, the depth of a decision tree, or the number of neighbors in a k-nearest neighbors algorithm.\n",
    "\n",
    "The way we choose the values for hyper-parameters is by looking at the performance of the models. \n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "If we were to find the best-values for hyperparameters looking always to the test-set, we would be pretty much training the model on the test set. Remember, we should always avoid this. The test set should be unseen data, and we should keep its integrity. This process is commonly described as [data leakage](https://towardsdatascience.com/what-is-data-leakage-and-how-can-it-be-avoided-in-machine-learning-eb435a27c3e3)\n",
    "\n",
    "For this reason, when training machine learning models, we often rely on resampling methods, such as cross-validation. These methods allow us to fine tune our models by taking multiple samples of the training data, and training the model multiple times. \n",
    "\n",
    "Read here a nice and shor introduction to cross-validation: https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6264fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Obs. to train on = 282, N obs to test on = 71\n",
      "N Obs. to train on = 282, N obs to test on = 71\n",
      "N Obs. to train on = 282, N obs to test on = 71\n",
      "N Obs. to train on = 283, N obs to test on = 70\n",
      "N Obs. to train on = 283, N obs to test on = 70\n",
      "Total numbers of models run = 5\n"
     ]
    }
   ],
   "source": [
    "# lets see the mechanics first\n",
    "from sklearn.model_selection import train_test_split # Train-test split\n",
    "from sklearn.model_selection import LeaveOneOut # Leave One Out Cross Validation\n",
    "from sklearn.model_selection import KFold # K-fold Cross validation\n",
    "\n",
    "# Intialize the K-Folds (splits)\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Split the data\n",
    "k_splits = kf.split(X_train)\n",
    "\n",
    "# Let's look at the splits\n",
    "n_models =0\n",
    "for train, test in k_splits:\n",
    "    print(f\"N Obs. to train on = {train.shape[0]}, N obs to test on = {test.shape[0]}\") #\n",
    "    n_models += 1 # Count the number of models\n",
    "\n",
    "print(f\"Total numbers of models run = {n_models}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b0ab995",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "71",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 71",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X[\u001b[38;5;241m71\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 71"
     ]
    }
   ],
   "source": [
    "X[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1e896ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Fold 2:\n",
      "Fold 3:\n",
      "Fold 4:\n",
      "Fold 5:\n"
     ]
    }
   ],
   "source": [
    "# what the splits are? Index of the data\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Split the data\n",
    "k_splits = kf.split(X_train)\n",
    "\n",
    "# containers to store the data\n",
    "train_data = list()\n",
    "val_data = list()\n",
    "\n",
    "# iterate\n",
    "for fold_number, (train_indices, val_indices) in enumerate(k_splits):\n",
    "    print(f\"Fold {fold_number + 1}:\")\n",
    "    \n",
    "    # Split your data into training and validation sets using the indices\n",
    "    train_data.append([X_train.iloc[i] for i in train_indices])\n",
    "    val_data.append([X_train.iloc[i] for i in val_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7abf7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.070769</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.012117</td>\n",
       "      <td>0.056301</td>\n",
       "      <td>0.034206</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>-0.039719</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.027364</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.009147</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.018062</td>\n",
       "      <td>-0.033213</td>\n",
       "      <td>-0.020832</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.019633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.049840</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>-0.015328</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>-0.013504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.035307</td>\n",
       "      <td>-0.029770</td>\n",
       "      <td>-0.056607</td>\n",
       "      <td>-0.058620</td>\n",
       "      <td>0.030232</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.049872</td>\n",
       "      <td>-0.129483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.023677</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.065486</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>-0.038720</td>\n",
       "      <td>-0.053610</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.037129</td>\n",
       "      <td>-0.042499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.096328</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.076264</td>\n",
       "      <td>-0.043542</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.083920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.030440</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.047347</td>\n",
       "      <td>0.015505</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.030811</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.020218</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.004321</td>\n",
       "      <td>-0.029497</td>\n",
       "      <td>0.078093</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.010903</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-0.012780</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.023451</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.038460</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.092695</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>0.056003</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "17   0.070769  0.050680  0.012117  0.056301  0.034206  0.049416 -0.039719   \n",
       "66  -0.009147  0.050680 -0.018062 -0.033213 -0.020832  0.012152 -0.072854   \n",
       "137  0.005383 -0.044642  0.049840  0.097615 -0.015328 -0.016345 -0.006584   \n",
       "245 -0.027310 -0.044642 -0.035307 -0.029770 -0.056607 -0.058620  0.030232   \n",
       "31  -0.023677 -0.044642 -0.065486 -0.081413 -0.038720 -0.053610  0.059685   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106 -0.096328 -0.044642 -0.076264 -0.043542 -0.045599 -0.034821  0.008142   \n",
       "270  0.005383  0.050680  0.030440  0.083844 -0.037344 -0.047347  0.015505   \n",
       "348  0.030811 -0.044642 -0.020218 -0.005670 -0.004321 -0.029497  0.078093   \n",
       "435 -0.012780 -0.044642 -0.023451 -0.040099 -0.016704  0.004636 -0.017629   \n",
       "102 -0.092695 -0.044642  0.028284 -0.015999  0.036958  0.024991  0.056003   \n",
       "\n",
       "           s4        s5        s6  \n",
       "17   0.034309  0.027364 -0.001078  \n",
       "66   0.071210  0.000272  0.019633  \n",
       "137 -0.002592  0.017036 -0.013504  \n",
       "245 -0.039493 -0.049872 -0.129483  \n",
       "31  -0.076395 -0.037129 -0.042499  \n",
       "..        ...       ...       ...  \n",
       "106 -0.039493 -0.059471 -0.083920  \n",
       "270 -0.039493  0.008641  0.015491  \n",
       "348 -0.039493 -0.010903 -0.001078  \n",
       "435 -0.002592 -0.038460 -0.038357  \n",
       "102 -0.039493 -0.005142 -0.001078  \n",
       "\n",
       "[282 rows x 10 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "pd.DataFrame(train_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e3816",
   "metadata": {},
   "source": [
    "### Easy implementation with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74217f4",
   "metadata": {},
   "source": [
    "Let's implement using `sklearn`. We actually don't need a loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fc14670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create my splits\n",
    "# what the splits are? Index of the data\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Split the data\n",
    "k_splits = kf.split(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6cdad8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Elastic Net parameters: {'alpha': 0.1, 'l1_ratio': 1}\n",
      "Best MSE: 0.45551049830889384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.279e+05, tolerance: 1.706e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e+05, tolerance: 1.758e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.511e+05, tolerance: 1.755e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.584e+05, tolerance: 1.559e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.670e+05, tolerance: 1.794e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e+05, tolerance: 1.706e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.729e+05, tolerance: 1.758e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.719e+05, tolerance: 1.755e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.749e+05, tolerance: 1.559e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e+05, tolerance: 1.794e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+05, tolerance: 1.706e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.760e+05, tolerance: 1.758e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.746e+05, tolerance: 1.755e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.771e+05, tolerance: 1.559e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.937e+05, tolerance: 1.794e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.517e+05, tolerance: 1.706e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.775e+05, tolerance: 1.758e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.760e+05, tolerance: 1.755e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.782e+05, tolerance: 1.559e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+05, tolerance: 1.794e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.525e+05, tolerance: 1.706e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.785e+05, tolerance: 1.758e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.769e+05, tolerance: 1.755e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.788e+05, tolerance: 1.559e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.963e+05, tolerance: 1.794e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "params = {\n",
    "    'alpha': [0.1, 0.5, 1, 2, 5],\n",
    "    'l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "# elastic net\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_en = GridSearchCV(elastic_net, params, cv=kf, scoring='r2')\n",
    "grid_en.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and corresponding MSE\n",
    "print(\"Best Elastic Net parameters:\", grid_en.best_params_)\n",
    "print(\"Best MSE:\", grid_en.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f8c1ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree parameters: {'max_depth': 2, 'min_samples_split': 2}\n",
      "Best MSE: 0.35160918571106714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "params = {\n",
    "    'max_depth': [None, 2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "grid_tree = GridSearchCV(tree, params, cv=kf, scoring='r2')\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Decision Tree parameters:\", grid_tree.best_params_)\n",
    "print(\"Best MSE:\", grid_tree.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa2f0740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN parameters: {'n_neighbors': 9}\n",
      "Best MSE: 0.37833624073149236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "grid_knn = GridSearchCV(knn, params, cv=kf, scoring='r2')\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best KNN parameters:\", grid_knn.best_params_)\n",
    "print(\"Best MSE:\", grid_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "383cf838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on cross-validation results\n",
    "best_model = min([grid_en, grid_tree, grid_knn], key=lambda x: -x.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b7d98c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 1}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which model?\n",
    "best_model.best_estimator_\n",
    "\n",
    "# what else\n",
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa0a9f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set MSE for the best model: 2798.19\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the test set MSE\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test set MSE for the best model: {mse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53b421",
   "metadata": {},
   "source": [
    "All of this only touches the top of the iceberg on Machine Learning. If you want to go ahead and learn more before DS II, I would suggest you to: \n",
    "\n",
    "- Read [Introduction to Statistical Learning in Python](https://www.statlearning.com/)\n",
    "\n",
    "- Work through the [tutorials on sklearn webpage](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178739c3",
   "metadata": {},
   "source": [
    "### Practice\n",
    "\n",
    "In groups, read the sklearn documentation or check the slide with models I show you in class. \n",
    "\n",
    "Pick a additional model from the sklearn. Compare this model with the three models I show you in this notebook \n",
    "\n",
    "Feel free to copy and paste the code above, and add your new model and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ef1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b23740a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook _week-9-models.ipynb to html\n",
      "[NbConvertApp] Writing 436849 bytes to _week-9-models.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert _week-9-models.ipynb --to html --template classic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
