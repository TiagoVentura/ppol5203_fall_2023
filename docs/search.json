[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Week\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nWeek 01\n\n\nIntroduction, Installations, IDEs, Command line\n\n\nAugust 29, 2023\n\n\n\n\nWeek 02\n\n\nVersion Control, Workflow and Reproducibility: Or a bit of Git & GitHub\n\n\nSeptember 12, 2023\n\n\n\n\nWeek 03\n\n\nIntro to Python - OOP, Data Types, Control Statements and Functions\n\n\nSeptember 19, 2023\n\n\n\n\nWeek 04\n\n\nFrom Nested Lists to Data Frames\n\n\nSeptember 26, 2023\n\n\n\n\nWeek 05\n\n\nPandas I: Data Manipulation\n\n\nOctober 03, 2023\n\n\n\n\nWeek 06\n\n\nPandas II: Advanced Manipulation and Visualization\n\n\nOctober 10, 2023\n\n\n\n\nWeek 07\n\n\nScrapping: Drawing from (Un-)Structured Data Sources\n\n\nOctober 17, 2023\n\n\n\n\nWeek 08\n\n\nText as data I: Data Mining\n\n\nOctober 24, 2023\n\n\n\n\nWeek 09\n\n\nIntroduction to Statistical Learning\n\n\nOctober 31, 2023\n\n\n\n\nWeek 10\n\n\nText as Data II: Topics + Supervised Models\n\n\nNovember 07, 2023\n\n\n\n\nWeek 11\n\n\nInvited Speaker: Introduction to Algorithms + Coding Interviews\n\n\nNovember 14, 2023\n\n\n\n\nWeek 12\n\n\nTraining Machines and collecting data with Selenium\n\n\nNovember 21, 2023\n\n\n\n\nWeek 13\n\n\nSQL + Spark\n\n\nNovember 28, 2023\n\n\n\n\nWeek 14\n\n\nPresentations of Final Projects\n\n\nDecember 05, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#weekly-schedule",
    "href": "schedule.html#weekly-schedule",
    "title": "Schedule",
    "section": "",
    "text": "Week\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nWeek 01\n\n\nIntroduction, Installations, IDEs, Command line\n\n\nAugust 29, 2023\n\n\n\n\nWeek 02\n\n\nVersion Control, Workflow and Reproducibility: Or a bit of Git & GitHub\n\n\nSeptember 12, 2023\n\n\n\n\nWeek 03\n\n\nIntro to Python - OOP, Data Types, Control Statements and Functions\n\n\nSeptember 19, 2023\n\n\n\n\nWeek 04\n\n\nFrom Nested Lists to Data Frames\n\n\nSeptember 26, 2023\n\n\n\n\nWeek 05\n\n\nPandas I: Data Manipulation\n\n\nOctober 03, 2023\n\n\n\n\nWeek 06\n\n\nPandas II: Advanced Manipulation and Visualization\n\n\nOctober 10, 2023\n\n\n\n\nWeek 07\n\n\nScrapping: Drawing from (Un-)Structured Data Sources\n\n\nOctober 17, 2023\n\n\n\n\nWeek 08\n\n\nText as data I: Data Mining\n\n\nOctober 24, 2023\n\n\n\n\nWeek 09\n\n\nIntroduction to Statistical Learning\n\n\nOctober 31, 2023\n\n\n\n\nWeek 10\n\n\nText as Data II: Topics + Supervised Models\n\n\nNovember 07, 2023\n\n\n\n\nWeek 11\n\n\nInvited Speaker: Introduction to Algorithms + Coding Interviews\n\n\nNovember 14, 2023\n\n\n\n\nWeek 12\n\n\nTraining Machines and collecting data with Selenium\n\n\nNovember 21, 2023\n\n\n\n\nWeek 13\n\n\nSQL + Spark\n\n\nNovember 28, 2023\n\n\n\n\nWeek 14\n\n\nPresentations of Final Projects\n\n\nDecember 05, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/week-2.html#announcements",
    "href": "slides/week-2.html#announcements",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Announcements",
    "text": "Announcements\n\nSierra Office Hours\n\nIn person: Wednesdays, 12:30 to 1:30 pm\nVirtual: Thursday, 1:00pm to 2:00 pm\n\nThis is our classroom\n\nI will get some power cords"
  },
  {
    "objectID": "slides/week-2.html#plans-for-today",
    "href": "slides/week-2.html#plans-for-today",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Plans for Today",
    "text": "Plans for Today\n\n\nBest Practices for Data Science Workflow and Reproducibility\nVersion Control\n\nIntro to commandline\nGit\nGithub\n\nIn-Class Exercise\nYour first homework\n\n\n\n\nthis lecture draws on materials from Simon Munzert Intro to Data Science + previous iterations of PPOL 5203."
  },
  {
    "objectID": "slides/week-2.html#thats-what-we-generally-look-for-as-data-scientists",
    "href": "slides/week-2.html#thats-what-we-generally-look-for-as-data-scientists",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "That’s what we generally look for as data scientists",
    "text": "That’s what we generally look for as data scientists"
  },
  {
    "objectID": "slides/week-2.html#but-we-often-dont-teach-students-how-to-organize-the-mess-behind-it.",
    "href": "slides/week-2.html#but-we-often-dont-teach-students-how-to-organize-the-mess-behind-it.",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "But we often don’t teach students how to organize the mess behind it.",
    "text": "But we often don’t teach students how to organize the mess behind it."
  },
  {
    "objectID": "slides/week-2.html#we-often-assume-we-are-capable-of-keeping-track-our-own-work",
    "href": "slides/week-2.html#we-often-assume-we-are-capable-of-keeping-track-our-own-work",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "We often assume we are capable of keeping track our own work",
    "text": "We often assume we are capable of keeping track our own work"
  },
  {
    "objectID": "slides/week-2.html#but-this-assumption-will-set-you-up-to-fail",
    "href": "slides/week-2.html#but-this-assumption-will-set-you-up-to-fail",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "But this assumption will set you up to fail",
    "text": "But this assumption will set you up to fail\n\nAs you advance on your career as a data scientist:\n\nYour projects will grow.\nYou will start collaborating with other colleagues (DS is fundamentally collaborative)\nYou will juggle through multiple project from now and from the past!\nProject will come and go.\nYou will re-use code A LOT!"
  },
  {
    "objectID": "slides/week-2.html#section",
    "href": "slides/week-2.html#section",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "",
    "text": "You need to set up a system to keep track of you work (not you! the system!)"
  },
  {
    "objectID": "slides/week-2.html#reproducibility",
    "href": "slides/week-2.html#reproducibility",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Reproducibility",
    "text": "Reproducibility\n\n\nReproducibility is fundamental to the scientific method but also a practical reality\nThink about your projects as self-contained project that need to be:\n\nfully replicated by others (that’s science)\nreplicable by you (that’s the practical reality)"
  },
  {
    "objectID": "slides/week-2.html#best-practices",
    "href": "slides/week-2.html#best-practices",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Best Practices",
    "text": "Best Practices\n\n\nSelf Contained Projects\nDocumentation\nReadability\nNaming\nPortability\nVersion Control"
  },
  {
    "objectID": "slides/week-2.html#self-contained-projects",
    "href": "slides/week-2.html#self-contained-projects",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Self-Contained Projects",
    "text": "Self-Contained Projects\n\nAlways consider your work in terms of projects.\n\nA project is a self-contained unit of data science work that can be shared and replicated\nA self-contained project has:\n\ncontent: data, code, outputs, literature, text\nmetadata: readme for the project and each folder, information about the tools you are running"
  },
  {
    "objectID": "slides/week-2.html#example-of-project-setup",
    "href": "slides/week-2.html#example-of-project-setup",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Example of Project Setup",
    "text": "Example of Project Setup\n\n├── /data\n│   ├── /raw      \n│   ├── /processed  \n├── /docs \n├── /code\n|   |── 01_clean_xxx.py\n|   |── 01_analysis_xxx.py\n\n├── /literature      \n\n├── /output      \n│   ├── /tables      \n│   ├── /figures  \n├── /misc \n└── readme.txt"
  },
  {
    "objectID": "slides/week-2.html#documentation",
    "href": "slides/week-2.html#documentation",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Documentation",
    "text": "Documentation\nUse # to describe every single step of your code\n\ndef distance_tree(geom, geo_neigh, n):\n    \"\"\"\"\n    function to calculate the closest point and get their index using scipy\n    geom: geo pandas data frame with the reference points\n    geo_neigh: geo pandas data frame the neighbors location point\n    n: str,  number of closest neighboors\n    \"\"\"\n\n    # convert geometries to numpy\n    n_geom = np.array(list(geom.geometry.apply(lambda x: (x.x, x.y))))\n    n_geo_neigh = np.array(list(geo_neigh.geometry.apply(lambda x: (x.x, x.y))))\n\n    # estimate the trees\n    btree = cKDTree(n_geo_neigh) # btreee neighbors\n\n    # captures distances and indexes\n    dist, idx = btree.query(n_geom, n)\n\nvs\n\ndef distance_tree(geom, geo_neigh, n):\n    n_geom = np.array(list(geom.geometry.apply(lambda x: (x.x, x.y))))\n    n_geo_neigh = np.array(list(geo_neigh.geometry.apply(lambda x: (x.x, x.y))))\n    btree = cKDTree(n_geo_neigh)\n    dist, idx = btree.query(n_geom, n)"
  },
  {
    "objectID": "slides/week-2.html#readability",
    "href": "slides/week-2.html#readability",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Readability",
    "text": "Readability\nMake you code readable in plain english. This usually mean giving names to your variables and functions that fully describe what your intents are.\n\nAvoid:\n\nAbbreviation\nGeneric Names\nMisleading names"
  },
  {
    "objectID": "slides/week-2.html#naming",
    "href": "slides/week-2.html#naming",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Naming",
    "text": "Naming\nUse meaningful names for your code/data/notebooks.\n\nFile names should be meaningful\nDO NOT USE SPACES. Use snake case (_) style for you files and code\n\n\n\n\ndata analysis 2.py → data_analysis_2.py\n\n\n\n\n\nmodel_analysis.py → model_analysis_het_treatment_effects_main_paper.py"
  },
  {
    "objectID": "slides/week-2.html#portability",
    "href": "slides/week-2.html#portability",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Portability",
    "text": "Portability\n\nUse computational environments for your projects. (pyenv or conda)\nAvoid absolute file paths\n\nGood Examples: “preprocessing.py” “figures/model-1.png” ” /data/survey.csv”\nTerrible examples: “/Users/me/ppol5203/data.csv” - only exists in your machine!!!"
  },
  {
    "objectID": "slides/week-2.html#why-version-control-in-theory",
    "href": "slides/week-2.html#why-version-control-in-theory",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Why version control (in theory)?",
    "text": "Why version control (in theory)?\n\n\n\n\n\n\n\n\n\n\n\nphdcomics.com"
  },
  {
    "objectID": "slides/week-2.html#why-version-control-in-practice",
    "href": "slides/week-2.html#why-version-control-in-practice",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Why version control (in practice)?",
    "text": "Why version control (in practice)?\n\nEasily handle collaboration (contribute to other people’s work)\nAllows you to “rewind the tape” to earlier incarnations of your notes, drafts, papers and code\nIt is like Microsoft Word track changes but for your entire project\nAllows you to review, comment, and analyze other people’s codes\nHeavily adopted in the industry"
  },
  {
    "objectID": "slides/week-2.html#what-is-version-control",
    "href": "slides/week-2.html#what-is-version-control",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "What is version control?",
    "text": "What is version control?\n\nVersion control is a system that records changes to a file or set of files over time so that you can recall specific versions later. (pro git)\n\n\nGit: one of many options for version control in data science. Distributed system\nGithub: is a public remote host for Git repositories. A web-based platform to store git repos\n\nIt has much more features, for example, git hub actions, pages, pull and push. we will go through some today\n\nTLDR: you will git locally, and share and collaborate with others using Github.\nCrucial to realize those are different!"
  },
  {
    "objectID": "slides/week-2.html#commandline",
    "href": "slides/week-2.html#commandline",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "CommandLine",
    "text": "CommandLine\n\nGit is a commandline tool. To use git in your computer, you will need to access the commandline.\nThe command line (CLI) is a program that allows you to interact directly with your operating system.\n\nIf you’re on a Mac a unix command line comes installed on your machine\nIf you’re on a Windows machine, you have a few different options for commandline, and not all are unix-based\n\nHow will we use CLI?\n\nRun git\nUnderstand file paths on your computer\nRun scripts from the commandline\nOpen notebook and interact with other programs\nSet up cluster computing."
  },
  {
    "objectID": "slides/week-2.html#basic-commands",
    "href": "slides/week-2.html#basic-commands",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Basic Commands",
    "text": "Basic Commands\nWhere am I?\n\npwd\n\nHow do I make a new directory with name foldername?\n\nmkdir foldername\n\nHow do I navigate to folder foldername?\n\ncd foldername\n\nI’m lost; how do I get back to the home directory?\n\ncd ~\n\nWhat files and directories are in this directory?\n\nls\n\nHow do I navigate “up one level” in the dir structure?\n\ncd .."
  },
  {
    "objectID": "slides/week-2.html#more-commands",
    "href": "slides/week-2.html#more-commands",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "More Commands",
    "text": "More Commands\nHow do I create a file?\n\ntouch &lt;file name&gt;\n# or\nvim &lt;file name&gt;\n\nHow do I move files?\n\nmv &lt;old path&gt; &lt;new path&gt;\n\nHow do I see a file?\n\ncat &lt;file name&gt;\n\nHow do I ask for help&gt;\n\nman ls"
  },
  {
    "objectID": "slides/week-2.html#version-control-in-theory",
    "href": "slides/week-2.html#version-control-in-theory",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Version Control in Theory",
    "text": "Version Control in Theory\nKey concepts in git:\n\nGit: snapshot + distributed VCS\nThree stages of git\nTime travel\nRemotes with Github"
  },
  {
    "objectID": "slides/week-2.html#git-a-distributed-version-control-system",
    "href": "slides/week-2.html#git-a-distributed-version-control-system",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Git: a distributed version control system",
    "text": "Git: a distributed version control system\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is the git system.\nit is distributed.\nExists in your local machine\n\n\n\n\n\nSource: pro git"
  },
  {
    "objectID": "slides/week-2.html#the-three-stages-of-git",
    "href": "slides/week-2.html#the-three-stages-of-git",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "The three stages of Git",
    "text": "The three stages of Git"
  },
  {
    "objectID": "slides/week-2.html#time-travel-in-git",
    "href": "slides/week-2.html#time-travel-in-git",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Time travel in Git",
    "text": "Time travel in Git"
  },
  {
    "objectID": "slides/week-2.html#github-remote-git-repositories",
    "href": "slides/week-2.html#github-remote-git-repositories",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Github (Remote Git Repositories)",
    "text": "Github (Remote Git Repositories)"
  },
  {
    "objectID": "slides/week-2.html#create-your-first-repository",
    "href": "slides/week-2.html#create-your-first-repository",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Create your first repository",
    "text": "Create your first repository\nCreate an empty directory to be our git walkthrough\n\n# check where you are\npwd \n\n# create dir\nmkdir gitwalkthrough\n\n# change cd\n\ncd gitwalkthrough\n\nCheck if you have a git\n\ngit status\n\nStart a repository\n\ngit init\n\nTracking and staging new files: make any changes you want, then stage\n\ngit add &lt;file name&gt;\n\nFirst commit\n\ngit commit -m \"add a tag\""
  },
  {
    "objectID": "slides/week-2.html#git-in-practice-ii-time-travel",
    "href": "slides/week-2.html#git-in-practice-ii-time-travel",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Git in Practice II: Time Travel",
    "text": "Git in Practice II: Time Travel\nReturning to a previous snapshot:\n\nMake more changes\n\ngit add . track and stage\ngit commit -m 'second commit' *second commit\n\nCheck your log\n\ngit log\n\nTime travel with checkout\n\ngit checkout &lt;hash&gt; #to move to a past different snapshot\n\nCheck your directory\n\nls"
  },
  {
    "objectID": "slides/week-2.html#git-branching",
    "href": "slides/week-2.html#git-branching",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Git Branching",
    "text": "Git Branching\n\nBranching allows us to work on different paths in Git. It is very useful for two purposes:\n\nExperimenting with code\nCollaborating with colleagues.\n\nVisualize with Visualize Git tool"
  },
  {
    "objectID": "slides/week-2.html#git-branching-in-practice",
    "href": "slides/week-2.html#git-branching-in-practice",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Git Branching in Practice",
    "text": "Git Branching in Practice\n\nCreate a new branch\n\ngit checkout -b &lt;branch-name&gt;\n\nWrite code or create new files\n\nvim test4.txt\n\nStage and commit\n\ngit add .\ngit commit -m \" hello from alternative world\"\n\nCheck status across different branches\n\nls  # test4.txt should be here\ngit checkout master #move back to the master branch*\nls  #no test4.txt\n\nThen we can merge our branches. Here we are doing a fast-forward merge, moving our master to keep up with the alternative branch\n\ngit merge [new branch]"
  },
  {
    "objectID": "slides/week-2.html#git-conflicts",
    "href": "slides/week-2.html#git-conflicts",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Git conflicts",
    "text": "Git conflicts\nWhen merging across different branches, sometimes there are conflicts between branches.\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nADD EXAMPLE FROM class\n=======\nADD EXAMPLE FROM CLASS\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; new-branch\n\nOpen your text editor and navigate to the file that has merge conflicts.\nSolve the conflict (which may incorporate changes from both branches) and delete the conflict markers\nStage your changes (git add)\nCommit your changes (git commit)"
  },
  {
    "objectID": "slides/week-2.html#git-in-practice-conflicts",
    "href": "slides/week-2.html#git-in-practice-conflicts",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Git in Practice: Conflicts",
    "text": "Git in Practice: Conflicts\n\nCreate a new branch, change an file, and commit\n\ngit checkout -b \"new\" # create a branch call new, checkout directly\nvim test1.txt # make some modification\ngit add test1.txt\ngit commit -m \"new file 1\" # commit your changes\n\nDo the same in the master branch\n\ngit checkout master # checkout to master branch\nvim test1.txt #make some modification and see that the old modification is not here\ngit add test1.txt # stage\ngit commit -m \"new file 1 from master\"  # commit your changes\n\nMerge and solve conflict\n\ngit merge new"
  },
  {
    "objectID": "slides/week-2.html#section-1",
    "href": "slides/week-2.html#section-1",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "",
    "text": "Solve the conflict\n\nvim test1.txt \ngit add test1.txt\ngit commit -m \"fixed conflict\" ## commit your changes\ngit log ## to see your merge complete"
  },
  {
    "objectID": "slides/week-2.html#git-remotes-git-github.",
    "href": "slides/week-2.html#git-remotes-git-github.",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Git Remotes: Git + Github.",
    "text": "Git Remotes: Git + Github.\nMost times, you will use git integrated with Github. Github allows multiple researchers to write and share code at the same time.\nThis is my workflow for github.\n\nStarting a New Project. Before you write any code:\n\nGo to your github, and create a new repository\nOpen your terminal, and clone the project\n\n\n\n\n# clone\ngit clone &lt;url&gt;\n\n#Move your working directory to this new folder\ncd &lt;project-directory&gt;\n\n#Write code!"
  },
  {
    "objectID": "slides/week-2.html#section-2",
    "href": "slides/week-2.html#section-2",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "",
    "text": "Track your changes:\n\ngit add . \n\nCommit:\n\ngit commit -m 'describe your commit'\n\nPush the changes in your local repository to GitHub:\n\ngit push \n# or with branch\ngit push-u origin [branch-name]"
  },
  {
    "objectID": "slides/week-2.html#can-anybody-push-to-my-repository",
    "href": "slides/week-2.html#can-anybody-push-to-my-repository",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Can anybody push to my repository?",
    "text": "Can anybody push to my repository?\n\nNo, all repositories are read-only for anonymous users. By default only the owner of the repository has write access. If you can push to your own repo, it’s because you are using one of the supported authentification methods (HTTPS, SSH, …).\n\n\nIf you want to grant someone else privileges to push to your repo, you would need to configure that access in the project settings.\n\n\nTo contribute to projects in which you don’t have push access, you push to your own copy of the repo, then ask for a pull-request. Linux is not a good example for that, because the kernel developers do not use GitHub pull requests.\n\n\n\nsource: https://stackoverflow.com/questions/17442930/can-anybody-push-to-my-project-on-github"
  },
  {
    "objectID": "slides/week-2.html#pull-from-remotes",
    "href": "slides/week-2.html#pull-from-remotes",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Pull from Remotes",
    "text": "Pull from Remotes\nTo keep up with your colleague work, you need to first pull their updates from the git repo.\n\n# go to your repo\ncd &lt;gitrepo&gt;\n\n# pull the changes\ngit pull\n\nSee this tutorial"
  },
  {
    "objectID": "slides/week-2.html#some-additional-tasks",
    "href": "slides/week-2.html#some-additional-tasks",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Some additional tasks:",
    "text": "Some additional tasks:\n\ncheck the discussion about .gitignore in the lecture notes.\nyou might need to set up an personal token to push things on github, see here\nplay around with gitub: readme, directories, and issues."
  },
  {
    "objectID": "slides/week-2.html#practice",
    "href": "slides/week-2.html#practice",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": " Practice!",
    "text": "Practice!\nClick here to setup your github classroom and do the in-class exercise for you to practice."
  },
  {
    "objectID": "slides/week-2.html#homework.",
    "href": "slides/week-2.html#homework.",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Homework.",
    "text": "Homework.\nYour homework will be posted today on slack and canvas.\n\nSame structure of the in-class exercise.\nDeadline: September 22, midnight EST.\nQuestions? Come to my/Sierra office hours, ask on slack.\n\n\n\nData science I: Foundations"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PPOL 5203 - Data Science I: Foundations",
    "section": "",
    "text": "This first course in the core data science sequence teaches Data Science for Public Policy (DSPP) students how to synthesize disparate, possibly unstructured data in order to draw meaningful insights. Topics covered include the fundamentals of object-oriented programming in Python; literate programming; an introduction to algorithms and data types; data wrangling, visualization, and extraction; an introduction to machine learning methods, and text analysis. In addition, students will be exposed to Git and Github for version control and reproducible research. The objective of the course is to teach students how incorporate data into their decision-making and analysis. No prior programming experience is assumed or required.\nThis is not the first time this course is taught at DSPP. For this reason, several of the materials here are borrowed from previous iterations of this PPOL 564 taught by Dr. Rebecca Johnson and Dr. Eric Dunford"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "PPOL 5203 - Data Science I: Foundations",
    "section": "",
    "text": "This first course in the core data science sequence teaches Data Science for Public Policy (DSPP) students how to synthesize disparate, possibly unstructured data in order to draw meaningful insights. Topics covered include the fundamentals of object-oriented programming in Python; literate programming; an introduction to algorithms and data types; data wrangling, visualization, and extraction; an introduction to machine learning methods, and text analysis. In addition, students will be exposed to Git and Github for version control and reproducible research. The objective of the course is to teach students how incorporate data into their decision-making and analysis. No prior programming experience is assumed or required.\nThis is not the first time this course is taught at DSPP. For this reason, several of the materials here are borrowed from previous iterations of this PPOL 564 taught by Dr. Rebecca Johnson and Dr. Eric Dunford"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "PPOL 5203 - Data Science I: Foundations",
    "section": "Goals",
    "text": "Goals\nAfter completing this course, the students will be able to:\n\nGeneral understanding of python’s object oriented programming syntax and data structures.\nCompetency using version control (Git/Github).\nLearn to manipulate and explore data with Pandas and other tools.\nGeneral understanding of analyzing algorithms and data structures.\nLearn to extract and process data from structured and unstructured sources.\nGet some intuition of modeling text data in Python.\nLearn the basics of machine learning as a modeling approach.\nLearn basics of using SQL to query databases."
  },
  {
    "objectID": "index.html#instructors-and-tas",
    "href": "index.html#instructors-and-tas",
    "title": "PPOL 5203 - Data Science I: Foundations",
    "section": "Instructors and TAs",
    "text": "Instructors and TAs\n\nInstructor: Professor Tiago Ventura\n\nPronouns: He/Him\nEmail: tv186@georgetown.edu\nOffice hours:\n\nTime: Every Thursday, 4pm - 6pm\nLocation: Old North, 312\n\n\n\n\n\n\n\n\nWhen should I go to your office hours?\n\n\n\n\n\n\nYou are all welcome to the office hours. You can come to the office hours to:\n\ndrink some coffee;\ntalk about soccer;\nAsk what I am doing research at;\nAsk any question about our class.\n\nAll are valid options! And no need to schedule time with me!\n\n\nTA: Sierra Sikorski (DSPP, Second Year)\n\nEmail: sps126@georgetown.edu@georgetown.edu\nOffice Hours:\n\nWednesdays, 12:30 to 1:30 pm, at Old North Lounge\nThursday, 1:00pm to 2:00 pm, via Zoom\n\n\n\n\nCourse Infra-structure\nClass Website: This class website will be used throughout the course and should be checked on a regular basis for lecture materials and required readings.\nClass Slack Channel: The class also has a dedicated slack channel. The channel serves as an open forum to discuss, collaborate, pose problems/questions, and offer solutions. Students are encouraged to pose any questions they have there as this will provide the professor and TA the means of answering the question so that all can see the response. If you’re unfamiliar with, please consult the following start-up tutorial https://get.slack.help/hc/en-us/articles/218080037-Getting-started-for-new-members. Please follow the invite link to be added to the Slack channel.\nCanvas: A Canvas site http://canvas.georgetown.edu will be used throughout the course and should be checked on a regular basis for announcements. Materials will be posted here, and not on canvas, or distributed in class or by e-mail. Support for Canvas is available at (202) 687-4949\nDatacamp: As part of this course, you will have access to a DataCamp classroom that you can use to take Datacamp modules for free. Datacamp courses can be a useful tool for you to practice the concepts we see in class. Although I will not assign specific courses for you,, you can use Datacamp courses to review the topics we cover in class. The lecture notes will cover in details all our in-class discussions. Datacamp courses will be considered additional material."
  },
  {
    "objectID": "lecture_notes/week-06/lecture_10-data-exploration.html",
    "href": "lecture_notes/week-06/lecture_10-data-exploration.html",
    "title": "Data Exploration",
    "section": "",
    "text": "dat.shape\n\n(13855, 12)\n\n\n\ndat.columns\n\nIndex(['country', 'ccode', 'year', 'polity', 'gdppc', 'pop', 'continent',\n       'regime_type', 'infant_mort', 'life_exp', 'life_exp_female',\n       'life_exp_male'],\n      dtype='object')\n\n\n\ndat.index\n\nRangeIndex(start=0, stop=13855, step=1)"
  },
  {
    "objectID": "lecture_notes/week-06/lecture_10-data-exploration.html#data-types-drives-visualization-decisions",
    "href": "lecture_notes/week-06/lecture_10-data-exploration.html#data-types-drives-visualization-decisions",
    "title": "Data Exploration",
    "section": "Data types drives visualization decisions",
    "text": "Data types drives visualization decisions\n\n\n\n\n\n\n\n\nData Type\nExample\nScale\n\n\n\n\nNumerical\n1.3, 800, 10e3\nContinuous\n\n\nInteger\n1, 2, 3\nDiscrete (when \\(n\\) is small), Continuous (when \\(n\\) is large)\n\n\nCategorical\n“dog”, “Nigeria”, “A”\nDiscrete\n\n\nOrdered\n“Small”, “Medium”, “Large”\nDiscrete\n\n\nDates/Time\n2009-01-02, 5:32:33\nContinuous\n\n\n\n\n###\n\nDiscrete Values\n\n\n \n\n###\n\nContinuous Values\n\n\n\n\n###\n\nRelationships"
  },
  {
    "objectID": "lecture_notes/week-06/lecture_10-data-exploration.html#numerical-summaries",
    "href": "lecture_notes/week-06/lecture_10-data-exploration.html#numerical-summaries",
    "title": "Data Exploration",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\n\nContinuous Variables\n\nFive Number Summary:\n\nMinimum Value\nFirst Quartile (25%)\nMedian (50%)\nThird Quartile (75%)\nMaximum Value\n\nMoments of the Distribution:\n\nMean (central tendency)\nStandard Deviation (Spread)\n\n\nPandas offers both these summaries jointly with the the .describe() method.\n\ndat.describe(include=\"float\").round(1).T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\npolity\n6538.0\n1.1\n7.4\n-10.0\n-7.0\n2.0\n9.0\n1.000000e+01\n\n\ngdppc\n6538.0\n5814.4\n11299.3\n37.5\n383.1\n1210.6\n5147.7\n1.030592e+05\n\n\npop\n6538.0\n38776599.2\n133833028.0\n220312.0\n3723898.8\n8930337.0\n23616013.7\n1.378665e+09\n\n\ninfant_mort\n6217.0\n58.0\n48.7\n1.6\n15.7\n45.6\n92.5\n2.365000e+02\n\n\nlife_exp\n6485.0\n62.7\n12.2\n18.9\n52.9\n65.0\n72.9\n8.400000e+01\n\n\nlife_exp_female\n6485.0\n64.9\n12.8\n22.4\n54.4\n67.2\n75.7\n8.710000e+01\n\n\nlife_exp_male\n6485.0\n60.6\n11.7\n16.3\n51.2\n62.9\n70.2\n8.170000e+01\n\n\n\n\n\n\n\n\n\nCategorical (Discrete) Variables\n\ndat.describe(include=\"category\").T\n\n\n\n\n\n\n\n\ncount\nunique\ntop\nfreq\n\n\n\n\ncountry\n6538\n122\nJordan\n57\n\n\ncontinent\n6538\n5\nAfrica\n2441\n\n\nregime_type\n6538\n3\ndemocracy\n2803\n\n\n\n\n\n\n\n\ndat.groupby(['continent']).size()\n\ncontinent\nAfrica      2441\nAmericas    1311\nAsia        1387\nEurope      1285\nOceania      114\ndtype: int64\n\n\n\ndat.groupby(['country']).size().sort_values(ascending=False).head()\n\ncountry\nJordan       57\nIndonesia    57\nFrance       57\nGabon        57\nGhana        57\ndtype: int64\n\n\n\ndat.groupby(['regime_type']).size().sort_values(ascending=False).head()\n\nregime_type\ndemocracy                    2803\nauthoritarian                2227\ncompetitive authoritarian    1508\ndtype: int64"
  },
  {
    "objectID": "lecture_notes/week-06/lecture_10-data-exploration.html#visual-summaries",
    "href": "lecture_notes/week-06/lecture_10-data-exploration.html#visual-summaries",
    "title": "Data Exploration",
    "section": "Visual Summaries",
    "text": "Visual Summaries\n\nContinuous Variables\n\n# Rest the basic setup\nsns.set_context(\"notebook\", font_scale=1.5)\n\n# Set up a subplot using matplotlib\nf, axes = plt.subplots(2, 2, figsize=(15, 10))  # set up the \nplt.subplots_adjust(wspace = 0.5,hspace = 0.5) # increase the space between plots\n\n# assign a variable\nvar = dat[\"life_exp\"].dropna()\n\ng = sns.distplot(var,hist=True,kde=False,ax=axes[0,0])\ng.set_title(\"Histogram\")\n\ng = sns.kdeplot(var,shade=True,ax=axes[0,1],legend=False)\ng.set_title(\"Density Plot\")\n\ng = sns.rugplot(var,ax=axes[1,0])\ng.set_title(\"Rug Plot\")\n\ng = sns.distplot(var,hist=True,kde=True,ax=axes[1,1])\ng.set_title(\"Histogram + Density Plot\")\n\nplt.show()\n\n\n\n\n\nQ-Q Plots (quantile-quantile plots)\nCompares the empirical distribution to the theoretical distribution. In practice, how normally distributed is our empirical variable.\n\n# With a tehoretically perfectly distributed variable\nplt.figure(figsize=(8,8))\nx = np.random.normal(0,1,500)\n_ = stats.probplot(x, dist=\"norm\",plot=plt)\n\n\n\n\n\n# With our actual life expectancy variable \nplt.figure(figsize=(8,8))\n_ = stats.probplot(var, dist=\"norm\",plot=plt)\n\n\n\n\n\n\nHistograms\n\nplt.figure(figsize=(15,3))\ng = sns.distplot(dat[\"life_exp\"].dropna(),\n                 color=\"steelblue\",\n                 hist=True,kde=False)\n\n\n\n\nFor Histograms, bin size can yield a disparate pictures of a variable.\n\nplt.figure(figsize=(15,3))\ng = sns.distplot(dat[\"life_exp\"].dropna(),\n                 color=\"steelblue\",\n                 bins=5,\n                 hist=True,kde=False)\n\n\n\n\n\nplt.figure(figsize=(15,3))\ng = sns.distplot(dat[\"life_exp\"].dropna(),\n                 color=\"steelblue\",\n                 bins=100,\n                 hist=True,kde=False)\n\n\n\n\nUsing a combination of the matplotlib and seaborn libraries, we can easily generate subgraphs to plot many variables simultaneously.\n\nf, axes = plt.subplots(4, 2, figsize=(20, 15))\nplt.subplots_adjust(wspace = 0.5,hspace = 0.5) \n\nsns.distplot(dat[\"gdppc\"],\n             color=\"steelblue\",\n             hist=True,kde=False,ax=axes[0,0])\n\nsns.distplot(dat[\"pop\"],\n             color=\"forestgreen\",\n             hist=True,kde=False,ax=axes[0,1])\n\nsns.distplot(dat[\"infant_mort\"].dropna(),\n             color=\"darkred\",\n             hist=True,kde=False,ax=axes[1,0])\n\nsns.distplot(dat[\"life_exp\"].dropna(),\n             color=\"orange\",\n             hist=True,kde=False,ax=axes[1,1])\n\nsns.distplot(dat[\"life_exp_female\"].dropna(),\n             color=\"pink\",\n             hist=True,kde=False,ax=axes[2,0])\n\nsns.distplot(dat[\"life_exp_male\"].dropna(),\n             color=\"lightblue\",\n             hist=True,kde=False,ax=axes[2,1])\n\nsns.distplot(dat[\"polity\"].dropna(),\n             color=\"black\",\n             hist=True,kde=False,ax=axes[3,0])\nplt.show()\n\n\n\n\n\n\n\nScaling Continuous Variables\nOne thing that should instantly stand out is that the scales differ widely.\n\n# Looking at the QQ plot, we can see the variable is way off from being normally distributed. \nplt.figure(figsize=(8,8))  \nd, x = stats.probplot(dat[\"gdppc\"], dist=\"norm\",plot=plt)\n\n\n\n\n\nLog transformation\nWe can adjust the right skewed data with large tail values by taking the natural log of the variable.\n\n# Demonstrate what a log transformation does.\nx = np.linspace(0,10e8)\ny = np.log(x)\n\nplt.figure(figsize=(15,3))\ng = sns.lineplot(x,y)\n\n\n\n\n\nplt.figure(figsize=(15,3))\nx = np.log(dat[\"gdppc\"])\ng = sns.distplot(x,\n                 color=\"steelblue\",\n                 hist=True,kde=True)\n\n\n\n\n\n# From the QQ plot, we can see the variable appears more normally distributed once transformed. \nplt.figure(figsize=(8,8))  \nd, x = stats.probplot(np.log(dat[\"gdppc\"]), dist=\"norm\",plot=plt)\n\n\n\n\nLet’s create two new variables that takes the natural log of GDP per capita and Population.\n\ndat['lngdppc'] = np.log(dat['gdppc']) \ndat['lnpop'] = np.log(dat['pop'])\ndat.head(3)\n\n\n\n\n\n\n\n\nindex\ncountry\nccode\nyear\npolity\ngdppc\npop\ncontinent\nregime_type\ninfant_mort\nlife_exp\nlife_exp_female\nlife_exp_male\nmissing\nlngdppc\nlnpop\n\n\n\n\n0\n160\nAfghanistan\n700\n1960\n-10.0\n59.777327\n8996351.0\nAsia\nauthoritarian\nNaN\n32.446\n33.314\n31.718\nNo\n4.090626\n16.012330\n\n\n1\n161\nAfghanistan\n700\n1961\n-10.0\n59.878153\n9166764.0\nAsia\nauthoritarian\n236.5\n32.962\n33.840\n32.224\nNo\n4.092312\n16.031095\n\n\n2\n162\nAfghanistan\n700\n1962\n-10.0\n58.492874\n9345868.0\nAsia\nauthoritarian\n232.6\n33.471\n34.359\n32.724\nNo\n4.068905\n16.050445\n\n\n\n\n\n\n\n\n\nStandardizing\nStandardizes the distribution of the variable by setting the mean to 0 and the variance to 1. This transformation retains the original form of the empirical distribution.\n\ndef standardize(x): \n    return (x - x.mean())/x.std()\n\n\n# Sim Numbers\nx = np.linspace(0,10e8)\ny = standardize(x)\n\n\nplt.figure(figsize=(10,4))\nsns.scatterplot(x,y)\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9541239cc0&gt;\n\n\n\n\n\n\nplt.figure(figsize=(10,4))\nx = standardize(dat[\"gdppc\"])\ng = sns.distplot(x,\n                 color=\"steelblue\",\n                 hist=True,kde=False)\n\n\n\n\n\n\nScale by Empirical Range\nScales values so that they exist between 0 and 1, where 0 corresponds with the minimum value, and 1 corresponds with the maximum value. This transformation retains the original form of the empirical distribution.\n\ndef range_scale(x): \n    return (x - x.min())/(x.max()-x.min())\n\n# Sim Numbers\nx = np.linspace(0,10e8)\ny = range_scale(x)\n\nplt.figure(figsize=(10,4))\nsns.scatterplot(x,y)\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9581011c18&gt;\n\n\n\n\n\n\nplt.figure(figsize=(10,4))\nx = range_scale(dat[\"gdppc\"])\ng = sns.distplot(x,\n                 color=\"steelblue\",\n                 hist=True,kde=False)\n\n\n\n\n\n\n\nCategorical (Discrete) Variables\n\nplt.figure(figsize=(15,5))\ng = sns.countplot(y=\"regime_type\", data=dat)\n\n\n\n\n\nplt.figure(figsize=(15,8))\ng = sns.countplot(x=\"continent\",hue=\"regime_type\", data=dat)"
  },
  {
    "objectID": "lecture_notes/week-06/lecture_10-data-exploration.html#numerical-summaries-1",
    "href": "lecture_notes/week-06/lecture_10-data-exploration.html#numerical-summaries-1",
    "title": "Data Exploration",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\n\nContinuous Variables\n\nCorrelation\nExplore the linear relationship between two (or more) variables.\n\\[r_{xy} = \\frac{\\sum^i_N  (x_i - \\bar{x}) (y_i - \\bar{y}) }{ \\sqrt{\\sum^i_N  (x_i - \\bar{x})^2 (y_i - \\bar{y})^2  } }\\]\n\ndat['life_exp'].corr(dat['lngdppc']).round(2)\n\n0.83\n\n\n\n\nCorrelation Matrix\n\n# Expand out to a correlation matrx\ndat.loc[:,\"polity\":\"lnpop\"].corr().round(2)\n\n\n\n\n\n\n\n\npolity\ngdppc\npop\ninfant_mort\nlife_exp\nlife_exp_female\nlife_exp_male\nlngdppc\nlnpop\n\n\n\n\npolity\n1.00\n0.36\n0.03\n-0.55\n0.53\n0.55\n0.52\n0.46\n0.18\n\n\ngdppc\n0.36\n1.00\n-0.01\n-0.48\n0.55\n0.54\n0.56\n0.75\n0.08\n\n\npop\n0.03\n-0.01\n1.00\n-0.04\n0.07\n0.06\n0.08\n-0.03\n0.58\n\n\ninfant_mort\n-0.55\n-0.48\n-0.04\n1.00\n-0.94\n-0.95\n-0.93\n-0.80\n-0.16\n\n\nlife_exp\n0.53\n0.55\n0.07\n-0.94\n1.00\n1.00\n1.00\n0.83\n0.21\n\n\nlife_exp_female\n0.55\n0.54\n0.06\n-0.95\n1.00\n1.00\n0.99\n0.83\n0.21\n\n\nlife_exp_male\n0.52\n0.56\n0.08\n-0.93\n1.00\n0.99\n1.00\n0.83\n0.21\n\n\nlngdppc\n0.46\n0.75\n-0.03\n-0.80\n0.83\n0.83\n0.83\n1.00\n0.09\n\n\nlnpop\n0.18\n0.08\n0.58\n-0.16\n0.21\n0.21\n0.21\n0.09\n1.00\n\n\n\n\n\n\n\n\n\n\nCategorical (Discrete) Variables\nCrosstabs\n\npd.crosstab(dat.regime_type,dat.continent,margins=True)\n\n\n\n\n\n\n\ncontinent\nAfrica\nAmericas\nAsia\nEurope\nOceania\nAll\n\n\nregime_type\n\n\n\n\n\n\n\n\n\n\nauthoritarian\n1163\n249\n633\n182\n0\n2227\n\n\ncompetitive authoritarian\n808\n261\n377\n62\n0\n1508\n\n\ndemocracy\n470\n801\n377\n1041\n114\n2803\n\n\nAll\n2441\n1311\n1387\n1285\n114\n6538\n\n\n\n\n\n\n\nCross tabs represented as proportions\n\n# By Rows\npd.crosstab(dat.regime_type,dat.continent).apply(lambda x: x/x.sum(), axis=1).round(3)\n\n\n\n\n\n\n\ncontinent\nAfrica\nAmericas\nAsia\nEurope\nOceania\n\n\nregime_type\n\n\n\n\n\n\n\n\n\nauthoritarian\n0.522\n0.112\n0.284\n0.082\n0.000\n\n\ncompetitive authoritarian\n0.536\n0.173\n0.250\n0.041\n0.000\n\n\ndemocracy\n0.168\n0.286\n0.134\n0.371\n0.041\n\n\n\n\n\n\n\n\n# By Columns\npd.crosstab(dat.regime_type,dat.continent).apply(lambda x: x/x.sum(), axis=0).round(3)\n\n\n\n\n\n\n\ncontinent\nAfrica\nAmericas\nAsia\nEurope\nOceania\n\n\nregime_type\n\n\n\n\n\n\n\n\n\nauthoritarian\n0.476\n0.190\n0.456\n0.142\n0.0\n\n\ncompetitive authoritarian\n0.331\n0.199\n0.272\n0.048\n0.0\n\n\ndemocracy\n0.193\n0.611\n0.272\n0.810\n1.0\n\n\n\n\n\n\n\n\n\nCategorical + Continuous\n\ndat.groupby(['continent'])['gdppc'].mean().sort_values(ascending=False)\n\ncontinent\nOceania     17352.233249\nEurope      16050.537032\nAsia         5116.408798\nAmericas     4281.519876\nAfrica       1106.908969\nName: gdppc, dtype: float64\n\n\n\ndat.groupby(['country'])['lnpop'].mean().sort_values(ascending=False).head(5).round(2)\n\ncountry\nChina            20.77\nIndia            20.51\nUnited States    19.32\nIndonesia        18.92\nBrazil           18.73\nName: lnpop, dtype: float64"
  },
  {
    "objectID": "lecture_notes/week-06/lecture_10-data-exploration.html#visual-summaries-1",
    "href": "lecture_notes/week-06/lecture_10-data-exploration.html#visual-summaries-1",
    "title": "Data Exploration",
    "section": "Visual Summaries",
    "text": "Visual Summaries\n\nContinuous Variables\nscatter plot\n\nplt.figure(figsize=(15,5))\nsns.scatterplot(x=\"lngdppc\",y=\"infant_mort\",alpha=.6,data=dat)\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9520cbf1d0&gt;\n\n\n\n\n\n\nplt.figure(figsize=(10,7))\n\n# Summarize data \nd = (dat\n     .groupby(['country'])\n     .mean()\n     .reset_index())\n \n# plot relationship\ng = sns.scatterplot(x=\"lngdppc\",\n                    y=\"infant_mort\",\n                    size='lnpop',\n                    hue = 'lnpop',\n                    sizes=(10, 300),\n                    data=d)\n\n\n\n\nLine plot\n\nplt.figure(figsize=(15,3))\nsns.lineplot(x=\"year\",y=\"polity\",data=dat.query(\"country == 'Nigeria'\"))\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f94d0181160&gt;\n\n\n\n\n\n\nUnivariate and Bivariate Together\n\nsns.jointplot(x=\"lngdppc\",y=\"infant_mort\",data=dat,\n              height=10)\n\n\n\n\n\n\nFitting the relationship\n\n# Regression line \nplt.figure(figsize=(15,5))\ng = sns.regplot(x=\"lngdppc\",y=\"infant_mort\",\n                scatter_kws={'alpha':0.1},\n                data=dat)\n\n\n\n\n\n# Higher order regression line: x + x^2\nplt.figure(figsize=(15,5))\ng = sns.regplot(x=\"lngdppc\",y=\"infant_mort\",\n                scatter_kws={'alpha':0.05},\n                order=2,\n                data=dat)\n\n\n\n\n\n# Lowess (locally weighted linear) regression\nplt.figure(figsize=(15,5))\ng = sns.regplot(x=\"lngdppc\",y=\"infant_mort\",\n                scatter_kws={'alpha':0.05},\n                lowess=True,\n                data=dat)\n\n\n\n\n\n# Regression by Grouping \nplt.figure(figsize=(15,5))\ng = sns.lmplot(x=\"lngdppc\",y=\"infant_mort\",\n                hue=\"continent\",\n                scatter_kws={'alpha':0.1},\n                height=10,\n                data=dat)\n\n&lt;Figure size 1080x360 with 0 Axes&gt;\n\n\n\n\n\n\n\nHeatmaps\n\n# Generate a correlation matrix \ncorr_mat = dat.loc[:,[\"polity\",\"infant_mort\",\"life_exp\",\"lngdppc\",\"lnpop\"] ].corr()\n\n# Generate a heatmap\nplt.figure(figsize=(15,10))\nsns.heatmap(corr_mat,\n            center=0,\n            linewidths=.5)\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9532854358&gt;\n\n\n\n\n\n\n\nPair Plots\n\nd = dat[['lngdppc','lnpop','polity',\"life_exp\"]].dropna()\n\ng = sns.PairGrid(d,height=7)\ng = g.map_diag(plt.hist)\ng = g.map_offdiag(plt.scatter)\n\n\n\n\n\n\n\nCategorical (Discrete) Variables\n\nd = dat.groupby(['continent','regime_type']).size().reset_index().rename(columns={0:''})\nd = d.pivot_table(columns=\"continent\",index='regime_type')\n\nplt.figure(figsize=(15,10))\nsns.heatmap(d,linewidths=.5,cmap=\"YlGnBu\")\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f95717ed9b0&gt;\n\n\n\n\n\n\n\nCategorical (Discrete) Variables + Continuous Variables\n\ng = sns.catplot(y=\"regime_type\", x=\"lngdppc\",\n                kind=\"violin\",\n                height=10,aspect=2,\n                data=dat)\n\n\n\n\n\ng = sns.catplot(y=\"regime_type\", x=\"lngdppc\", \n                kind=\"box\",\n                height=10,aspect=2,\n                data=dat)\n\n\n\n\n\ng = sns.catplot(y=\"regime_type\", x=\"lngdppc\", \n                height=10,aspect=2,\n                data=dat)\n\n\n\n\n\ng = sns.catplot(y=\"regime_type\", x=\"lngdppc\",\n                kind=\"bar\",\n                height=10,aspect=2,\n                data=dat)"
  },
  {
    "objectID": "lecture_notes/week-01/intro-to-quarto.html",
    "href": "lecture_notes/week-01/intro-to-quarto.html",
    "title": "Week 1: Introduction to Quarto for Python",
    "section": "",
    "text": "The purpose of this notebook is to show case the use of Quarto notebooks. It will cover:\n\nBrief introduction to Quarto Notebooks\nRunning R with Quarto Notebooks\nRunning Python with Quarto Notebooks + reticulate\n\nSee Quarto’s website for a more in-depth coverage of the framework."
  },
  {
    "objectID": "lecture_notes/week-01/intro-to-quarto.html#my-personal-tldr-about-quarto",
    "href": "lecture_notes/week-01/intro-to-quarto.html#my-personal-tldr-about-quarto",
    "title": "Week 1: Introduction to Quarto for Python",
    "section": "My personal TLDR about Quarto",
    "text": "My personal TLDR about Quarto\nQuarto was developed by Posit (the new name of RStudio). It represents the effort of RStudio to become a language agnostic IDE for Data Science.\nQuarto main promise is to allow data scientists to run many different languages using the same notebook structure. For the purpose of our course, we will use mostly Jupyter Notebooks, since those are still dominant among Python developers.\nAs you are learning Python and R at the same time throughout your DSPP courses, I advice you to take a look at Quarto. You might find it a useful tool to run both R and Python."
  },
  {
    "objectID": "lecture_notes/week-01/intro-to-quarto.html#quick-tutorial-for-rstudio",
    "href": "lecture_notes/week-01/intro-to-quarto.html#quick-tutorial-for-rstudio",
    "title": "Week 1: Introduction to Quarto for Python",
    "section": "Quick tutorial for RStudio",
    "text": "Quick tutorial for RStudio\nThis is what RStudio looks like when you open it for the first time.\n\n\n\n\n\nTop left pane (input/script)\nThis is your code editor. Here you enter code in any file type (.py, .r, .qmd) you are working on. If not working with notebooks, this is just gonna be a plain text file but with a extension that run the commands.\nFor example, enter 2 + 2 in your script and run a line of code by pressing command + enter (Mac) or Ctrl + enter (PC). This is a huge advantage of Rstudio over Jupyter. You can run your code line by line, instead of running the entire cell.\nBottom left pane (output/console)\nThis is the console. It is pretty much like when you open Python/R from the Command line.\nIn the console, the prompt &gt; looks like a greater than symbol. If your prompt begins to look like a + symbol by mistake, simply click in your console and press the esc key on your keyboard as many times as necessary to return to the prompt.\nRstudio uses + when code is broken up across multiple lines and is still expecting more code. A line of code does not usually end until Rstudio finds an appropriate stop parameter or punctuation that completes some code such as a closed round parenthesis ), square bracket ], curly brace }, or quotation mark '.\nIf the output in your console gets too messy, you can clear it by pressing control + l on both Mac and PC. This will not erase any saved data - it will simply make your console easier to read.\nTop right pane (global environment)\nThis is your environment pane. All objects you create will be displayed here.\nBottom right pane (files, plots, packages, and help)\nHere you find useful tabs for navigating your file system, displaying plots, installing packages, and viewing help pages. Press the control key and a number (1 through 9) on your keyboard to shortcut between these panes and tabs."
  },
  {
    "objectID": "lecture_notes/week-01/minimal_example_python.html",
    "href": "lecture_notes/week-01/minimal_example_python.html",
    "title": "Minimal Example Python",
    "section": "",
    "text": "Here you add your text as markdown."
  },
  {
    "objectID": "lecture_notes/week-01/minimal_example_python.html#minimal-example-of-using-python-with-quarto",
    "href": "lecture_notes/week-01/minimal_example_python.html#minimal-example-of-using-python-with-quarto",
    "title": "Minimal Example Python",
    "section": "",
    "text": "Here you add your text as markdown."
  },
  {
    "objectID": "lecture_notes/week-01/minimal_example_python.html#code",
    "href": "lecture_notes/week-01/minimal_example_python.html#code",
    "title": "Minimal Example Python",
    "section": "Code",
    "text": "Code\nYou will use the same code block for any language. You just need to change language inside of the brackets {}\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\nimport math\n\nmu = 0\nvariance = 1\nsigma = math.sqrt(variance)\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\nplt.plot(x, stats.norm.pdf(x, mu, sigma))\nplt.show()"
  },
  {
    "objectID": "weeks/week-14.html",
    "href": "weeks/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-03.html",
    "href": "weeks/week-03.html",
    "title": "Week 03",
    "section": "",
    "text": "Intro to Python - OOP, Data Types, and Collectors: html,  Jupyter Notebook \nIntro to Python II - Control Statements and Functions: html,  Jupyter Notebook"
  },
  {
    "objectID": "weeks/week-03.html#lectures-notes",
    "href": "weeks/week-03.html#lectures-notes",
    "title": "Week 03",
    "section": "",
    "text": "Intro to Python - OOP, Data Types, and Collectors: html,  Jupyter Notebook \nIntro to Python II - Control Statements and Functions: html,  Jupyter Notebook"
  },
  {
    "objectID": "weeks/week-03.html#slides",
    "href": "weeks/week-03.html#slides",
    "title": "Week 03",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "weeks/week-03.html#required-readings",
    "href": "weeks/week-03.html#required-readings",
    "title": "Week 03",
    "section": "Required Readings",
    "text": "Required Readings\nFrom Miller, Brad, and David Ranum, Problem Solving with Algorithms and Data Structures using Python\n\nGetting Started with Data\nControl Structure\nException Handling\nDefining Functions\n\nFrom Wes McKinney, Python for Data Analysis\n\nChapter 2: Python Language Basics, IPython, and Jupyter Notebooks\nChapter 2: Built-In Data Structures, Functions, and Files\n\nMutable vs Immutable Objects in Python - Mohan, Megha"
  },
  {
    "objectID": "weeks/week-03.html#additional-code",
    "href": "weeks/week-03.html#additional-code",
    "title": "Week 03",
    "section": "Additional Code",
    "text": "Additional Code\n\nData Carpentry\n\nPython Fundamentals\nRepeated Actions with Loops\nMaking Choices\nCreating Functions\nStoring Multiple Values in Lists"
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\nTBD\n\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-07.html",
    "href": "weeks/week-07.html",
    "title": "Week 07",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-05.html#slides",
    "href": "weeks/week-05.html#slides",
    "title": "Week 05",
    "section": "Slides",
    "text": "Slides\nTBD"
  },
  {
    "objectID": "weeks/week-05.html#readings",
    "href": "weeks/week-05.html#readings",
    "title": "Week 05",
    "section": "Readings",
    "text": "Readings\nSuggested Readings"
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-09.html",
    "href": "weeks/week-09.html",
    "title": "Week 09",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-08.html",
    "href": "weeks/week-08.html",
    "title": "Week 08",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-04.html#slides",
    "href": "weeks/week-04.html#slides",
    "title": "Week 04",
    "section": "Slides",
    "text": "Slides\n\nTBD"
  },
  {
    "objectID": "weeks/week-04.html#readings",
    "href": "weeks/week-04.html#readings",
    "title": "Week 04",
    "section": "Readings",
    "text": "Readings"
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Lectures Notes:\n\n\nSlides\n\n\nReadings"
  },
  {
    "objectID": "weeks/week-06.html",
    "href": "weeks/week-06.html",
    "title": "Week 06",
    "section": "",
    "text": "Lectures Notes:\n\n\n\nSlides\n\n\n\nReadings\n\nRequired Readings\n\nTheory\n\nCh. 2: Visualizing data: Mapping data onto aesthetics - Fundamentals of Data Visualization - Wilke, Claus\nCh. 4: Color scales - Fundamentals of Data Visualization - Wilke, Claus\nCh. 5: Directory of Visualizations - datviz\n\nIn-Practice\n\nMaking Plots With plotnine - i.e. ggplot in Python\nCh. 4: Visualization with Matplotlib - Python Data Science Handbook - VanderPlas, Jake - i.e. matplotlib and seaborn libraries\n\nGrammar of Graphics: How ggplot works by Kieran Healy\n\n\n\n\nAdditional Resources and Suggested Materials\n\nThe Python Graph Gallery\nBokeh - For interactive Graphics\n\nBokeh User Guide\nBokeh Tutorial\n\n\nEither Fundamentals of Data Visualization - Wilke, Claus or Data Visualization: A practical introduction by Kieran Healy are amazing sources you can consult frequently"
  },
  {
    "objectID": "weeks/week-02.html",
    "href": "weeks/week-02.html",
    "title": "Week 02",
    "section": "",
    "text": "Lecture Notes\n\nVersion Control, Workflow and Reproducibility: Or a bit of Git & GitHub: html,  notebook \n\n\n\nSlides\n\nVersion Control, Workflow and Reproducibility: Or a bit of Git & GitHub\n\n\n\n\n\nReadings\nRequired Readings\n\nThe Plain Person’s Guide to Plain Text Social Science - Healy, Kieran\n\nCh. 1: Introduction;\nCh. 2: Keep a Record;\nCh. 3: Write and Edit;\nCh. 4: Reproduce Work.\n\nPro Git - Chacon & Straub\n\nCh. 1: Getting Started; Read 1.1 - 1.3\nCh. 2: Git Basics; Only read 2.1 - 2.5\nCh. 3: Git Branching\n\n\nAdditional Resources and Suggested Materials\n\nMore on Git/Github in Pro Git:\n\nRead 1.4 - 1.7 for help on installation and commandline\nRead Ch. 6 for more information regarding Git + Github.\n\nCh. 13 Detect Git from RStudio -Happy Git with R - Bryan, Jenny & Jim Hester"
  },
  {
    "objectID": "weeks/week-01.html",
    "href": "weeks/week-01.html",
    "title": "Week 01",
    "section": "",
    "text": "Lectures Notes:\n\nInstructions for setting up the course infra-structure.\nUsing Jupyter Notebooks: html,  notebook \nUsing Quarto for Python and R html,  notebook \nBasics of Command Line: html,  notebook \n\n\n\nSlides\n\nWeek 01:Introduction, Installations, IDEs, Command line\n\n\n\nReadings\nThe readings for this week will be a mix of:\nA more general introduction to data science from a applied perspective (which you can call Data Science and Public Policy, Data Science for Public Good, or Computational Social Science in academic spaces)\nRequired Readings\n\nBit by Bit: Social Research in the Digital Age By Mathew Salganik\nIntroduction\nObserving Behavior\nA Three-Step Guide to Training Computational Social Science Ph.D. Students for Academic and Non-Academic Careers - By Aniket Kesari, Jae Yeon Kim, Sono Shah, Taylor Brown, Tiago Ventura and Tina Law\n\nBest Practices in Programming, IDEs and Files Management:\nRequired Readings\n\nJupyter Notebook for Beginners: A tutorial Pryke, Benjamin - www.dataquest.io\nUsing Python with RStudio and reticulate: here and here\n\nAdditional\n\nMore on RStudio + Reticulate\nR & Python: A Love Storsy - rstudio.com\nRStudio 1.2 Preview: Reticulated Python\nOn using LaTex to write math in markdown - docx2latex.com"
  },
  {
    "objectID": "problemset.html",
    "href": "problemset.html",
    "title": "Problem Sets",
    "section": "",
    "text": "Problem Set\n\n\nContent\n\n\nDate Assigned\n\n\nDue Date\n\n\n\n\n\n\nProblem Set 1\n\n\nVersion Control, Workflow and Reproducibility: Or a bit of Git & GitHub\n\n\n09/12/2023\n\n\nBefore EOD Friday Week 3\n\n\n\n\nProblem Set 02\n\n\nCore Programming Concepts in Python\n\n\n09/26/2023\n\n\nBefore EOD Friday Week 5\n\n\n\n\nProblem Set 03\n\n\nData Wrangling in Pandas\n\n\n10/10/2023\n\n\nBefore EOD Friday Week 7\n\n\n\n\nProblem Set 04\n\n\nUnestructure data, Scrapping, and more pandas\n\n\n10/24/2023\n\n\nBefore EOD Friday Week 9\n\n\n\n\nProblem Set 05\n\n\nWorking with text data\n\n\n11/07/2023\n\n\nBefore EOD Friday Week 11\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lecture_notes/week-01/course_infrastructure.html",
    "href": "lecture_notes/week-01/course_infrastructure.html",
    "title": "Week 1: Course Infrastructure",
    "section": "",
    "text": "Throughout the semester, we will use a combination of tools. This a summary of the main tools:\n\nCommandLine: primarily to interact with git, install programs and run a few scripts\nPython3: for programming taks\nGit/Github: for version control, reproucibility and for sharing materials\nJupyter Notebooks: as a main IDE to work with Python\nQuarto via RStudio: as a secondary IDE (you can make your primary if you prefer) to coding in Python/R/SQL\nSlack: for communication.\n\nLet’s cover how to set up each of these tools in your local machines.\n\n\n\n\n\n\nWarning\n\n\n\nIf you run into issues, please reach out to the Teaching Assistant for assistance\n\n\n\n\nAt times, we’ll use a unix-based commandline. The commandline will feature into our discussion on using git and also running Python programs. If you use a Mac or a Linux operating system, then a functioning commandline comes with your operating system. For Apple machines, this is the Terminal.\nFor Windows (specifically Windows 10), you can enable Linux Bash shell. The following offers a tutorial on how to do this.\nIf you’re using a version of Windows that pre-dates version 10, then Git Bash offers a program will allow you to use git commands from your windows machine.\nLater in the first class, we will cover some concepts of working with the commandline. You can get a full notebook with a intro to commandline in the materials for week 1\n\n\n\nWe’ll use Python3 throughout this course. Below are instructions for downloading Python3 using commandline packages manager (Homebrew for mac, Chocolatey for windows).\n\nInstalling Python3 using Homebrew on a Mac (Apple)\nInstalling Python3 using Chocolatey on a PC (Windows)\n\nAn alternative way to install Python3 is to download an Anaconda distribution. I will use pip rather than conda in the instruction for downloading Python modules. These are simply two ways of downloading and managing open-source software packages. Choose which ever works best for you\nMost computers already have python3 installed. You can check if that is your case through your commandline\npython3 --version\nOn some versions of Windows, you may need to use py instead of python3:\npy --version\nIn either case, the output of this command should be something like Python 3.8.5\n\n\n\nOnce you have Python3 on your computer, you can install a Jupyter Notebook. If you downloaded Python3 using Anaconda, then Jupyter Notebook comes with the distribution and requires no further installation on your part. If you are not using Anaconda, you can install Jupyter notebook running the following code using your commandline.\n# on your command line\npip install jupyter\nYou can then activate a Jupyter Notebook from the commandline by typing:\n# on your command line\njupyter notebook\n\n\nHere is my workflow to open Jupyter Notebooks using the commandline.\n\nOpen the terminal\nNavigate (using cd) to the folder you want to be the root of your jupyter notebook\nOpen the notebook (jupyter notebook)\n\nIt looks like this if I were to open a notebook in the folder I have for this course\n# open terminal\ncd ppol_5203\njupyter notebook\n\n\n\nIf you installed Python using Anaconda distribution system (here: https://www.anaconda.com/products/individual). You can open Jupyter through a point-and-click system. It take forever, but it works!\nIn the lecture notes, you can also find a Introduction to Jupyter notebook. We will cover this in the first class of the course.\n\n\n\n\nA quick digression of the R vs Python debate\nFor some of your classes in the Data Science and Public Policy Masters, you will be using R. Some data scientists and computational social scientists have strong beleifs as to which langugae is better. I, and the DSPP faculty, do not subscribe to that view. Most techniques that are relevent for applied data science can be done in either language.\nIn my personal opinion, R outperforms Python in data manipulation tasks, visualization and statistical modeling. This is because R started out as a statistical programming environment, and that heritage is still visible. Meanwhile, Python started our a general purpose programming language, which was heavily adopted by computer scientists, which means Python outperforms on abstraction, machine learning tasks, working with more complex data types.\nMost importantly, you will be using more one language compared to the other conditional on your career path and the type of tasks you end up working with. If you end up in a team full of computer scientists, it is more likely Python will be your favored language. If you move to work more with social scientists, R will probably be more heavily used. There is no need to chose now. Learn both and broad your horizons. As general programming languages, learning both requires almost the same amount of effort of learning one in isolation.\nBack to the course infrastructure\nIn your classes that are focused on using R, RStudio will be your main IDE. However, RStudio isn’t just for R. It can handle a number of different languages. We can use Python in RStudio using the reticulate package.\nI create a full notebook to teach you how to use Python in Rstudio. Check the intro do quarto notebook. Let’s cover some of the installation steps here:\nTo install RStudio, download from the following link . reticulate is an R package that allows one run a Python REPL in the R console. In addition, it allows one to read in and use Python code, and pass data between R and and Python. The following provides instructions on installing reticulate.\nWith reticulate, you can use Rstudio as a IDE for Python. Another option is to use Quarto (the next-generation version of R Markdown) as an unified framework to generate notebooks with text + code. If you’re an R Markdown user, you will see how Quarto is just an extension of the capabilities that were previously provided by R Markdown. Now, instead of .rmd files, we have .qmd files. Quarto is already installed with RStudio.\n\n\n\nWe’ll go over more Git/GitHub instructions during the second class session. Before that session:\n\nInstall Git if it’s not installed already\nCreate a GitHub account if you don’t have one already (any email and free subscription is fine)\n\n\n\n\nOur course will make use of Slack for internal communication. Enter in our workspace with this link: (https://join.slack.com/t/ppol5203fall2023/shared_invite/zt-1z99dee8l-jxY3HCwfEkxY1H6ZUNedEA).\nWhen should you use slack?\n\nInteract with the TAs\nAsk questions to your colleagues\nShare links that are interesting to the discussions in class.\n\nWhen I should not use slack?\n\nIf you have a question you believe will require a longer conversation, I prefer if you can stop by at my office hours\n\nRemember, you don’t need to let me know you are going to my office hours. Just stop by!\nIf you’re new to Slack, check out this tutorial. In the first class, I’ll send out the invitation for everyone to join Slack and we’ll discuss how to use it."
  },
  {
    "objectID": "lecture_notes/week-01/course_infrastructure.html#commandline",
    "href": "lecture_notes/week-01/course_infrastructure.html#commandline",
    "title": "Week 1: Course Infrastructure",
    "section": "",
    "text": "At times, we’ll use a unix-based commandline. The commandline will feature into our discussion on using git and also running Python programs. If you use a Mac or a Linux operating system, then a functioning commandline comes with your operating system. For Apple machines, this is the Terminal.\nFor Windows (specifically Windows 10), you can enable Linux Bash shell. The following offers a tutorial on how to do this.\nIf you’re using a version of Windows that pre-dates version 10, then Git Bash offers a program will allow you to use git commands from your windows machine.\nLater in the first class, we will cover some concepts of working with the commandline. You can get a full notebook with a intro to commandline in the materials for week 1"
  },
  {
    "objectID": "lecture_notes/week-01/course_infrastructure.html#python3",
    "href": "lecture_notes/week-01/course_infrastructure.html#python3",
    "title": "Week 1: Course Infrastructure",
    "section": "",
    "text": "We’ll use Python3 throughout this course. Below are instructions for downloading Python3 using commandline packages manager (Homebrew for mac, Chocolatey for windows).\n\nInstalling Python3 using Homebrew on a Mac (Apple)\nInstalling Python3 using Chocolatey on a PC (Windows)\n\nAn alternative way to install Python3 is to download an Anaconda distribution. I will use pip rather than conda in the instruction for downloading Python modules. These are simply two ways of downloading and managing open-source software packages. Choose which ever works best for you\nMost computers already have python3 installed. You can check if that is your case through your commandline\npython3 --version\nOn some versions of Windows, you may need to use py instead of python3:\npy --version\nIn either case, the output of this command should be something like Python 3.8.5"
  },
  {
    "objectID": "lecture_notes/week-01/course_infrastructure.html#jupyter-notebooks",
    "href": "lecture_notes/week-01/course_infrastructure.html#jupyter-notebooks",
    "title": "Week 1: Course Infrastructure",
    "section": "",
    "text": "Once you have Python3 on your computer, you can install a Jupyter Notebook. If you downloaded Python3 using Anaconda, then Jupyter Notebook comes with the distribution and requires no further installation on your part. If you are not using Anaconda, you can install Jupyter notebook running the following code using your commandline.\n# on your command line\npip install jupyter\nYou can then activate a Jupyter Notebook from the commandline by typing:\n# on your command line\njupyter notebook\n\n\nHere is my workflow to open Jupyter Notebooks using the commandline.\n\nOpen the terminal\nNavigate (using cd) to the folder you want to be the root of your jupyter notebook\nOpen the notebook (jupyter notebook)\n\nIt looks like this if I were to open a notebook in the folder I have for this course\n# open terminal\ncd ppol_5203\njupyter notebook\n\n\n\nIf you installed Python using Anaconda distribution system (here: https://www.anaconda.com/products/individual). You can open Jupyter through a point-and-click system. It take forever, but it works!\nIn the lecture notes, you can also find a Introduction to Jupyter notebook. We will cover this in the first class of the course."
  },
  {
    "objectID": "lecture_notes/week-01/course_infrastructure.html#rstudio-reticulatequarto",
    "href": "lecture_notes/week-01/course_infrastructure.html#rstudio-reticulatequarto",
    "title": "Week 1: Course Infrastructure",
    "section": "",
    "text": "A quick digression of the R vs Python debate\nFor some of your classes in the Data Science and Public Policy Masters, you will be using R. Some data scientists and computational social scientists have strong beleifs as to which langugae is better. I, and the DSPP faculty, do not subscribe to that view. Most techniques that are relevent for applied data science can be done in either language.\nIn my personal opinion, R outperforms Python in data manipulation tasks, visualization and statistical modeling. This is because R started out as a statistical programming environment, and that heritage is still visible. Meanwhile, Python started our a general purpose programming language, which was heavily adopted by computer scientists, which means Python outperforms on abstraction, machine learning tasks, working with more complex data types.\nMost importantly, you will be using more one language compared to the other conditional on your career path and the type of tasks you end up working with. If you end up in a team full of computer scientists, it is more likely Python will be your favored language. If you move to work more with social scientists, R will probably be more heavily used. There is no need to chose now. Learn both and broad your horizons. As general programming languages, learning both requires almost the same amount of effort of learning one in isolation.\nBack to the course infrastructure\nIn your classes that are focused on using R, RStudio will be your main IDE. However, RStudio isn’t just for R. It can handle a number of different languages. We can use Python in RStudio using the reticulate package.\nI create a full notebook to teach you how to use Python in Rstudio. Check the intro do quarto notebook. Let’s cover some of the installation steps here:\nTo install RStudio, download from the following link . reticulate is an R package that allows one run a Python REPL in the R console. In addition, it allows one to read in and use Python code, and pass data between R and and Python. The following provides instructions on installing reticulate.\nWith reticulate, you can use Rstudio as a IDE for Python. Another option is to use Quarto (the next-generation version of R Markdown) as an unified framework to generate notebooks with text + code. If you’re an R Markdown user, you will see how Quarto is just an extension of the capabilities that were previously provided by R Markdown. Now, instead of .rmd files, we have .qmd files. Quarto is already installed with RStudio."
  },
  {
    "objectID": "lecture_notes/week-01/course_infrastructure.html#git",
    "href": "lecture_notes/week-01/course_infrastructure.html#git",
    "title": "Week 1: Course Infrastructure",
    "section": "",
    "text": "We’ll go over more Git/GitHub instructions during the second class session. Before that session:\n\nInstall Git if it’s not installed already\nCreate a GitHub account if you don’t have one already (any email and free subscription is fine)"
  },
  {
    "objectID": "lecture_notes/week-01/course_infrastructure.html#slack",
    "href": "lecture_notes/week-01/course_infrastructure.html#slack",
    "title": "Week 1: Course Infrastructure",
    "section": "",
    "text": "Our course will make use of Slack for internal communication. Enter in our workspace with this link: (https://join.slack.com/t/ppol5203fall2023/shared_invite/zt-1z99dee8l-jxY3HCwfEkxY1H6ZUNedEA).\nWhen should you use slack?\n\nInteract with the TAs\nAsk questions to your colleagues\nShare links that are interesting to the discussions in class.\n\nWhen I should not use slack?\n\nIf you have a question you believe will require a longer conversation, I prefer if you can stop by at my office hours\n\nRemember, you don’t need to let me know you are going to my office hours. Just stop by!\nIf you’re new to Slack, check out this tutorial. In the first class, I’ll send out the invitation for everyone to join Slack and we’ll discuss how to use it."
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html",
    "href": "lecture_notes/week-06/week-6-data-visualization.html",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "PPOL 5203 Data Science I: Foundations   Data Visualization Tiago Ventura"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#aesthetics",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#aesthetics",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "The key aspect on data visualization is to take data points and convert them visual elements.\n\nAll data visualizations map data values into quantifiable features of the resulting graphic. We refer to these features as aesthetics. Fundamentals of Data Visualization, Claus Wilke\n\nBelow you can see some commonly used aesthetics in data visualization:\n\n\n\n\nsource: Fundamentals of Data Visualization, Claus Wilke"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#cartesian-coordinates-system",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#cartesian-coordinates-system",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "Most often we will use a 2d cartesian coordinate system to present our graphs. Humans can very easily understand information in two dimensions, and our work will very often consist on mapping data into X and Y axis."
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#adding-a-3rd-4th-5th-variable-in-a-2d-space",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#adding-a-3rd-4th-5th-variable-in-a-2d-space",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "However, most often, we want to add more variables to a 2d space. For example, we might want to:\n\ndistinguish discrete items or groups that do not have an intrinsic order\nhighlight values that pass a certain threeshold\nAdd a sequential data value in the graph\n\nThose are all data points. If we want to represent them in a 2d graph, we need to map them in new aesthetics. Let’s show examples with the a few different aesthethics"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#data-types-drives-visualization-decisions",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#data-types-drives-visualization-decisions",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "Data Type\nExample\nScale\n\n\n\n\nNumerical\n1.3, 800, 10e3\nContinuous\n\n\nInteger\n1, 2, 3\nDiscrete (when \\(n\\) is small), Continuous (when \\(n\\) is large)\n\n\nCategorical\n“dog”, “Nigeria”, “A”\nDiscrete\n\n\nOrdered\n“Small”, “Medium”, “Large”\nDiscrete\n\n\nDates/Time\n2009-01-02, 5:32:33\nContinuous\n\n\n\n\n###\n\nDiscrete Values\n\n\n \n\n###\n\nContinuous Values\n\n\n\n\n###\n\nRelationships"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#grammar-of-graphics",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#grammar-of-graphics",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "According to ChatGPT, a “Grammar is the set of structural rules that dictate how words in a language can be combined to form meaningful sentences. These rules determine how phrases and sentences are constructed in a particular language.””\nThe grammar of graphics, as the name says, brings a similar effort to establish structural rules to data visualizations. This idea of building a grammar of graphics was first developed by Leland Wilkinson’s book “The Grammar of Graphics”. The grammar of graphics is about breaking down graphs into these consistent components, allowing for a systematic and structured approach to creating a wide variety of visualizations.\nOne of the most well-known implementations of the grammar of graphics is the ggplot2 package in the R programming language, developed by Hadley Wickham. ggplot2 breakes the grammar of graphics layer by layer\nNative libraries in Python do not use this framework. However, for the reasons explain before, we will focus on this framework in our class, which has been implemented with the library plotnine. plotnine offers an emulator for the powerful ggplot2 graphics package from R\n\n\nplotnine/ggplot2 graphs have three key steps\n\nData step: The raw information you wish to visualize.\nAesthetics step: How you map variables in your data to visual properties of geoms, like x and y position, color, size, shape, etc\nGeometric Representations step: The visual representations of data points (bars, points, lines, histograms etc..)\n\nThis all you need to build you graphs. In addition, there are other components you will eventually use to adjust your data visualization\n\nFacets: to produce create subplots based on specific variable\nannotations: labels, titles, subtitles, captions.\nCoordinates & Scales: some additional functions to adjust aesthetics you are mapping (change colors, size, alpha, scale of x and y coordinates)\nTheme: Control the finer presentation details like font size, background color, grid line styles, etc."
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#in-practice-plotnine",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#in-practice-plotnine",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "Let’s first open the gapminder dataset, a subset of the original data set from (http://gapminder.org). For each of 142 countries, it provides values for life expectancy, GDP per capita, and population, every five years, from 1952 to 2007.\n\nimport pandas as pd\nimport numpy as np\nfrom plotnine import * # to imitate ggplot\nfrom gapminder import gapminder # bring data\n\nimport warnings\nwarnings.filterwarnings('ignore') # Ignore warnings\n\n# Read in data \ngapminder.head()\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n\n\n\n\n\n\n\n\n# create to new log variables\ngapminder = (gapminder\n       .assign(lngdpPercap = np.log(gapminder[\"gdpPercap\"]), \n               lnpop = np.log(gapminder[\"pop\"]))\n      )"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#three-key-steps-with-plotnine",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#three-key-steps-with-plotnine",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "# build in plotnine graph\n\n# step 1: data\n(ggplot(data=gapminder) + \n\n# step 2: geom\n geom_point(\n\n# step 3: aesthethics\n     aes(x=\"lngdpPercap\", y=\"lifeExp\"))\n)\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n# you can either easily change the geometric representations\n# step 1: data\n(ggplot(data=gapminder) + \n\n# step 2: geom\n geom_smooth(\n\n# step 3: aesthethics\n     aes(x=\"lngdpPercap\", y=\"lifeExp\"))\n)\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# you can either easily change the geometric representations\n# step 1: data\n(ggplot(data=gapminder) + \n\n# step 2: geom\n geom_smooth(\n\n# step 3: aesthethics\n     aes(x=\"lngdpPercap\", y=\"lifeExp\")) +\n \n# new geometric representation\ngeom_point(\n     aes(x=\"lngdpPercap\", y=\"lifeExp\")) \n \n)\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# you can either easily change the geometric representations\n# step 1: data\n(ggplot(data=gapminder) + \n\n# step 2: geom\n geom_smooth(\n\n# step 3: aesthethics as variable\n     aes(x=\"lngdpPercap\", y=\"lifeExp\", color=\"continent\")) +\n \n# aesthetics as values\ngeom_point(\n     aes(x=\"lngdpPercap\", y=\"lifeExp\"), alpha=.1, size=2, shape=\"o\") \n \n)\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#the-additional-components-of-grammar-of-graphics-with-plotnine",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#the-additional-components-of-grammar-of-graphics-with-plotnine",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "# step 1: data\n(ggplot(data=gapminder) + \n\n# step 2: geom\n geom_point(\n\n# step 3: aesthethics\n     aes(x=\"lngdpPercap\", y=\"lifeExp\", color=\"continent\"), \n        alpha=.2, size=3) +\n\n\n# step scale: manually edit the aesthetics variables\nscale_color_manual(values = [\"blue\",\"steelblue\",\"black\",\"gold\",\"pink\"], \n                  name=\"Continent\") +\n# step theme: change the overall layout of the graph\ntheme_minimal(base_size=16) +\n \n# step facet: break the graph in subplots\nfacet_wrap(\"continent\", scales=\"free\") +\n \n\n# step labels: edit the labels of the graph\nlabs(x=\"Log GDP Per Capita\", y=\"Life Expectancy\", title=\"Gdp vs Life Expectancy Across the World\")\n \n)\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\nDo I need to memorize all of these options? \nNo. You need to learn the fundamental steps and how they work. But, you should be asking yourself, what do I do when I need to build a graph? This is how it works for me:\n\nConsult the plotnine’s documentation website for additional guidance and tips on using the API.\nCheck the library to see graphs you would like to replicate on your work.\nAnd get ready to ask google the same question over and over."
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#native-python-libraries-matplotlib-seaborn",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#native-python-libraries-matplotlib-seaborn",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "Before plotnine and the integration of grammar fo graphics to Python, of course Python had its own native visualization tools. The most famous is matplotlib and seaborn, which is actually built based on matplotlib.\nBecause matplotlib and seaborn are still the most used visualization library in Python, and it is likely you will encounter them as you look through other data scientists’ code, we will also cover in class how these libraries work.\nWe will use the same gapminder data.\n\n\nMatplotlib has its own way to built plots. In general, it involves:\n\nstep 1: Create the plt.figure() and plt.axes() objects\nstep 2: Create the visualization with a specifc method using the plt.axes() object\nstep 3: Edit aesthetics with arguments inside of methods\nstep 4: Edit labels, titles, and overall annotations\n\nLet’s see an example:\n\n# setup\n%matplotlib inline\nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns # for plotting\n\ngapminder.head()\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\nlngdpPercap\nlnpop\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n6.658583\n15.946754\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n6.710344\n16.039154\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n6.748878\n16.144454\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n6.728864\n16.261154\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n6.606625\n16.386554\n\n\n\n\n\n\n\n\n# Matplot lib\n\n# step 1: can be done with `plt.subplots()`\nfig, ax = plt.subplots()\n\n# step 2 + step 3\nax.scatter(x = gapminder[\"lngdpPercap\"], y = gapminder[\"lifeExp\"], c=\"green\", alpha=.5, marker=\"*\") \n\n# step 4\nax.set_ylabel(\"Log GDP Percapita\")\nax.set_xlabel(\"Life Expectancy\")\n\nText(0.5, 0, 'Life Expectancy')\n\n\n\n\n\n\n\n\n\n# Using .plt methods to avoid .axes and .figure\nplt.figure(figsize=(8,4))\nplt.scatter(x = gapminder[\"lngdpPercap\"], y = gapminder[\"lifeExp\"],  c=\"green\", alpha=.5, marker=\"*\") \nplt.xlabel(\"Log GDP perCapita\")\nplt.ylabel(\"Life Expectancy\")\n\nText(0, 0.5, 'Life Expectancy')\n\n\n\n\n\n\n# filter for a single country\ngapminder_ = gapminder.query('country==\"Brazil\"')\n\n# Using .plt methods to avoid .axes and .figure\nplt.figure(figsize=(8,4))\nplt.plot(gapminder_[\"year\"], gapminder_[\"lifeExp\"],  c=\"green\", alpha=.5, marker=\"*\") \nplt.xlabel(\"Log GDP perCapita\")\nplt.ylabel(\"Life Expectancy\")\n\nText(0, 0.5, 'Life Expectancy')\n\n\n\n\n\n\n\n\nseaborn is another more traditional Python data visualization library. It is built on top of matplotlib. It offers a higher-level, more attractive interface for creating statistically-informed visualizations.\nMain advantages:\n\ngraphs are visually more pleasing than matplotlib\nbuilt-in themes\nintegrates seamlessly with pandas DataFrames\n\nCheck the seaborn official tutorial\nLet’s see how it works\n\n# seaborn\nsns.scatterplot(x = \"lngdpPercap\",y=\"lifeExp\",\n                alpha=.5,color=\"green\",s=100,\n                data = gapminder)\nplt.xlabel(\"Log GDP perCapita\")\nplt.ylabel(\"Life Expectancy\")\n\nText(0, 0.5, 'Life Expectancy')\n\n\n\n\n\nNotice:\n\nData comes as an argument\nVariables are masked\nOther than that, very similar to matplotlib"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#data-types-drives-visualization-decisions-1",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#data-types-drives-visualization-decisions-1",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "Data Type\nExample\nScale\n\n\n\n\nNumerical\n1.3, 800, 10e3\nContinuous\n\n\nInteger\n1, 2, 3\nDiscrete (when \\(n\\) is small), Continuous (when \\(n\\) is large)\n\n\nCategorical\n“dog”, “Nigeria”, “A”\nDiscrete\n\n\nOrdered\n“Small”, “Medium”, “Large”\nDiscrete\n\n\nDates/Time\n2009-01-02, 5:32:33\nContinuous\n\n\n\n\n###\n\nDiscrete Values\n\n\n \n\n\n\n\n\n\ngapminder\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\nlngdpPercap\nlnpop\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n6.658583\n15.946754\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n6.710344\n16.039154\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n6.748878\n16.144454\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n6.728864\n16.261154\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n6.606625\n16.386554\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1699\nZimbabwe\nAfrica\n1987\n62.351\n9216418\n706.157306\n6.559838\n16.036497\n\n\n1700\nZimbabwe\nAfrica\n1992\n60.377\n10704340\n693.420786\n6.541637\n16.186160\n\n\n1701\nZimbabwe\nAfrica\n1997\n46.809\n11404948\n792.449960\n6.675129\n16.249558\n\n\n1702\nZimbabwe\nAfrica\n2002\n39.989\n11926563\n672.038623\n6.510316\n16.294279\n\n\n1703\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.709298\n6.152114\n16.326015\n\n\n\n\n1704 rows × 8 columns\n\n\n\n\n# plotnine\n(ggplot(gapminder,aes(x='continent')) +\n  geom_bar())\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Ordering Bar Plot by Frequency\n(ggplot(gapminder,aes(x='continent')) +\n  geom_bar() +\n  scale_x_discrete(limits=[\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\"]) +\n  ylim(0, 800) +\n  theme_minimal() \n)\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# create a binary indicator for wealthy countries\ngapminder = (gapminder.\n                assign(wealthy=np.where(gapminder[\"lngdpPercap\"] &gt; 9,\"yes\",\"no\")\n                      )\n            )\n\n\n\n## Adding in more categorical data \n(ggplot(gapminder,aes(x='continent',fill='wealthy')) +\n  geom_bar() +\n  scale_x_discrete(limits=[\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\"]))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Dodge + edit colors\n(ggplot(gapminder,aes(x='continent',fill='wealthy')) +\n  geom_bar(position=\"dodge\", color=\"black\") +\n  scale_x_discrete(limits=[\"Africa\", \"Americas\", \"Asia\", \"Europe\", \"Oceania\"]) +\n  scale_fill_manual(values=[\"yellow\", \"red\"], \n                    limits=[\"yes\", \"no\"], \n                    labels=[\"Yes\", \"No\"], \n                    name=\"Wealthy?\") \n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Create the bar plot\npalette = {\"yes\": \"yellow\", \"no\": \"red\"}\n\n# Seaborn\npalette = {\"yes\": \"yellow\", \"no\": \"red\"}\nsns.catplot(x=\"continent\", hue = \"wealthy\",\n            data=gapminder,\n            kind=\"count\", \n            palette=palette,\n            dodge=True, \n            edgecolor=\"black\")\n\n# Set legend title\nplt.legend(title=\"Wealthy?\")\n\n&lt;matplotlib.legend.Legend at 0x2b5da8350&gt;"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#point-uncertainty",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#point-uncertainty",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "# plotnine\n# Calculate the means and standard errors for lifeExp grouped by continent\ngrouped = gapminder.groupby('continent')['lifeExp'].agg(['mean', 'std']).reset_index()\ngrouped['ymin'] = grouped['mean'] - grouped['std']\ngrouped['ymax'] = grouped['mean'] + grouped['std']\n\n# Plot\n(ggplot(grouped, aes(x='continent', y='mean')) \n     + geom_point(color=\"red\", size=3)\n     + geom_errorbar(aes( ymin='ymin', ymax='ymax'), width=.2, size=1.2)\n)\n \n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# seaborn catplot method\nsns.catplot(x=\"continent\",\n            y=\"lifeExp\", \n            data=gapminder,\n            kind=\"point\",\n            join=False)\n\n\n\n\n\n\n\n\n\n# plotnine\n(ggplot(gapminder,aes(x='continent',y = 'lifeExp')) +\n  geom_boxplot() +\n  coord_flip())\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Seaborn\nsns.boxplot(y='continent',x = 'lifeExp',data=gapminder)\n\n&lt;Axes: xlabel='lifeExp', ylabel='continent'&gt;\n\n\n\n\n\n\n\n\n\n# ggplot\n(ggplot(gapminder,aes(x='continent',y = 'lifeExp')) + \n    geom_violin())\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Seaborn\nsns.violinplot(x='continent',y = 'lifeExp',data=gapminder)\n\n&lt;Axes: xlabel='continent', ylabel='lifeExp'&gt;\n\n\n\n\n\n\n\n\n\n(ggplot(gapminder,aes(x='continent',y = 'lifeExp',color=\"continent\")) +\n  geom_jitter(width = .25,alpha=.5,show_legend=False))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Layer the representations\n(ggplot(gapminder,aes(x='continent',y = 'lifeExp',color=\"continent\")) +\n  geom_jitter(width = .1,alpha=.1,show_legend=False) +\n  geom_boxplot(alpha=.5,show_legend=False))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Seaborn\ncolor = {\"Asia\": \"blue\", \n         \"Europe\": \"red\", \n         \"Africa\": \"yellow\", \n         \"Americas\":\"green\", \n         \"Oceania\":\"gray\"}\n\n# boxplot\nsns.boxplot(x='continent',y = 'lifeExp', \n            hue=\"continent\", \n            palette=color,\n            data=gapminder)\n# jitter\nsns.stripplot(x='continent', y='lifeExp',\n              data=gapminder, jitter=True, \n              alpha=0.1, hue=\"continent\", \n             palette=color)\n\nplt.legend([], [], frameon=False)\n\n&lt;matplotlib.legend.Legend at 0x2be7800d0&gt;\n\n\n\n\n\n###\n\nContinuous Values"
  },
  {
    "objectID": "lecture_notes/week-06/week-6-data-visualization.html#univariate-continuos",
    "href": "lecture_notes/week-06/week-6-data-visualization.html#univariate-continuos",
    "title": "In this Notebook we cover:",
    "section": "",
    "text": "# plotnine/ggplot2 \n(ggplot(gapminder, aes(x = 'lifeExp')) +\n  geom_histogram(bins=100))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Seaborn\nsns.distplot(gapminder.lifeExp,hist=True,kde=True)\n\n&lt;Axes: xlabel='lifeExp', ylabel='Density'&gt;\n\n\n\n\n\n\n\n\n\n# plotnine/ggplot2 \n(ggplot(gapminder, aes(x = 'lifeExp')) +\n  geom_density(fill=\"blue\",color=\"black\",alpha=.5)+\n  xlim(0,100))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n# plotnine/ggplot2 \n(ggplot(gapminder, aes(x = 'lifeExp', fill=\"continent\")) +\n  geom_density(color=\"black\",alpha=.5)+\n  xlim(0,100) +\n  facet_grid(\" ~ continent\"))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Seaborn\nsns.kdeplot(gapminder.lifeExp,shade=True)\n\n&lt;Axes: xlabel='lifeExp', ylabel='Density'&gt;\n\n\n\n\n\n###\n\nRelationships\n\n\n \n\n\n\n\n\n\n\n# plotnine/ggplot2 \n(ggplot(gapminder, aes(x = 'lngdpPercap', y = 'lifeExp')) +\n  geom_point(alpha=.5))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Seaborn\nsns.scatterplot(x = 'lngdpPercap', y = 'lifeExp',data=gapminder)\n\n&lt;Axes: xlabel='lngdpPercap', ylabel='lifeExp'&gt;\n\n\n\n\n\n\n\n\n\n# plotnine/ggplot2 \n(ggplot(gapminder, aes(x = 'lngdpPercap', y = 'lifeExp')) +\n  geom_line())\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# easily smooth in ggplot\n(ggplot(gapminder, aes(x = 'lngdpPercap', y = 'lifeExp')) +\n   geom_point(alpha=.2)\n    + geom_smooth(method=\"loess\"))\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n# Seaborn\nsns.lineplot(x = 'lngdpPercap', y = 'lifeExp',data=gapminder)\n\n&lt;Axes: xlabel='lngdpPercap', ylabel='lifeExp'&gt;"
  },
  {
    "objectID": "slides/week-1.html#plans-for-today",
    "href": "slides/week-1.html#plans-for-today",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Plans for Today",
    "text": "Plans for Today\n\n\nData Science for Public Policy, Computational Social Science, or why are we here?!\nGoals of the course\nCourse Logistics\nIntroductions\nIDEs\n\nJupyter\nQuarto\n\nIntroduction to Commandline"
  },
  {
    "objectID": "slides/week-1.html#rise-of-the-digital-information-age",
    "href": "slides/week-1.html#rise-of-the-digital-information-age",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Rise of the digital information age",
    "text": "Rise of the digital information age\n\n\n\n\n\n\n\n\n\n\n\nhttps://www.washingtonpost.com/wp-dyn/content/graphic/2011/02/11/GR2011021100614.html"
  },
  {
    "objectID": "slides/week-1.html#real-time-data-mobility-credit-card-usage-expenses",
    "href": "slides/week-1.html#real-time-data-mobility-credit-card-usage-expenses",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Real Time Data: Mobility, Credit Card Usage, Expenses…",
    "text": "Real Time Data: Mobility, Credit Card Usage, Expenses…"
  },
  {
    "objectID": "slides/week-1.html#social-media-data",
    "href": "slides/week-1.html#social-media-data",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Social Media Data",
    "text": "Social Media Data"
  },
  {
    "objectID": "slides/week-1.html#new-data-formats-image-text-videos..",
    "href": "slides/week-1.html#new-data-formats-image-text-videos..",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "New Data Formats: Image, text, videos..",
    "text": "New Data Formats: Image, text, videos.."
  },
  {
    "objectID": "slides/week-1.html#online-research",
    "href": "slides/week-1.html#online-research",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Online Research",
    "text": "Online Research"
  },
  {
    "objectID": "slides/week-1.html#powerful-and-cheap-computer-power",
    "href": "slides/week-1.html#powerful-and-cheap-computer-power",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Powerful and Cheap Computer Power",
    "text": "Powerful and Cheap Computer Power"
  },
  {
    "objectID": "slides/week-1.html#as-a-consequence",
    "href": "slides/week-1.html#as-a-consequence",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "As a consequence:",
    "text": "As a consequence:\n\nAbundance of data we can use for research and governments can use to make better decisions\n\nNovel research questions\nNew ways to answer old, long-standing research questions\n\nNew technologies also have social implications and can generate important policy questions.\n\nPrivacy issues\nUse of technology by bad actors.\nUse of technology by governments to censor/monitor citizens.\netc…\n\nPolicy scholars need to be equipped for these challenges"
  },
  {
    "objectID": "slides/week-1.html#an-example-merging-voter-files-with-twitter-data",
    "href": "slides/week-1.html#an-example-merging-voter-files-with-twitter-data",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "An example: Merging Voter Files with Twitter Data",
    "text": "An example: Merging Voter Files with Twitter Data"
  },
  {
    "objectID": "slides/week-1.html#what-it-looks-like",
    "href": "slides/week-1.html#what-it-looks-like",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "What it looks like…",
    "text": "What it looks like…"
  },
  {
    "objectID": "slides/week-1.html#all-the-steps-tools-....-so-far-...",
    "href": "slides/week-1.html#all-the-steps-tools-....-so-far-...",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "All the steps + Tools .... so far ...",
    "text": "All the steps + Tools .... so far ...\n\n\nStep 1: Processing 180M voter files ~ 5 terabytes\n\nHPC + Python + Spark\n\nStep 2: Find Matches between voters and Twitter users and Neighboors\n\nHPC + Python\n\nStep 3: Estimate/Impute Ideology for voters and neighboors\n\nJuggles across multiple dataset (census, precincts, twitter networks) + Python and R\n\nStep 4: Run the analysis\n\nR"
  },
  {
    "objectID": "slides/week-1.html#data-science-for-public-policy",
    "href": "slides/week-1.html#data-science-for-public-policy",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Data Science for Public Policy",
    "text": "Data Science for Public Policy\nData Scientist for Public Policy focuses on computational approaches to solve/understand Policy Problems.\n\nA part of a larger field on computational social scientist with a more policy-focus.\nWhat is social science? It refers to a domain of study - social phenomena:\n\nEncompasses many scales: human psychology, language, economic behavior, political systems, policy problems\nInvolve many approaches: qualitative interviews, statistical analysis, simulations\n\nWhat is Data Science?:\n\nUse often large-scale data + algorithms to answer questions"
  },
  {
    "objectID": "slides/week-1.html#readings",
    "href": "slides/week-1.html#readings",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Readings",
    "text": "Readings\n\nBit by Bit: Social Research in the Digital Age By Mathew Salganik\n\nIntroduction\nObserving Behavior"
  },
  {
    "objectID": "slides/week-1.html#goals-of-the-course",
    "href": "slides/week-1.html#goals-of-the-course",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Goals of the course",
    "text": "Goals of the course\n\nThe goal of this course is to teach you:\n\nComputational thinking: how to approach problems and devise solutions from a computational perspective.\nGet you started on Python and a bit of SQL for applied data science; lay the foundations for the remainder of the core sequence\nWorkflows and tools: Git/Github + Commandline."
  },
  {
    "objectID": "slides/week-1.html#logistics",
    "href": "slides/week-1.html#logistics",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Logistics",
    "text": "Logistics\n\nCommunication: via slack. Join the channel!\nAll materials: hosted on the class website: https://tiagoventura.github.io/ppol5203_fall_2023/\nSyllabus: also on the website.\nMy Office Hours: Every thursday from 4 to 6pm. Just stop by!\nCanvas: Only for communication! Materials will be hosted in the website!\nDatacamp: Additional exercises! I will not assign modules for you!\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/week-1.html#ta",
    "href": "slides/week-1.html#ta",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "TA",
    "text": "TA\nSierra Sikorski\n\nEmail: sps126@georgetown.edu\nOffice Hours:\n\nEvery Tuesday 2pm (in person, old north)\nEvery Wednesday 2pm (remote via Zoom)"
  },
  {
    "objectID": "slides/week-1.html#evaluation",
    "href": "slides/week-1.html#evaluation",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Evaluation",
    "text": "Evaluation\n\n\n\nAssignment\nPercentage of Grade\n\n\n\n\nParticipation/Attendance\n5%\n\n\nCoding Discussion\n5%\n\n\nProblem sets\n50%\n\n\nFinal Project\n40%"
  },
  {
    "objectID": "slides/week-1.html#problem-sets",
    "href": "slides/week-1.html#problem-sets",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Problem Sets",
    "text": "Problem Sets\nIndividual submission through GitHub.\n\n\n\nAssignment\nDate Assigned\nDate Due\n\n\n\n\nNo. 1\nWeek 2\nBefore EOD of Friday of Week 3\n\n\nNo. 2\nWeek 4\nBefore EOD of Friday of Week 5\n\n\nNo. 3\nWeek 6\nBefore EOD of Friday of Week 7\n\n\nNo. 4\nweek 8\nBefore EOD of Friday of Week 9\n\n\nNo. 5\nNovember 10\nBefore EOD of Friday of Week 111"
  },
  {
    "objectID": "slides/week-1.html#final-project",
    "href": "slides/week-1.html#final-project",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Final Project",
    "text": "Final Project\n\nYou will work on randomly assigned groups!\nThe project is composed of three parts:\n\na 2 page project proposal: (which should be discussed and approved by me)\nan in-class presentation,\nA 10-page project report."
  },
  {
    "objectID": "slides/week-1.html#due-dates-and-points",
    "href": "slides/week-1.html#due-dates-and-points",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Due dates and Points:",
    "text": "Due dates and Points:\n\n\n\nRequirement\nDue\nLength\nPercentage\n\n\n\n\nProject Proposal\nOctober 31\n2 pages\n5%\n\n\nPresentation\nDecember 5\n10-15 minutes\n10%\n\n\nProject Report\nDecember 12\n10 pages\n25%"
  },
  {
    "objectID": "slides/week-1.html#chatgpt",
    "href": "slides/week-1.html#chatgpt",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "ChatGPT",
    "text": "ChatGPT\nYou are allowed to use ChatGPT as you would use google in this class. This means:\n\nDo not copy the responses from chatgpt – a lot of them are wrong or will just not run on your computer\nUse chatgpt as a auxiliary source.\nIf your entire homework comes straight from chatgpt, I will consider it plagiarism.\nIf you use chatgpt, I ask you to mention on your code how chatgpt worked for you."
  },
  {
    "objectID": "slides/week-1.html#about-me",
    "href": "slides/week-1.html#about-me",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "About me",
    "text": "About me\n\n\nProfessor Tiago Ventura (he/him)\n\nAssistant Professor at McCourt School.\nPolitical Science Ph.D.\nPostdoc at Center for Social Media and Politics at NYU.\nResearcher at Twitter.\n\nResearch Interests:\n\nSocial media and politics\nComputational methods\nFocus on Global South\n\nOutside of work, I enjoy watching soccer and reading sci-fi.\n\nSometimes I enjoy soccer while working!\nAnd I am from Brazil!"
  },
  {
    "objectID": "slides/week-1.html#quiz",
    "href": "slides/week-1.html#quiz",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Quiz!",
    "text": "Quiz!\nWhich programming language did I use the most at?\n\nPhD\nPostdoc\nTwitter"
  },
  {
    "objectID": "slides/week-1.html#a-comment-from-the-pre-course-survey",
    "href": "slides/week-1.html#a-comment-from-the-pre-course-survey",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "A comment from the pre-course survey",
    "text": "A comment from the pre-course survey\n\nHi professor Ventura! I noticed that we gonna learn multiple data analysis tool this semester and I am definitely a novice of data science. I am little worried about how can I master all of them without being confused, because some commands might be very similar."
  },
  {
    "objectID": "slides/week-1.html#your-turn",
    "href": "slides/week-1.html#your-turn",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Your turn!",
    "text": "Your turn!\n\nName\n(Briefly) what you were up to prior to the DSPP\nIf you could have any data source at your disposal, what would it be?"
  },
  {
    "objectID": "slides/week-1.html#summary-of-the-survey",
    "href": "slides/week-1.html#summary-of-the-survey",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Summary of the survey",
    "text": "Summary of the survey\n\n75% of you have some experience with Python.\n42% of you have some with SQL and 42% have none (which is great for the intro purposes of this course!)\nNONE of you were using primarily Python in your work before!\n\n30% using R and 30% using Stata.\n\nA few still do not have Python/Jupyter/Github in your laptops. If you are having issue after today, talk to Sierra.\nMain Policy Areas:\n\nSocial Media/Tech (Thank you, my dear students. Not so much for you Elon!)\nInternational Development (let’s talk war, peace and RCTs)\nEducation (Gonna get some data with Professor Johnson)"
  },
  {
    "objectID": "slides/week-1.html#jupyter",
    "href": "slides/week-1.html#jupyter",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Jupyter:",
    "text": "Jupyter:\nSee Jupyter Notebook in the Class Website"
  },
  {
    "objectID": "slides/week-1.html#quarto",
    "href": "slides/week-1.html#quarto",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Quarto",
    "text": "Quarto\nSee Quarto Notebook in the Class Website"
  },
  {
    "objectID": "slides/week-1.html#command-line",
    "href": "slides/week-1.html#command-line",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "Command Line",
    "text": "Command Line\nSee Command Line Tutorial in the Class Website"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "",
    "text": "This first course in the core data science sequence teaches Data Science for Public Policy (DSPP) students how to synthesize disparate, possibly unstructured data in order to draw meaningful insights. Topics covered include the fundamentals of object-oriented programming in Python; literate programming; an introduction to algorithms and data types; data wrangling, visualization, and extraction; an introduction to machine learning methods, and text analysis. In addition, students will be exposed to Git and Github for version control and reproducible research. The objective of the course is to teach students how incorporate data into their decision-making and analysis. No prior programming experience is assumed or required.\nClass Website: https://tiagoventura.github.io/ppol5203_fall_2023"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "",
    "text": "This first course in the core data science sequence teaches Data Science for Public Policy (DSPP) students how to synthesize disparate, possibly unstructured data in order to draw meaningful insights. Topics covered include the fundamentals of object-oriented programming in Python; literate programming; an introduction to algorithms and data types; data wrangling, visualization, and extraction; an introduction to machine learning methods, and text analysis. In addition, students will be exposed to Git and Github for version control and reproducible research. The objective of the course is to teach students how incorporate data into their decision-making and analysis. No prior programming experience is assumed or required.\nClass Website: https://tiagoventura.github.io/ppol5203_fall_2023"
  },
  {
    "objectID": "syllabus.html#learning-goals",
    "href": "syllabus.html#learning-goals",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Learning Goals",
    "text": "Learning Goals\nAfter completing this course, the students will be able to:\n\nGeneral understanding of python’s object oriented programming syntax and data structures.\nCompetency using version control (Git/Github).\nLearn to manipulate and explore data with Pandas and other tools.\nGeneral understanding of analyzing algorithms and data structures.\nLearn to extract and process data from structured and unstructured sources.\nGet some intuition of modeling text data in Python.\nLearn the basics of machine learning as a modeling approach.\nLearn basics of using SQL to query databases."
  },
  {
    "objectID": "syllabus.html#instructors-and-tas",
    "href": "syllabus.html#instructors-and-tas",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Instructors and TAs",
    "text": "Instructors and TAs\n\nInstructor\n\nProfessor: Dr. Tiago Ventura\nPronouns: He/Him\nEmail: tv186@georgetown.edu\nOffice hours:\n\nTime: Every Thursday, 4pm - 6pm\nLocation: Old North, 312"
  },
  {
    "objectID": "syllabus.html#teaching-assistant-sierra-sikorski-dspp-second-year-student",
    "href": "syllabus.html#teaching-assistant-sierra-sikorski-dspp-second-year-student",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Teaching Assistant: Sierra Sikorski (DSPP Second-Year Student)",
    "text": "Teaching Assistant: Sierra Sikorski (DSPP Second-Year Student)\n\nEmail: sps126@georgetown.edu@georgetown.edu\nOffice Hours:\n\nEvery Tuesday 2pm (in person, old north)\nEvery Wednesday 2pm (remote via Zoom)"
  },
  {
    "objectID": "syllabus.html#our-classes",
    "href": "syllabus.html#our-classes",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Our classes",
    "text": "Our classes\nClasses will take place at the scheduled class time/place and will involve a combination of lectures, coding walkthrough, breakout group sessions, and questions. We will start our classes with a lecture highlighting what I consider to be the broader substantive and programming concepts covered in the class. From that, we will switch to a mix of coding walk through and breakout group sessions.\nFor every lecture, you will have access to a notebook (in .qmd or .ipynb) covering the topics and code discussed in class. I will upload these materials (which I call lecture notes every day before the class starts). In addition, you will also have access (in at least a week in advance), of required readings (book chapters, articles, blog posts or coding tutorials) for every class. What you will take from this class will be tremendously improved if you work through all these materials.\nNote that this class is scheduled to meet weekly for 2.5 hours. I will do my best to make our meetings dynamic and enjoyable for all parts involved. We will take one or two breaks in each of our lecture."
  },
  {
    "objectID": "syllabus.html#required-materials",
    "href": "syllabus.html#required-materials",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Required Materials",
    "text": "Required Materials\nReadings: We will rely primarily on the following text for this course.\n\nMcKinney, W. , 2022. Python for Data Analysis. O’Reilly Media, Inc.(Online version: https://wesmckinney.com/book/).\nVanderplas, J.T., 2016. “Python data science handbook: tools and techniques for developers.” O’Reilly. (Online version: https://jakevdp.github.io/PythonDataScienceHandbook/)\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). “An Introduction to Statistical Learning: with Applications in R”. New York: springer.\nGrimmer, J., Roberts, M. E., & Stewart, B. M. (2022). Text as data: A new framework for machine learning and the social sciences. Princeton University Press.\nSalganik, M. 2017. Bit by Bit: Social Research in the Digital Age. Princeton, NJ: Princeton University Press.\n\nAdditional readings will be posted for each class and can be found on the course website. Most reading materials are open source and available via a link on the weekly schedule. Otherwise it can be found on Canvas."
  },
  {
    "objectID": "syllabus.html#course-infrastructure",
    "href": "syllabus.html#course-infrastructure",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Course Infrastructure",
    "text": "Course Infrastructure\nClass Website: A class website https://tiagoventura.github.io/ppol5203_fall_2023 will be used throughout the course and should be checked on a regular basis for lecture materials and required readings.\nClass Slack Channel: The class also has a dedicated slack channel (ppol-564-fall-2023.slack.com). The channel serves as an open forum to discuss, collaborate, pose problems/questions, and offer solutions. Students are encouraged to pose any questions they have there as this will provide the professor and TA the means of answering the question so that all can see the response. If you’re unfamiliar with, please consult the following start-up tutorial (https://get.slack.help/hc/en-us/articles/218080037-Getting-started-for-new-members). Please follow the invite link to be added to the Slack channel.\nCanvas: A Canvas site (http://canvas.georgetown.edu) will be used throughout the course and should be checked on a regular basis for announcements. ll announcements for the assignments and classes will be posted on Canvas; they will not be distributed in class or by e-mail. Support for Canvas is available at (202) 687-4949\nNOTE: Students are encouraged to run lecture code on their own machines. If you do not have access to a laptop on which you can install python3, please contact the professor and/or TA for assistance. Only python3 will be used in this course."
  },
  {
    "objectID": "syllabus.html#weekly-schedule",
    "href": "syllabus.html#weekly-schedule",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Weekly Schedule",
    "text": "Weekly Schedule\n\n\n\n\n\n\nWeek\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nWeek 01\n\n\nIntroduction, Installations, IDEs, Command line\n\n\nAugust 29, 2023\n\n\n\n\nWeek 02\n\n\nVersion Control, Workflow and Reproducibility: Or a bit of Git & GitHub\n\n\nSeptember 12, 2023\n\n\n\n\nWeek 03\n\n\nIntro to Python - OOP, Data Types, Control Statements and Functions\n\n\nSeptember 19, 2023\n\n\n\n\nWeek 04\n\n\nFrom Nested Lists to Data Frames\n\n\nSeptember 26, 2023\n\n\n\n\nWeek 05\n\n\nPandas I: Data Manipulation\n\n\nOctober 03, 2023\n\n\n\n\nWeek 06\n\n\nPandas II: Advanced Manipulation and Visualization\n\n\nOctober 10, 2023\n\n\n\n\nWeek 07\n\n\nScrapping: Drawing from (Un-)Structured Data Sources\n\n\nOctober 17, 2023\n\n\n\n\nWeek 08\n\n\nText as data I: Data Mining\n\n\nOctober 24, 2023\n\n\n\n\nWeek 09\n\n\nIntroduction to Statistical Learning\n\n\nOctober 31, 2023\n\n\n\n\nWeek 10\n\n\nText as Data II: Topics + Supervised Models\n\n\nNovember 07, 2023\n\n\n\n\nWeek 11\n\n\nInvited Speaker: Introduction to Algorithms + Coding Interviews\n\n\nNovember 14, 2023\n\n\n\n\nWeek 12\n\n\nTraining Machines and collecting data with Selenium\n\n\nNovember 21, 2023\n\n\n\n\nWeek 13\n\n\nSQL + Spark\n\n\nNovember 28, 2023\n\n\n\n\nWeek 14\n\n\nPresentations of Final Projects\n\n\nDecember 05, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "syllabus.html#course-requirements",
    "href": "syllabus.html#course-requirements",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Course Requirements",
    "text": "Course Requirements\n\n\n\nAssignment\nPercentage of Grade\n\n\n\n\nParticipation/Attendance\n5%\n\n\nCoding Discussion\n5%\n\n\nProblem sets\n50%\n\n\nFinal Project\n40%\n\n\n\nParticipation and Attendance (5%):\nData science is an cooperative endeavor, and it’s crucial to view your fellow classmates as valuable assets rather than rivals. Your performance in the following aspects will be considered when assessing this part of your grade:\n\nActive involvement during class sessions, fostering a dynamic learning environment.\nContributions made to your group’s ultimate project.\nAssisting classmates by addressing problem set queries through GitHub issues. Supporting your peers will enhance your evaluation in terms of teamwork and engagement\nAssisting classmates with slack questions, sharing interesting materials on slack, asking question, and anything that provides healthy contributtions to the course.\n\nCoding Discussion(5%)\nEvery class will involve some lecture time, and some coding time. The coding time will be divided between me showing you things, and you working on small problem sets. These problem sets are purposefully constructed to help you understand the concepts we go through in class. You participation and involvement in these group exercises will also be part of your grade.\nProblem Sets (50%)\nStudents will be assigned five problem sets over the course of the semesters. While you are encouraged to discuss the problem sets with your peers and/or consult online resources, the finished product must be your own work. The goal of the assignment is to reinforce the student’s comprehension of the materials covered in each section.\nThe problems sets will assess your ability to apply the concepts to data that is substantially messier, and problems that are substantially more difficult, than the ones in the coding discussion in class.\nI will distribute the assignment through a mix of canvas and github. The assignments can be in the form of a Jupyter Notebook (.ipynb) or Quarto (.qmd). Students must submit completed assignments as a rendered .html file and the corresponding source code (.ipynb or .qmd).\nThe assignments will be graded in accuracy and quality of the programming style. For instance, our grading team will be looking at:\n\n\nall code must run;\n\n\nsolutions should be readable\n\n\nCode should be thoroughly commented (the Professor/TA should be able to understand the codes purpose by reading the comment),\nCoding solutions should be broken up into individual code chunks in Jupyter/R Markdown notebooks, not clumped together into one large code chunk (See examples in class or reach out to the TA/Professor if this is unclear),\nEach student defined function must contain a doc string explaining what the function does, each input argument, and what the function returns;\n\n\nCommentary, responses, and/or solutions should all be written in Markdown and explain sufficiently the outpus.\n\n\nAll solutions must be completed in Python.\n\n\nThe follow schedule lays out when each assignment will be assigned.\n\n\n\nAssignment\nDate Assigned\nDate Due\n\n\n\n\nNo. 1\nWeek 2\nBefore EOD of Friday of Week 3\n\n\nNo. 2\nWeek 4\nBefore EOD of Friday of Week 5\n\n\nNo. 3\nWeek 6\nBefore EOD of Friday of Week 7\n\n\nNo. 4\nWeek 8\nBefore EOD of Friday of Week 10\n\n\nNo. 5\nWeek 10\nBefore EOD of Friday of Week 11\n\n\n\nFinal Project (40%): Data science is an applied field and the DSPP is particularly geared towards providing students the tools to make policy and substantive contributtions using data and recent computational developments. In this sense, it is fundamental that you understand how to conduct a complete analysis from collecting data, to cleaning and analyzing it, to presenting your findings. For this reason, a considerable part of your grade will come from a an independent data science project, applying concepts learned throughout the course.\nThe project is composed of three parts:\n\na 2 page project proposal: (which should be discussed and approved by me)\nan in-class presentation,\nA 10-page project report.\n\nDue dates and breakdowns for the project are as follows:\n\n\n\nRequirement\nDue\nLength\nPercentage\n\n\n\n\nProject Proposal\nOctober 31\n2 pages\n5%\n\n\nPresentation\nDecember 5\n10-15 minutes\n10%\n\n\nProject Report\nDecember 12\n10 pages\n25%\n\n\n\nImportant notes about the final project\n\nFor the project proposal, you need to schedule a 30min with me at least a week before the due date. For this meeting, I expect you to send me a draft of your ideas. We will do the group assignment and start scheduling meetings by week 4, I will share with you a calendar invite to organize our meetings.\nFor the presentation, You will have 10-15 minutes in our last class of the semester to present you project.\nTake the final project seriously. After you finish your Masters, in any path you take, you will need to show concrete examples of your portfolio. This is a good opportunity to start building it.\nYour groups will be randomly assigned.\n\nSubmission of the Final Project\nThe end product should be a github repository that contains:\n\nThe raw source data you used for the project. If the data is too large for GitHub, talk with me, and we will find a solution\nYour proposal\nA README for the repository that, for each file, describes in detail:\n\nInputs to the file: e.g., raw data; a file containing credentials needed to access an API\nWhat the file does: describe major transformations.\nOutput: if the file produces any outputs (e.g., a cleaned dataset; a figure or graph).\nA set of code files that transform that data into a form usable to answer the question you have posed in your descriptive research proposal.\nYour final 10 pages report (I will share a template later in the semester)\n\n\nOf course, no commits after the due date will be considered in the assessment."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Grading",
    "text": "Grading\nCourse grades will be determined according to the following scale:\n\n\n\nLetter\nRange\n\n\n\n\nA\n95% – 100%\n\n\nA-\n91% – 94%\n\n\nB+\n87% – 90%\n\n\nB\n84% – 86%\n\n\nB-\n80% – 83%\n\n\nC\n70% – 79%\n\n\nF\n&lt; 70%\n\n\n\nGrades may be curved if there are no students receiving A’s on the non-curved grading scale.\nLate problem sets will be penalized a letter grade per day."
  },
  {
    "objectID": "syllabus.html#communication",
    "href": "syllabus.html#communication",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Communication",
    "text": "Communication\n\nClass-relevant and/or coding-related questions, Slack is the preferred method of communication. Please use the general or the relevant channel for these questions.\nFor private questions concerning the class, email is the preferred method of communication. All email messages must originate from your Georgetown University email account(s). Please use a professional salutation, proper spelling and grammar, and patience in waiting for a response. The professor reserves the right to not respond to emails that are drafted inappropriately. Please email the professor and the TA directly rather than through the Canvas messaging system. Emails sent through CANVAS will be ignored.\nI will try my best to respond to all emails/slack questions within 24 hours of being sent during a weekday. I will not respond to emails/slack sent late Friday (after 5:00 pm) or during the weekend until Monday (9:00 am). Please plan accordingly if you have questions regarding current or upcoming assignments.\nOnly reach out to the professor or teaching assistant regarding a technical question, error, or issue after you made a good faith effort to debugging/isolate your problem prior to reaching out. Learning how to search for help online is a important skill for data scientists.\n\n\nChatGPT\nIn the last year, the internet was inundated with popularization of Large Language Models, particularly the easy use of ChatGPT. As a Data Scientist, LLMs will be part of your daily work. I see ChatGPT as Google on steroids, so I assume ChatGPT will be part of your daily work in this course, and it is part of my work as a researcher.\nThat being said, ChatGPT does not replace your training as a data scientist. If you are using ChatGPT instead of learning, I consider you are cheating in the course. And most importantly, you are wasting your time and resources. So that’s our policy for using LLMs models in class:\n\nDo not copy the responses from chatgpt – a lot of them are wrong or will just not run on your computer.\nUse chatgpt as a auxiliary source.\nIf your entire homework comes straight from chatgpt, I will consider it plagiarism.\n\nIf you use chatgpt, I ask you to mention on your code how chatgpt worked for you."
  },
  {
    "objectID": "syllabus.html#electronic-devices",
    "href": "syllabus.html#electronic-devices",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Electronic Devices",
    "text": "Electronic Devices\nWhen meeting in-person: the use of laptops, tablets, or other mobile devices is permitted only for class-related work. Audio and video recording is not allowed unless prior approval is given by the professor. Please mute all electronic devices during class."
  },
  {
    "objectID": "syllabus.html#georgetown-policies",
    "href": "syllabus.html#georgetown-policies",
    "title": "Syllabus: PPOL 5203 - Data Science I: Foundations",
    "section": "Georgetown Policies",
    "text": "Georgetown Policies\n\nDisability\nIf you believe you have a disability, then you should contact the Academic Resource Center (arc@georgetown.edu) for further information. The Center is located in the Leavey Center, Suite 335 (202-687-8354). The Academic Resource Center is the campus office responsible for reviewing documentation provided by students with disabilities and for determining reasonable accommodations in accordance with the Americans with Disabilities Act (ASA) and University policies. For more information, go to http://academicsupport.georgetown.edu/disability/\n\n\nImportant Academic Policies and Academic Integrity\nMcCourt School students are expected to uphold the academic policies set forth by Georgetown University and the Graduate School of Arts and Sciences. Students should therefore familiarize themselves with all the rules, regulations, and procedures relevant to their pursuit of a Graduate School degree. The policies are located at: http://grad.georgetown.edu/academics/policies/\nApplied to this course, while I encourage collaboration on assignments and use of resources like StackOverflow, the problem sets will ask you to list who you worked on the problem set with and cite StackOverflow if it is the direct source of a code snippet.\n\n\nStatement on Sexual Misconduct\nGeorgetown University and its faculty are committed to supporting survivors and those impacted by sexual misconduct, which includes sexual assault, sexual harassment, relationship violence, and stalking. Georgetown requires faculty members, unless otherwise designated as confidential, to report all disclosures of sexual misconduct to the University Title IX Coordinator or a Deputy Title IX Coordinator. If you disclose an incident of sexual misconduct to a professor in or outside of the classroom (with the exception of disclosures in papers), that faculty member must report the incident to the Title IX Coordinator, or Deputy Title IX Coordinator. The coordinator will, in turn, reach out to the student to provide support, resources, and the option to meet. [Please note that the student is not required to meet with the Title IX coordinator.]. More information about reporting options and resources can be found on the Sexual Misconduct\nWebsite: https://sexualassault.georgetown.edu/resourcecenter\nIf you would prefer to speak to someone confidentially, Georgetown has a number of fully confidential professional resources that can provide support and assistance. These resources include: Health Education Services for Sexual Assault Response and Prevention: confidential email: sarp[at]georgetown.edu\nCounseling and Psychiatric Services (CAPS): 202.687.6985 or after hours, call (833) 960-3006 to reach Fonemed, a telehealth service; individuals may ask for the on-call CAPS clinician\nMore information about reporting options and resources can be found on the Sexual Misconduct Website.\n\n\nProvost’s Policy on Religious Observances\nGeorgetown University promotes respect for all religions. Any student who is unable to attend classes or to participate in any examination, presentation, or assignment on a given day because of the observance of a major religious holiday or related travel shall be excused and provided with the opportunity to make up, without unreasonable burden, any work that has been missed for this reason and shall not in any other way be penalized for the absence or rescheduled work. Students will remain responsible for all assigned work. Students should notify professors in writing at the beginning of the semester of religious observances that conflict with their classes. The Office of the Provost, in consultation with Campus Ministry and the Registrar, will publish, before classes begin for a given term, a list of major religious holidays likely to affect Georgetown students. The Provost and the Main Campus Executive Faculty encourage faculty to accommodate students whose bona fide religious observances in other ways impede normal participation in a course. Students who cannot be accommodated should discuss the matter with an advising dean."
  },
  {
    "objectID": "slides/week-3.html#plans-for-today",
    "href": "slides/week-3.html#plans-for-today",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "",
    "text": "In-class exercise about Git\nIntro to Python\n101 Object-Oriented Programming\nData Types in Python\nControl statements\nFunctions"
  },
  {
    "objectID": "slides/week-3.html",
    "href": "slides/week-3.html",
    "title": " PPOL 5203 - Data Science I: Foundations ",
    "section": "",
    "text": "In-class exercise about Git\nIntro to Python\n101 Object-Oriented Programming\nData Types in Python\nControl statements\nFunctions"
  }
]