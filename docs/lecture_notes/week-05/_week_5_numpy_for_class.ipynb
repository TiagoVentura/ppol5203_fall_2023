{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab903f6",
   "metadata": {},
   "source": [
    "<h1><center> PPOL 5203 Data Science I: Foundations <br><br> \n",
    "<font color='grey'>Data as Nested Lists -> Introduction to Numpy <br><br>\n",
    "Tiago Ventura </center> <h1> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde27f5",
   "metadata": {},
   "source": [
    "## Data as nested lists\n",
    "\n",
    "Before introducting Numpy, we will learn how you can process and analyse your data as nested list. \n",
    "\n",
    "We will cover:\n",
    "\n",
    "- open csv as nested lists\n",
    "- Working with retangular data as nested lists\n",
    "\n",
    "This will work as a motivation for the use of `numpy` and later for `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4980855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batteries included Functions\n",
    "import csv # convert a .csv to a nested list\n",
    "import os  # library for managing our operating system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57695ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tb186/Dropbox/courses/ppol_5203_fall_2023/lecture_notes/week-05'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## looking at your working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8726d591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tb186/Dropbox/courses/ppol_5203_fall_2023/lecture_notes/week-05'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## as magic line\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86421e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change working directory\n",
    "os.chdir('/Users/tb186/Dropbox/courses/ppol_5203_fall_2023/lecture_notes/week-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219ea5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'student_data.csv',\n",
       " '_week_4_comprehension_generators.ipynb',\n",
       " '_week_4_nested_lists.ipynb',\n",
       " '_week_4_numpy.html',\n",
       " 'student_data_write.csv',\n",
       " '_week_4_comprehension_generators.html',\n",
       " '_week_4_file_management.ipynb',\n",
       " 'data_week4',\n",
       " '_week_4_nested_lists.html',\n",
       " '_week_4_file_management.html',\n",
       " 'text_file.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'redrising.txt',\n",
       " 'data_week4.zip',\n",
       " 'gapminder.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### see what exists on my dataset\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8303edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the gapminder data \n",
    "with open(\"gapminder.csv\",mode=\"rt\") as file:\n",
    "    data = [row for row in csv.reader(file)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da46e5",
   "metadata": {},
   "source": [
    "### What does the data looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f673f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['country', 'lifeExp', 'gdpPercap'],\n",
       " ['Guinea_Bissau', '39.21', '652.157'],\n",
       " ['Bolivia', '52.505', '2961.229'],\n",
       " ['Austria', '73.103', '20411.916'],\n",
       " ['Malawi', '43.352', '575.447'],\n",
       " ['Finland', '72.992', '17473.723'],\n",
       " ['North_Korea', '63.607', '2591.853'],\n",
       " ['Malaysia', '64.28', '5406.038'],\n",
       " ['Hungary', '69.393', '10888.176'],\n",
       " ['Congo', '52.502', '3312.788']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is a nested list. \n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5e255",
   "metadata": {},
   "source": [
    "## Indexing Nested Lists\n",
    "\n",
    "Notice something important here, because we open the data using a iterator, the code doesn't know that the first row is the header of the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92dd3edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'lifeExp', 'gdpPercap']\n"
     ]
    }
   ],
   "source": [
    "# accessing the header\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa13429",
   "metadata": {},
   "source": [
    "### Indexing Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49aef660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Burundi', '44.817', '471.663']\n"
     ]
    }
   ],
   "source": [
    "# For any row > 0, row == 0 is the column names. \n",
    "print(data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c7911",
   "metadata": {},
   "source": [
    "### Indexing by columns\n",
    "\n",
    "Accessing columns values become much more trick, because every row is a separate entry in your nested list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15ad89f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44.817'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Referencing a column data value\n",
    "d = data[100] # First select the row\n",
    "d[1] # Then reference the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e68a646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44.817'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing the above all in one step\n",
    "data[100][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15d887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'lifeExp', 'gdpPercap']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The key is to keep in mind the column names\n",
    "cnames = data.pop(0)\n",
    "cnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8071b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now reference this column name list to pull out the columns we're interested in.\n",
    "ind = cnames.index(\"lifeExp\") # Index allows us to \"look up\" the location of a data value. \n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "add5ee92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44.817'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[99][ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e4156",
   "metadata": {},
   "source": [
    "## Accessing a entire column\n",
    "\n",
    "If I want to extract all the values of a particular column, I need to loop through all the *j* element of a sublist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4244a4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39.21', '52.505', '73.103', '43.352', '72.992', '63.607', '64.28', '69.393', '52.502', '57.609', '73.444', '62.817', '68.922', '73.989', '52.302', '47.619', '42.96', '70.056', '54.336', '74.903', '52.382', '70.299', '71.601', '66.828', '70.177', '50.007', '74.014', '60.721', '52.681', '44.401', '67.708', '59.304', '73.733', '52.341', '58.859', '59.696', '66.644', '66.526', '47.903', '69.744', '65.866', '51.499', '46.78', '68.749', '49.002', '67.431', '73.646', '59.03', '71.511', '46.381', '71.22', '43.581', '49.834', '44.544', '71.045', '53.491', '48.401', '61.346', '41.482', '72.739', '68.433', '57.48', '40.38', '43.413', '58.679', '42.476', '47.771', '46.774', '51.221', '64.953', '45.996', '68.291', '61.554', '56.243', '50.626', '58.443', '52.663', '54.598', '48.436', '37.479', '65.409', '57.896', '53.322', '75.565', '73.923', '74.827', '59.633', '53.166', '62.2', '65.606', '74.663', '55.89', '48.986', '58.637', '57.921', '43.24', '66.581', '76.511', '40.989', '44.817', '67.802', '70.181', '60.967', '74.37', '48.78', '45.999', '73.642', '60.329', '65.001', '44.476', '56.729', '63.898', '48.129', '73.478', '54.882', '61.785', '36.769', '70.696', '47.912', '66.809', '69.06', '74.203', '75.648', '74.349', '44.559', '43.867', '68.551', '56.582', '70.782', '37.883', '76.177', '58.349', '53.993', '44.694', '50.165', '75.843', '70.337', '70.42', '59.786', '73.017', '62.239']\n"
     ]
    }
   ],
   "source": [
    "# get you columns again\n",
    "ind = cnames.index(\"lifeExp\") \n",
    "\n",
    "# Looping through each row pulling out the relevant data value\n",
    "\n",
    "#create a container\n",
    "life_exp = []\n",
    "\n",
    "# loop\n",
    "for row in data:\n",
    "    life_exp.append(row[ind])\n",
    "print(life_exp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d9cf612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39.21', '52.505', '73.103', '43.352', '72.992', '63.607', '64.28', '69.393', '52.502', '57.609', '73.444', '62.817', '68.922', '73.989', '52.302', '47.619', '42.96', '70.056', '54.336', '74.903', '52.382', '70.299', '71.601', '66.828', '70.177', '50.007', '74.014', '60.721', '52.681', '44.401', '67.708', '59.304', '73.733', '52.341', '58.859', '59.696', '66.644', '66.526', '47.903', '69.744', '65.866', '51.499', '46.78', '68.749', '49.002', '67.431', '73.646', '59.03', '71.511', '46.381', '71.22', '43.581', '49.834', '44.544', '71.045', '53.491', '48.401', '61.346', '41.482', '72.739', '68.433', '57.48', '40.38', '43.413', '58.679', '42.476', '47.771', '46.774', '51.221', '64.953', '45.996', '68.291', '61.554', '56.243', '50.626', '58.443', '52.663', '54.598', '48.436', '37.479', '65.409', '57.896', '53.322', '75.565', '73.923', '74.827', '59.633', '53.166', '62.2', '65.606', '74.663', '55.89', '48.986', '58.637', '57.921', '43.24', '66.581', '76.511', '40.989', '44.817', '67.802', '70.181', '60.967', '74.37', '48.78', '45.999', '73.642', '60.329', '65.001', '44.476', '56.729', '63.898', '48.129', '73.478', '54.882', '61.785', '36.769', '70.696', '47.912', '66.809', '69.06', '74.203', '75.648', '74.349', '44.559', '43.867', '68.551', '56.582', '70.782', '37.883', '76.177', '58.349', '53.993', '44.694', '50.165', '75.843', '70.337', '70.42', '59.786', '73.017', '62.239']\n"
     ]
    }
   ],
   "source": [
    "# Same idea, but as a list comprehension \n",
    "life_exp = [row[ind] for row in data]\n",
    "print(life_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14e51ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['652.157', '2961.229', '20411.916', '575.447', '17473.723', '2591.853', '5406.038', '10888.176', '3312.788', '2447.909', '20556.684', '5733.625', '65332.91', '17262.623', '1356.671', '810.384', '2469.167', '9331.712', '1741.365', '22410.746', '1314.38', '7208.065', '14074.582', '7866.872', '8416.554', '780.553', '16245.209', '3477.21', '1200.416', '680.133', '3484.779', '12013.579', '13969.037', '1044.582', '5613.844', '4469.453', '4898.398', '1854.731', '675.368', '6384.055', '7269.216', '1153.82', '1569.275', '6197.645', '3163.352', '6703.289', '14160.936', '4426.026', '13920.011', '2697.833', '17425.382', '1488.309', '817.559', '648.343', '6283.259', '3675.582', '1835.01', '3009.288', '675.669', '10863.164', '3255.367', '1017.713', '542.278', '673.093', '20261.744', '604.814', '1335.595', '1165.454', '11529.865', '4768.942', '1358.199', '7300.17', '2844.856', '3074.031', '1533.122', '12138.562', '635.858', '5031.504', '1912.825', '802.675', '7724.113', '1382.782', '439.333', '27074.334', '19380.473', '17750.87', '4431.847', '1057.296', '3045.966', '18077.664', '19980.596', '1692.805', '782.729', '7376.583', '2834.413', '776.067', '10088.516', '20531.422', '1140.793', '471.663', '5754.827', '5448.611', '2174.771', '21671.825', '1155.395', '541.003', '19900.758', '3759.997', '8217.318', '509.115', '4015.403', '4195.343', '1774.634', '26261.151', '1439.271', '1488.308', '1072.819', '10415.531', '849.281', '3239.607', '8955.554', '14029.826', '21748.852', '18833.57', '781.077', '958.785', '9305.049', '7811.809', '7100.133', '3607.101', '19943.126', '3424.656', '7247.431', '843.991', '1620.739', '26747.307', '10224.807', '11354.092', '3128.121', '15758.606', '5829.317']\n"
     ]
    }
   ],
   "source": [
    "# Make this code more flexible with list comprehensions\n",
    "var_name = \"gdpPercap\"\n",
    "out = [row[cnames.index(var_name)] for row in data]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640357f",
   "metadata": {},
   "source": [
    "## Motivating Numpy\n",
    "\n",
    "All of the above seems a little too much for working with retangular data in Python. And it is. So of course, there are more recent, modern and easy to work with strategies to work with data frames in Python. \n",
    "\n",
    "A first approach to facilitate working with Data Frames in Python comes through using `numpy` to convert nested lists in `arrays`. \n",
    "\n",
    "**If you coming from R, think about numpy arrays as matrices.**\n",
    "\n",
    "We will see more of numpy soon. But, let's see briefly how numpy works and the speed boost of using numpy to access data in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0580ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Guinea_Bissau', '39.21', '652.157'],\n",
       "       ['Bolivia', '52.505', '2961.229'],\n",
       "       ['Austria', '73.103', '20411.916'],\n",
       "       ['Malawi', '43.352', '575.447'],\n",
       "       ['Finland', '72.992', '17473.723'],\n",
       "       ['North_Korea', '63.607', '2591.853'],\n",
       "       ['Malaysia', '64.28', '5406.038'],\n",
       "       ['Hungary', '69.393', '10888.176'],\n",
       "       ['Congo', '52.502', '3312.788'],\n",
       "       ['Morocco', '57.609', '2447.909'],\n",
       "       ['Germany', '73.444', '20556.684'],\n",
       "       ['Ecuador', '62.817', '5733.625'],\n",
       "       ['Kuwait', '68.922', '65332.91'],\n",
       "       ['New_Zealand', '73.989', '17262.623'],\n",
       "       ['Mauritania', '52.302', '1356.671'],\n",
       "       ['Uganda', '47.619', '810.384'],\n",
       "       ['Equatorial Guinea', '42.96', '2469.167'],\n",
       "       ['Croatia', '70.056', '9331.712'],\n",
       "       ['Indonesia', '54.336', '1741.365'],\n",
       "       ['Canada', '74.903', '22410.746'],\n",
       "       ['Comoros', '52.382', '1314.38'],\n",
       "       ['Montenegro', '70.299', '7208.065'],\n",
       "       ['Slovenia', '71.601', '14074.582'],\n",
       "       ['Trinidad and Tobago', '66.828', '7866.872'],\n",
       "       ['Poland', '70.177', '8416.554'],\n",
       "       ['Lesotho', '50.007', '780.553'],\n",
       "       ['Italy', '74.014', '16245.209'],\n",
       "       ['Tunisia', '60.721', '3477.21'],\n",
       "       ['Kenya', '52.681', '1200.416'],\n",
       "       ['Gambia', '44.401', '680.133'],\n",
       "       ['Bosnia and Herzegovina', '67.708', '3484.779'],\n",
       "       ['Libya', '59.304', '12013.579'],\n",
       "       ['Greece', '73.733', '13969.037'],\n",
       "       ['Ghana', '52.341', '1044.582'],\n",
       "       ['Peru', '58.859', '5613.844'],\n",
       "       ['Turkey', '59.696', '4469.453'],\n",
       "       ['Reunion', '66.644', '4898.398'],\n",
       "       ['Sri_Lanka', '66.526', '1854.731'],\n",
       "       ['Cambodia', '47.903', '675.368'],\n",
       "       ['Bulgaria', '69.744', '6384.055'],\n",
       "       ['Lebanon', '65.866', '7269.216'],\n",
       "       ['Togo', '51.499', '1153.82'],\n",
       "       ['Yemen', '46.78', '1569.275'],\n",
       "       ['Jamaica', '68.749', '6197.645'],\n",
       "       ['Swaziland', '49.002', '3163.352'],\n",
       "       ['Chile', '67.431', '6703.289'],\n",
       "       ['Israel', '73.646', '14160.936'],\n",
       "       ['Algeria', '59.03', '4426.026'],\n",
       "       ['Czech_Republic', '71.511', '13920.011'],\n",
       "       ['Djibouti', '46.381', '2697.833'],\n",
       "       ['Singapore', '71.22', '17425.382'],\n",
       "       ['Nigeria', '43.581', '1488.309'],\n",
       "       ['Bangladesh', '49.834', '817.559'],\n",
       "       ['DRC', '44.544', '648.343'],\n",
       "       ['Cuba', '71.045', '6283.259'],\n",
       "       ['Namibia', '53.491', '3675.582'],\n",
       "       ['Sudan', '48.401', '1835.01'],\n",
       "       ['Syria', '61.346', '3009.288'],\n",
       "       ['Rwanda', '41.482', '675.669'],\n",
       "       ['Puerto Rico', '72.739', '10863.164'],\n",
       "       ['Albania', '68.433', '3255.367'],\n",
       "       ['Vietnam', '57.48', '1017.713'],\n",
       "       ['Mozambique', '40.38', '542.278'],\n",
       "       ['Mali', '43.413', '673.093'],\n",
       "       ['Saudi Arabia', '58.679', '20261.744'],\n",
       "       ['Liberia', '42.476', '604.814'],\n",
       "       ['Madagascar', '47.771', '1335.595'],\n",
       "       ['Chad', '46.774', '1165.454'],\n",
       "       ['Gabon', '51.221', '11529.865'],\n",
       "       ['Mauritius', '64.953', '4768.942'],\n",
       "       ['Zambia', '45.996', '1358.199'],\n",
       "       ['Romania', '68.291', '7300.17'],\n",
       "       ['Dominican Republic', '61.554', '2844.856'],\n",
       "       ['Egypt', '56.243', '3074.031'],\n",
       "       ['Senegal', '50.626', '1533.122'],\n",
       "       ['Oman', '58.443', '12138.562'],\n",
       "       ['Zimbabwe', '52.663', '635.858'],\n",
       "       ['Botswana', '54.598', '5031.504'],\n",
       "       [\"Cote d'Ivoire\", '48.436', '1912.825'],\n",
       "       ['Afghanistan', '37.479', '802.675'],\n",
       "       ['Mexico', '65.409', '7724.113'],\n",
       "       ['Sao Tome and Principe', '57.896', '1382.782'],\n",
       "       ['Myanmar', '53.322', '439.333'],\n",
       "       ['Switzerland', '75.565', '27074.334'],\n",
       "       ['United Kingdom', '73.923', '19380.473'],\n",
       "       ['Japan', '74.827', '17750.87'],\n",
       "       ['El Salvador', '59.633', '4431.847'],\n",
       "       ['India', '53.166', '1057.296'],\n",
       "       ['Thailand', '62.2', '3045.966'],\n",
       "       ['Bahrain', '65.606', '18077.664'],\n",
       "       ['Australia', '74.663', '19980.596'],\n",
       "       ['Mongolia', '55.89', '1692.805'],\n",
       "       ['Nepal', '48.986', '782.729'],\n",
       "       ['Iran', '58.637', '7376.583'],\n",
       "       ['Honduras', '57.921', '2834.413'],\n",
       "       ['Guinea', '43.24', '776.067'],\n",
       "       ['Venezuela', '66.581', '10088.516'],\n",
       "       ['Iceland', '76.511', '20531.422'],\n",
       "       ['Somalia', '40.989', '1140.793'],\n",
       "       ['Burundi', '44.817', '471.663'],\n",
       "       ['Panama', '67.802', '5754.827'],\n",
       "       ['Costa Rica', '70.181', '5448.611'],\n",
       "       ['Philippines', '60.967', '2174.771'],\n",
       "       ['Denmark', '74.37', '21671.825'],\n",
       "       ['Benin', '48.78', '1155.395'],\n",
       "       ['Eritrea', '45.999', '541.003'],\n",
       "       ['Belgium', '73.642', '19900.758'],\n",
       "       ['West Bank and Gaza', '60.329', '3759.997'],\n",
       "       ['South_Korea', '65.001', '8217.318'],\n",
       "       ['Ethiopia', '44.476', '509.115'],\n",
       "       ['Guatemala', '56.729', '4015.403'],\n",
       "       ['Colombia', '63.898', '4195.343'],\n",
       "       ['Cameroon', '48.129', '1774.634'],\n",
       "       ['United States', '73.478', '26261.151'],\n",
       "       ['Pakistan', '54.882', '1439.271'],\n",
       "       ['China', '61.785', '1488.308'],\n",
       "       ['Sierra Leone', '36.769', '1072.819'],\n",
       "       ['Slovak Republic', '70.696', '10415.531'],\n",
       "       ['Tanzania', '47.912', '849.281'],\n",
       "       ['Paraguay', '66.809', '3239.607'],\n",
       "       ['Argentina', '69.06', '8955.554'],\n",
       "       ['Spain', '74.203', '14029.826'],\n",
       "       ['Netherlands', '75.648', '21748.852'],\n",
       "       ['France', '74.349', '18833.57'],\n",
       "       ['Niger', '44.559', '781.077'],\n",
       "       ['Central African Republic', '43.867', '958.785'],\n",
       "       ['Serbia', '68.551', '9305.049'],\n",
       "       ['Iraq', '56.582', '7811.809'],\n",
       "       ['Uruguay', '70.782', '7100.133'],\n",
       "       ['Angola', '37.883', '3607.101'],\n",
       "       ['Sweden', '76.177', '19943.126'],\n",
       "       ['Nicaragua', '58.349', '3424.656'],\n",
       "       ['South Africa', '53.993', '7247.431'],\n",
       "       ['Burkina Faso', '44.694', '843.991'],\n",
       "       ['Haiti', '50.165', '1620.739'],\n",
       "       ['Norway', '75.843', '26747.307'],\n",
       "       ['Taiwan', '70.337', '10224.807'],\n",
       "       ['Portugal', '70.42', '11354.092'],\n",
       "       ['Jordan', '59.786', '3128.121'],\n",
       "       ['Ireland', '73.017', '15758.606'],\n",
       "       ['Brazil', '62.239', '5829.317']], dtype='<U24')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% -----------------------------------------\n",
    "# Numpy offers an efficiency boost, especially when indexing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Convert to a numpy array\n",
    "data_np = np.array(data)\n",
    "data_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f8bc6",
   "metadata": {},
   "source": [
    "### slicing data with numpy\n",
    "\n",
    "It allows for slicing both at the row and column indexes\n",
    "\n",
    "```\n",
    "        array[rows, columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23194d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['39.21', '52.505', '73.103', '43.352', '72.992', '63.607', '64.28',\n",
       "       '69.393', '52.502', '57.609', '73.444', '62.817', '68.922',\n",
       "       '73.989', '52.302', '47.619', '42.96', '70.056', '54.336',\n",
       "       '74.903', '52.382', '70.299', '71.601', '66.828', '70.177',\n",
       "       '50.007', '74.014', '60.721', '52.681', '44.401', '67.708',\n",
       "       '59.304', '73.733', '52.341', '58.859', '59.696', '66.644',\n",
       "       '66.526', '47.903', '69.744', '65.866', '51.499', '46.78',\n",
       "       '68.749', '49.002', '67.431', '73.646', '59.03', '71.511',\n",
       "       '46.381', '71.22', '43.581', '49.834', '44.544', '71.045',\n",
       "       '53.491', '48.401', '61.346', '41.482', '72.739', '68.433',\n",
       "       '57.48', '40.38', '43.413', '58.679', '42.476', '47.771', '46.774',\n",
       "       '51.221', '64.953', '45.996', '68.291', '61.554', '56.243',\n",
       "       '50.626', '58.443', '52.663', '54.598', '48.436', '37.479',\n",
       "       '65.409', '57.896', '53.322', '75.565', '73.923', '74.827',\n",
       "       '59.633', '53.166', '62.2', '65.606', '74.663', '55.89', '48.986',\n",
       "       '58.637', '57.921', '43.24', '66.581', '76.511', '40.989',\n",
       "       '44.817', '67.802', '70.181', '60.967', '74.37', '48.78', '45.999',\n",
       "       '73.642', '60.329', '65.001', '44.476', '56.729', '63.898',\n",
       "       '48.129', '73.478', '54.882', '61.785', '36.769', '70.696',\n",
       "       '47.912', '66.809', '69.06', '74.203', '75.648', '74.349',\n",
       "       '44.559', '43.867', '68.551', '56.582', '70.782', '37.883',\n",
       "       '76.177', '58.349', '53.993', '44.694', '50.165', '75.843',\n",
       "       '70.337', '70.42', '59.786', '73.017', '62.239'], dtype='<U24')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple slicing of rows and columns of your 2d array\n",
    "data_np[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd7bc7",
   "metadata": {},
   "source": [
    "## Indexing with Numpy is much faster!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "335e94ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35 µs ± 98.3 ns per loop (mean ± std. dev. of 10 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100000\n",
    "out1 = []\n",
    "for row in data:\n",
    "    out1.append(row[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf2a7243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.88 µs ± 120 ns per loop (mean ± std. dev. of 10 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100000\n",
    "out2 = [row[ind] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a85c866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 ns ± 56 ns per loop (mean ± std. dev. of 10 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100000\n",
    "out3 = data_np[:,ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aed9d2",
   "metadata": {},
   "source": [
    "## Introduction to Numpy\n",
    "\n",
    "`numpy` is at the core of many important python libraries. This is a extensive notebook, with a great deal of information about numpy. Primarily, we will cover: \n",
    "\n",
    "- Introduction to numpy, creating and manipulating arrays. \n",
    "- Efficency with numpy arrays\n",
    "- Vectorization\n",
    "- Broadcasting\n",
    "\n",
    "For more, go through your required readings. Both textbooks provide a comprehensive coverage of Numpy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275cd208",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "NumPy (short for Numerical Python) provides an efficient interface to store and operate on dense data buffers. In some ways, NumPy arrays are like Python’s built-in list type, but NumPy arrays provide much more efficient storage and data operations as the arrays grow larger in size and in dimensions. \n",
    "\n",
    "NumPy arrays form the core of nearly the entire ecosystem of data science tools in Python, so time spent learning to use NumPy effectively will be valuable no matter what aspect of data science interests you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d835e",
   "metadata": {},
   "source": [
    "## Basics of Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "93da0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5307c11f",
   "metadata": {},
   "source": [
    "#### Creating array from Python lists\n",
    "\n",
    "`np.array()` form the core building block to create array.\n",
    "\n",
    "- input: list\n",
    "- output: numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb9904e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 8, 5, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from a list of int elements\n",
    "np.array([1, 4, 8, 5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "382498a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can specify the type\n",
    "np.array([1, 2, 3, 4], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98fb1a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [4, 5, 6],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unlikely lists, NumPy arrays can explicitly be multidimensional\n",
    "nested_list = [range(i, i+3) for i in [2, 4, 6]]\n",
    "multi_array = np.array(nested_list)\n",
    "multi_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdbacf",
   "metadata": {},
   "source": [
    "### Numpy Arrays vs Built-in Lists\n",
    "\n",
    "We will see throughout this notebook why Numpy's arrays are more efficient than python built-in dtaa structures, like lists. \n",
    "\n",
    "A primary difference to keep in mind is how elements are stored:  \n",
    "\n",
    "- Numpy leans toward less flexibility and more efficiency. \n",
    "- Lists gives you more flexibility and less efficiency. \n",
    "\n",
    "This is a trade-off between allowing a container to store **heterogenous** data types, which lists allow you to do, compared to **homogenous** data storage provided by numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba5f1812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beep', 'false', False, 1, 1.2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lists support heterogenous data types. It needs to store this information somewhere for every element!\n",
    "list_ =  [\"beep\", \"false\", False, 1, 1.2]\n",
    "list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876f71da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True,  True],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpys only support homogenous data types. Stores elements and this information in a single place!\n",
    "numpy_boolean = np.array([[True, 0], [True, \"TRUE\"], [False, True]], dtype=bool)\n",
    "numpy_boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0de12b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['True', '0'],\n",
       "       ['True', 'TRUE'],\n",
       "       ['False', 'True']], dtype='<U5')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see with string\n",
    "numpy_boolean = np.array([[True, 0], [True, \"TRUE\"], [False, True]], dtype=str)\n",
    "numpy_boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86c486",
   "metadata": {},
   "source": [
    "See this paragraph from your PDS textbook: \n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "\n",
    "At the implementation level, the array essentially contains a single pointer to one contiguous block of data. The Python list, on the other hand, contains a pointer to a block of pointers, each of which in turn points to a full Python object like the Python integer we saw earlier. Again, the advantage of the list is flexibility: because each list element is a full structure containing both data and type information, the list can be filled with data of any desired type. Fixed-type NumPy-style arrays lack this flexibility, but are much more efficient for storing and manipulating data.\n",
    "\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5e9f3",
   "metadata": {},
   "source": [
    "### Creating Arrays from xcratch\n",
    "\n",
    "Numpy also offer a set of distinct methods to create arrays from scratch, instead of converting from a list. Some options: \n",
    "\n",
    "- `numpy.arange()` will create arrays with regularly incrementing values\n",
    "- `numpy.linspace()` will create arrays with a specified number of elements, and spaced equally between the specified beginning and end values.\n",
    "- `numpy.zeros()` will create an array filled with 0 values with the specified shape.\n",
    "- `numpy.ones()` will create an array filled with 1 values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d1ff4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arange a incremental sequence\n",
    "np.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdbe994d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.44444444, 1.88888889, 2.33333333, 2.77777778,\n",
       "       3.22222222, 3.66666667, 4.11111111, 4.55555556, 5.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array with equally spaced intervals\n",
    "np.linspace(1,5,10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2267b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array filled with 0 values with the specified shape.\n",
    "np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85dc7bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an array filled with 1 values\n",
    "np.ones((3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b5264",
   "metadata": {},
   "source": [
    "#### Random numbers with numpy.random\n",
    "\n",
    "Numpy allows for the generation of number from several known mathematical distributions. Some examples below: \n",
    "\n",
    "- `numpy.random.random()` will create an array of uniformly distributed random values between 0 and 1\n",
    "- `numpy.random.normal()` will create an array of normally distributed random values with mean 0 and standard deviation 1\n",
    "- `numpy.random.randint()` will create an array of random integers from a pre-defined interval\n",
    "\n",
    "Other options that should be self-explanatory: \n",
    "\n",
    "- `numpy.random.poisson()`\n",
    "- `numpy.random.binomial()`\n",
    "- `numpy.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa6c00f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function random:\n",
      "\n",
      "random(...) method of numpy.random.mtrand.RandomState instance\n",
      "    random(size=None)\n",
      "    \n",
      "    Return random floats in the half-open interval [0.0, 1.0). Alias for\n",
      "    `random_sample` to ease forward-porting to the new random API.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from a random sequence between 0 and 1\n",
    "help(np.random.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15747743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79101286, 0.85447581, 0.90415383, 0.89677082, 0.99745146,\n",
       "       0.45545068, 0.12237682, 0.65271547, 0.08551359, 0.46130489])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how it works\n",
    "np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef5e2ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.57734582, -2.49535403, -1.85371445],\n",
       "       [-0.03921928,  1.66423104,  0.57046832],\n",
       "       [-0.38373116, -0.43965859, -1.12595718]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from a normal distribution\n",
    "np.random.normal(0, 1, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fb4e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(np.random.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed9c28a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 9, 3],\n",
       "       [0, 0, 3],\n",
       "       [7, 5, 6]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random integers from a pre-defined interval\n",
    "np.random.randint(0, 10, (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6a413",
   "metadata": {},
   "source": [
    "### Retrieving attributtes from Arrays\n",
    "\n",
    "- `numpy.dim()`: generates the number of dimension\n",
    "- `numpy.shape()`: generates the size of each dimension\n",
    "- `numpy.size()`: generates the full size of a array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf1e2e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim:  3\n",
      "shape: (2, 3, 4)\n",
      "size:  24\n"
     ]
    }
   ],
   "source": [
    "# generate a 3-d array from a nested list\n",
    "array_3d = np.array([ # first element of 1 dimension\n",
    "                    [ \n",
    "                    [1,2,3,4],\n",
    "                    [2,3,4,1],\n",
    "                    [-1,1,2,1]],\n",
    "                    [# second element of 1 dimension\n",
    "                    [1,2,3,4],\n",
    "                    [2,3,4,1],\n",
    "                    [-1,1,2,1]]])\n",
    "\n",
    "# information\n",
    "print(\"ndim: \", array_3d.ndim)\n",
    "print(\"shape:\", array_3d.shape)\n",
    "print(\"size: \", array_3d.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c08ebd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 2,  3,  4,  1],\n",
       "       [-1,  1,  2,  1]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_3d[0][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd525e",
   "metadata": {},
   "source": [
    "### Reshaping Arrays\n",
    "\n",
    "You can reshape array, as soon as you input the appropriate new dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9a57842c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  2,  3],\n",
       "       [ 4,  1, -1,  1,  2,  1],\n",
       "       [ 1,  2,  3,  4,  2,  3],\n",
       "       [ 4,  1, -1,  1,  2,  1]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new 2d array\n",
    "array_3d.reshape(4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e1f6e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 2,  3,  4,  1],\n",
       "       [-1,  1,  2,  1],\n",
       "       [ 1,  2,  3,  4],\n",
       "       [ 2,  3,  4,  1],\n",
       "       [-1,  1,  2,  1]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or 6d array\n",
    "array_3d.reshape(6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "faf89341",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 24 into shape (6,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## but you need to provide the proper dimension\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m array_3d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 24 into shape (6,6)"
     ]
    }
   ],
   "source": [
    "## but you need to provide the proper dimension\n",
    "array_3d.reshape(6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "812dace4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2, -1,  1,  2, -1],\n",
       "       [ 2,  3,  1,  2,  3,  1],\n",
       "       [ 3,  4,  2,  3,  4,  2],\n",
       "       [ 4,  1,  1,  4,  1,  1]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## transpose an array. Very common property in matrix operations. \n",
    "array_3d.reshape(6, 4).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e604d96",
   "metadata": {},
   "source": [
    "### Array Indexing and Slicing\n",
    "\n",
    "Numpy indexing is quite similar to list indexing in Python. And we covered lists and indexing last week.\n",
    "\n",
    "In a one-dimensional array, you can access the ith value (**counting from zero**) by specifying the desired numerical index. \n",
    "\n",
    "```\n",
    "M[element_index]\n",
    "```\n",
    "\n",
    "For n-dimensional arrays, you can access elements with a tuple for row and column index. \n",
    "\n",
    "```\n",
    "M[row, columne]\n",
    "```\n",
    "\n",
    "You can use the `:` shortcut for slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53a7ceb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77, 73, 65, 58, 74],\n",
       "       [ 1, 63, 42, 77, 91],\n",
       "       [78,  2, 20,  3, 78],\n",
       "       [98, 97, 80, 82, 51],\n",
       "       [35, 97, 32, 61, 77]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an 5d array\n",
    "X = np.random.randint(0, 100, (5, 5))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e665d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77, 73, 65, 58, 74])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index first row \n",
    "X[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cc5444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77,  1, 78, 98, 35])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index first column\n",
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54ec4fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index a specific cell \n",
    "X[0,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0125a325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77, 73, 65],\n",
       "       [ 1, 63, 42],\n",
       "       [78,  2, 20]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice rows and columns\n",
    "X[0:3,0:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b038edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 97, 32, 61, 77])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last row\n",
    "X[-1,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae637ee",
   "metadata": {},
   "source": [
    "### Reassignment\n",
    "\n",
    "As we just saw, `numpy` makes your life easier for access elements on a retangular type of data -- when compared to nested lists. \n",
    "\n",
    "In the same venue, `numpy` uses the benefits of its easy indexing scheme to facilate reassignment of values. \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> \n",
    "\n",
    "**Importance:**\n",
    "    \n",
    "Using numpy for reassignment will be at the core of your data wrangling work with pandas!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18c8e43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start creating a array\n",
    "X = np.zeros(50).reshape(10,5)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31b78da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[999.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reassign data values by referencing positions\n",
    "X[0,0] = 999\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0160b0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[999., 999., 999., 999., 999.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.],\n",
       "       [999.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reassign whole ranges of values\n",
    "X[0,:] = 999\n",
    "X\n",
    "\n",
    "# by row\n",
    "X[:,0] = 999\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "839bc773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9, -0.3,  0.5,  0.6,  1.2],\n",
       "       [ 0.2,  0.4,  0.9,  1.1,  1.3],\n",
       "       [-0.9, -2.2,  0.7, -1. ,  0.1],\n",
       "       [ 2. , -1.5, -0.5, -1.5, -0.5],\n",
       "       [-0. , -0.4,  0.6,  1.1, -1. ],\n",
       "       [-1.2,  0.5,  1.2, -2.7,  1.2],\n",
       "       [ 1.2,  0.4,  0.6,  0.7, -0.9],\n",
       "       [ 1.6,  0.2, -0.3, -0.4, -1.3],\n",
       "       [-1. ,  0. ,  0.4,  0.8,  0.1],\n",
       "       [ 0.1,  1.1, -0.5,  1.6, -0.9]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reassignment using boolean values. \n",
    "D = np.random.randn(50).reshape(10,5).round(1)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f9e5d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1.],\n",
       "       [1., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reassignment\n",
    "D[D > 0] = 1\n",
    "D[D <= 0] = 0\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe3cf9",
   "metadata": {},
   "source": [
    "#### np.where\n",
    "\n",
    "`np.where()` can check whether elements meet a condition and then pull one element if the condition is met and another if not. It uses this syntax:\n",
    "\n",
    "`np.where(condition, replacement_if_true, replacement_if_false)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e92eaba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1, -0.6,  1.1, -0.3,  0.8],\n",
       "       [-0.3,  0.5,  0.1, -0.2, -2.3],\n",
       "       [ 2. ,  0.3,  1.8,  2.5, -0.4],\n",
       "       [-0.5,  0.2, -0.8,  0.5,  0.9],\n",
       "       [ 0.9, -0.7,  0.7, -0.5,  1.1],\n",
       "       [-0.3,  0.2, -1.3, -0.7, -1.1],\n",
       "       [ 0.4, -0.9,  1. ,  0.2,  0.2],\n",
       "       [ 0.1, -0.8,  0.6,  0.5, -0.2],\n",
       "       [ 0.7, -0.2,  0.2,  0.8, -0.8],\n",
       "       [ 1.4,  0.4, -0.7,  1.1, -0.6]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using where \"ifelse()-like\" method\n",
    "D = np.random.randn(50).reshape(10,5).round(1) # Generate some random numbers again\n",
    "D # Before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3f1c929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 1],\n",
       "       [1, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(D>0,1,0) # After"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f581fa7",
   "metadata": {},
   "source": [
    "#### np.select\n",
    "\n",
    "`np.select` allows  for element-wise selection reassignment, just like case_when from R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e880563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['-1', '-1', '1', '-1', '1'],\n",
       "       ['-1', '1', '1', '-1', '-1'],\n",
       "       ['1', '1', '1', '1', '-1'],\n",
       "       ['-1', '1', '-1', '1', '1'],\n",
       "       ['1', '-1', '1', '-1', '1'],\n",
       "       ['-1', '1', '-1', '-1', '-1'],\n",
       "       ['1', '-1', '1', '1', '1'],\n",
       "       ['1', '-1', '1', '1', '-1'],\n",
       "       ['1', '-1', '1', '1', '-1'],\n",
       "       ['1', '1', '-1', '1', '-1']], dtype='<U21')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic usage: np.select(conditions, choices, default=0)\n",
    "\n",
    "# create conditions\n",
    "conditions = [D < 0, D == 0, D > 0]\n",
    "\n",
    "# element wise reassignment\n",
    "choices = [-1, 0, 1]\n",
    "\n",
    "# run np.select\n",
    "np.select(conditions, choices, default='unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b668ce",
   "metadata": {},
   "source": [
    "### Concatenating and Splitting Arrays\n",
    "\n",
    "We can easily stack and grow numpy arrays. These are the main functions for concatenating arrays: \n",
    "\n",
    "- `np.concatenate([array,array],axis=0)`: concatenate by rows\n",
    "- `np.concatenate([array,array],axis=1)`: concatenate by columns \n",
    "\n",
    "The same behavior can be achieved with `np.vstack([array,array])` or `np.hstack([m1,m2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61424611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays\n",
    "X = np.random.randint(0, 100, (5, 2))\n",
    "Y = np.random.randint(0, 100, (5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a0e8ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 82],\n",
       "       [52,  1],\n",
       "       [29, 67],\n",
       "       [10, 97],\n",
       "       [33, 49],\n",
       "       [55,  5],\n",
       "       [89, 52],\n",
       "       [ 4, 91],\n",
       "       [52, 60],\n",
       "       [62, 98]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row bind\n",
    "np.concatenate([X,Y],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f7618f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 82, 55,  5],\n",
       "       [52,  1, 89, 52],\n",
       "       [29, 67,  4, 91],\n",
       "       [10, 97, 52, 60],\n",
       "       [33, 49, 62, 98]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column bind\n",
    "np.concatenate([X,Y],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7130763",
   "metadata": {},
   "source": [
    "### View vs Copy in Array\n",
    "\n",
    "An sutil, but interesting point, about numpy arrays refers to the default behavior for slicing. When we slice an array\n",
    "we **_do not copy fully the array_**, rather we get a \"**view**\" of the array.\n",
    "\n",
    "**Why this matters?**: any change in the view will affect the original array\n",
    "    \n",
    "**Solution**: Make a copy. \n",
    "\n",
    "As noted in the [reading for this week](https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html): \n",
    "\n",
    "> One important—and extremely useful—thing to know about array slices is that they return views rather than copies of the array data. **This is one area in which NumPy array slicing differs from Python list slicing: in lists, slices will be copies**\n",
    "\n",
    "We need to use the `.copy()` method from numpy to create a new array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e2eae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 2, 3] [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# from lists\n",
    "x = [1, 2, 3]\n",
    "\n",
    "# full slice is enough on lists\n",
    "y=x[:] \n",
    "\n",
    "# modify\n",
    "y[0]=100\n",
    "\n",
    "#print\n",
    "print(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f7477f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58 17 34 91 46]] [[58 17 34 91 46]]\n"
     ]
    }
   ],
   "source": [
    "# for arrays\n",
    "X = np.random.randint(0, 100, (1, 5))\n",
    "\n",
    "# slice\n",
    "X_sub = X[:]\n",
    "print(X, X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3f41ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000   17   34   91   46]] [[1000   17   34   91   46]]\n"
     ]
    }
   ],
   "source": [
    "# modify\n",
    "X_sub[0][0] = 1000\n",
    "\n",
    "# print\n",
    "print(X, X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c0e832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 70 57 52 86]] [[1000   70   57   52   86]]\n"
     ]
    }
   ],
   "source": [
    "# need to copy\n",
    "# for arrays\n",
    "X = np.random.randint(0, 100, (1, 5))\n",
    "\n",
    "# slice.copy()\n",
    "X_sub = X[:3].copy()\n",
    "\n",
    "# modify\n",
    "X_sub[0][0] = 1000\n",
    "\n",
    "# print\n",
    "print(X, X_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50719e40",
   "metadata": {},
   "source": [
    "## Vectorization (or ufunc in Numpy)\n",
    "\n",
    "A critical reason for `numpy` popularity among data scientists is its efficiency.  NumPy provides an easy to implement and flexible interface to optimized computation with arrays of data. The key to making it fast is to use built-in (or easy to implement) vectorized operations. \n",
    "\n",
    "\n",
    "**What are vectorized functions?** A vectorize function allows for efficient processing of entire arrays or collections of data elements in a **single operation**. In plain english, it applies a particular operation in one-shot over a sequence of object. Vectorize functions are efficient because it allows us to avoid looping through entire collections of data. \n",
    "\n",
    "Let's compare the peformance of vectorized function and a loop, using a example from your [reading for this week](https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28f8e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=1701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "853df29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "def compute_reciprocals(values):\n",
    "    output = np.empty(len(values))\n",
    "    for i in range(len(values)):\n",
    "        # notice the loop\n",
    "        output[i] = 1.0 / values[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee01b258",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create a list and apply\u001b[39;00m\n\u001b[1;32m      2\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mvalues\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'list'"
     ]
    }
   ],
   "source": [
    "# create a list and apply\n",
    "values = list(rng.integers(1, 10, size=5))\n",
    "\n",
    "# error because lists do not support vectorize operations\n",
    "1.0/values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c612fcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11111111, 0.25      , 1.        , 0.11111111, 0.2       ])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try with the function\n",
    "compute_reciprocals(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "426cd60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple implementation\n",
    "big_array = list(rng.integers(1, 100, size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b848a4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673 µs ± 13.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 compute_reciprocals(big_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db6a3bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.5 µs ± 8.18 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# vectorize implementation\n",
    "%timeit -n 1000 np.divide(1.0 , big_array) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad75e8c",
   "metadata": {},
   "source": [
    " ### <span style=\"color:red\"> ALERT: What just happened?</span>\n",
    "\n",
    "NumPy provides built-in vectorized routines as methods for `np.arrays`. This vectorized approach is designed to push the loop into the compiled layer that underlies NumPy, leading to much faster execution.\n",
    "\n",
    "\n",
    "These built-in vectorize methods are called `ufuncs` (or \"universal functions\"). Numpy comes baked in with a large number those vectorized operations. [See here for a detailed list.](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.math.html) \n",
    "\n",
    "The [google colab notebook](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.03-Computation-on-arrays-ufuncs.ipynb) from your reading also provides a in-depth coverage of universal functions in `numpy`. Check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57870ddd",
   "metadata": {},
   "source": [
    "### Building vectorized functions\n",
    "\n",
    "We can take advantage of numpy vectorize approach, and very easily vectorise our user-defined functions. \n",
    "\n",
    "Consider the following function that yields a different string when input `a` is larger/smaller than input `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2e8b844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigsmall(a,b):\n",
    "    if a > b:\n",
    "        return \"A is larger\"\n",
    "    else:\n",
    "        return \"B is larger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7d2cada6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B is larger'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigsmall(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "438a13ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.vectorize at 0x1078e6c90>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vectorized version of the function\n",
    "vec_bigsmall = np.vectorize(bigsmall)\n",
    "vec_bigsmall "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a5c10",
   "metadata": {},
   "source": [
    "The vectorization here brings two main advantages: \n",
    "\n",
    "- Advantage 1: it allows us to apply the function to a collection without using loops. \n",
    "- Advantage 2: it does is in a vectorize manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ec9f7b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Advantage 1. Avoid the loops\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bigsmall([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[180], line 2\u001b[0m, in \u001b[0;36mbigsmall\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbigsmall\u001b[39m(a,b):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a \u001b[38;5;241m>\u001b[39m b:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA is larger\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# Advantage 1. Avoid the loops\n",
    "bigsmall([0,2,5,7,0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "471a7105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B is larger', 'B is larger', 'A is larger', 'A is larger',\n",
       "       'B is larger'], dtype='<U11')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize\n",
    "vec_bigsmall([0,2,5,7,0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b690b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advantage II: vectorize, means faster\n",
    "# write a function to run element-wise\n",
    "def bigsmall_el_wise(a_collection, b):\n",
    "    container = []\n",
    "    for a in a_collection:\n",
    "        if a > b:\n",
    "            container.append(\"A is larger\")\n",
    "        else:\n",
    "            container.append(\"B is larger\")\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086759e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating some random data\n",
    "a_collection = np.random.rand(1000000)\n",
    "b = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1608738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 µs ± 12.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 vec_bigsmall(big_array, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0f1949bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 µs ± 13.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 bigsmall_el_wise(big_array, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d0e7b",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8bcafd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Broadcasting** makes it possible for operations to be performed on arrays of mismatched shapes.\n",
    "\n",
    "Broadcasting describes how numpy treats arrays with different shapes during arithmetic operations. \n",
    "\n",
    "The idea is to wrangle data so that operations can occur element-wise.\n",
    "\n",
    "\n",
    "**Overall:** subject to certain constraints, the smaller array is \"broadcast\" across the larger array so that they have compatible shapes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95e8fa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For example, say we have a numpy array of dimensions (5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a24c6d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ \n",
    "\\begin{bmatrix} 1\\\\2\\\\3\\\\4\\\\5\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847b372",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now say we wanted to add the values in this array by 5\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} 1\\\\2\\\\3\\\\4\\\\5\\end{bmatrix} + 5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b34b7c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Broadcasting \"pads\" the array of 5 (which is shape = 1,1), and extends it so that it has similar dimension to the larger array in which the computation is being performed.\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} 1\\\\2\\\\3\\\\4\\\\5\\end{bmatrix} + \\begin{bmatrix} 5\\\\\\color{lightgrey}{5}\\\\\\color{lightgrey}{5}\\\\\\color{lightgrey}{5}\\\\\\color{lightgrey}{5}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} 1 + 5\\\\2 + 5\\\\3 + 5\\\\4 + 5\\\\5 + 5\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} 6\\\\7\\\\8\\\\9\\\\10\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fb664fa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([1,2,3,4,5])\n",
    "A + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e4f47",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By 'broadcast', we mean that the smaller array is made to match the size of the larger array in order to allow for element-wise manipulations.\n",
    "\n",
    "### How it works:\n",
    "\n",
    "- Shapes of the two arrays are compared _element-wise_. \n",
    "- Dimensions are considered in reverse order, starting with the trailing dimensions, and working forward \n",
    "- We are stretching the smaller array by making copies of its elements. However, and this is key, no actual copies are made, making the method computationally and memory efficient.\n",
    "\n",
    "A general **Rule of thumb**: All corresponding dimension of the arrays must be compatible or one of the two dimensions is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead95543",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Rules of Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71420b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Broadcasting in NumPy follows a strict set of rules to determine the interaction between the two arrays (from [reading](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html)):\n",
    "\n",
    "\n",
    "### Rule 1\n",
    "> If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.\n",
    "\n",
    "### Rule 2\n",
    "\n",
    "> If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.\n",
    "\n",
    "### Rule 3 \n",
    "\n",
    "> If in any dimension the sizes disagree and neither is equal to 1, an error is raised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd698f89",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4d61d2a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3) + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e701d5e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\texttt{np.arange(3)} = \\begin{bmatrix} 0&1&2\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br> \n",
    "\n",
    "$$\n",
    "\\texttt{5}  = \\begin{bmatrix} 5 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br> \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 0&1&2\\end{bmatrix} + \\begin{bmatrix} 5 & \\color{lightgrey}{5} & \\color{lightgrey}{5}\\end{bmatrix} = \\begin{bmatrix} 5 & 6 & 7\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fc4bd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "01036dde",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((3,3)) + np.arange(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb5b7e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\texttt{np.ones((3,3)) = }\\begin{bmatrix} 1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\texttt{np.arange(3)} = \\begin{bmatrix} 0 & 1 & 2\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix} + \n",
    "\\begin{bmatrix} 0 & 1 & 2\\\\ \\color{lightgrey}{0} & \\color{lightgrey}{1} & \\color{lightgrey}{2} \\\\  \\color{lightgrey}{0} & \\color{lightgrey}{1} & \\color{lightgrey}{2}\\end{bmatrix}  = \n",
    "\\begin{bmatrix} 1 & 2 & 3\\\\ 1 & 2 & 3 \\\\ 1 & 2 & 3 \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a350533",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "612553a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3).reshape(3,1) + np.arange(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a6f5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\texttt{np.arange(3).reshape(3,1)} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 2\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\texttt{np.arange(3)} = \\begin{bmatrix} 0 & 1 & 2\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 0 & \\color{lightgrey}{0} & \\color{lightgrey}{0} \\\\ 1 & \\color{lightgrey}{1} & \\color{lightgrey}{1} \\\\  2 & \\color{lightgrey}{2} & \\color{lightgrey}{2}\\end{bmatrix} +\n",
    "\\begin{bmatrix} 0 & 1 & 2\\\\ \\color{lightgrey}{0} & \\color{lightgrey}{1} & \\color{lightgrey}{2} \\\\  \\color{lightgrey}{0} & \\color{lightgrey}{1} & \\color{lightgrey}{2}\\end{bmatrix}  =\n",
    "\\begin{bmatrix} 0 & 1 & 2\\\\ 1 &2&3 \\\\ 2& 3 & 4\\end{bmatrix} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350b04b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Example 4\n",
    "\n",
    "Example of dimensional disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "21f895c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((4,7)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "204d0947",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,7) (7,9) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[198], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m7\u001b[39m))  \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros( (\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m9\u001b[39m) )\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,7) (7,9) "
     ]
    }
   ],
   "source": [
    "np.ones((4,7))  + np.zeros( (7,9) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddea741",
   "metadata": {},
   "source": [
    "#### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a895ac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.ones((3, 2))\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7c59fed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(3)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7c7c547d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m M \u001b[38;5;241m+\u001b[39m a\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (3,) "
     ]
    }
   ],
   "source": [
    "M + a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34fc33a",
   "metadata": {},
   "source": [
    "#### In practice: Mean Centering a array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "65310bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21539496, 0.14646488, 0.30907838],\n",
       "       [0.60371727, 0.21537589, 0.68194277],\n",
       "       [0.63833831, 0.72524305, 0.28385588],\n",
       "       [0.19813106, 0.89265894, 0.77541369],\n",
       "       [0.59011527, 0.16661737, 0.42753666],\n",
       "       [0.99338948, 0.73362274, 0.06922053],\n",
       "       [0.72288873, 0.03344708, 0.61698078],\n",
       "       [0.87205533, 0.43981373, 0.19324654],\n",
       "       [0.00129213, 0.41930223, 0.68320364],\n",
       "       [0.77421512, 0.08673353, 0.73662498]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.random((10, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3902fdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56095377, 0.38592794, 0.47771038])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xmean = X.mean(0)\n",
    "Xmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c636214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "## Shape\n",
    "print(X.shape)\n",
    "print(Xmean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2da444b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise operation\n",
    "Xcentered = X - Xmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3855e0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34555881, -0.23946306, -0.16863201],\n",
       "       [ 0.0427635 , -0.17055206,  0.20423238],\n",
       "       [ 0.07738454,  0.33931511, -0.19385451],\n",
       "       [-0.36282271,  0.50673099,  0.29770331],\n",
       "       [ 0.0291615 , -0.21931057, -0.05017372],\n",
       "       [ 0.43243571,  0.3476948 , -0.40848985],\n",
       "       [ 0.16193497, -0.35248087,  0.1392704 ],\n",
       "       [ 0.31110156,  0.05388578, -0.28446385],\n",
       "       [-0.55966164,  0.03337429,  0.20549325],\n",
       "       [ 0.21326135, -0.29919441,  0.2589146 ]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcentered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17de240",
   "metadata": {},
   "source": [
    "# The rest of this notebook will not be covered in class. Go through by yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaaa3e5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba9eac",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Numpy provides a data class for missing values (i.e. `nan` == \"Not a Number\", see [here](https://en.wikipedia.org/wiki/NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "283f2301",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 9., 1., 7., 8.],\n",
       "       [6., 2., 5., 6., 6.],\n",
       "       [4., 1., 9., 8., 2.],\n",
       "       [8., 5., 4., 9., 6.],\n",
       "       [8., 8., 2., 9., 5.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.random.randint(1,10,25).reshape(5,5) + .0\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b545d9c3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4., nan,  1., nan, nan],\n",
       "       [nan,  2.,  5., nan, nan],\n",
       "       [ 4.,  1., nan, nan,  2.],\n",
       "       [nan,  5.,  4., nan, nan],\n",
       "       [nan, nan,  2., nan,  5.]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[Y > 5] = np.nan\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ce79a090",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3e618a1b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False,  True,  True],\n",
       "       [ True, False, False,  True,  True],\n",
       "       [False, False,  True,  True, False],\n",
       "       [ True, False, False,  True,  True],\n",
       "       [ True,  True, False,  True, False]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scan for missing values\n",
    "np.isnan(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "52968186",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False, False],\n",
       "       [False,  True,  True, False, False],\n",
       "       [ True,  True, False, False,  True],\n",
       "       [False,  True,  True, False, False],\n",
       "       [False, False,  True, False,  True]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~np.isnan(Y) # are not NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27626a7f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we have missing values, we'll run into issues when computing across the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ae07b62c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f24516",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To get around this, we need to use special version of the methods that compensate for the existence of `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d34df6a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1818181818181817"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "31e5900d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/10_nyhkn3nv_rrbnd8f_fr940000gp/T/ipykernel_31209/1376022794.py:1: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(Y,axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.        , 2.66666667, 3.        ,        nan, 3.5       ])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(Y,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "894349b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.        , 3.18181818, 1.        , 3.18181818, 3.18181818],\n",
       "       [3.18181818, 2.        , 5.        , 3.18181818, 3.18181818],\n",
       "       [4.        , 1.        , 3.18181818, 3.18181818, 2.        ],\n",
       "       [3.18181818, 5.        , 4.        , 3.18181818, 3.18181818],\n",
       "       [3.18181818, 3.18181818, 2.        , 3.18181818, 5.        ]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean impute the missing values\n",
    "Y[np.where(np.isnan(Y))] = np.nanmean(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556e470",
   "metadata": {},
   "source": [
    "### Structured Data: NumPy’s Structured Arrays\n",
    "\n",
    "Out of the box, numpy arrays can only handle one data class at a time. Most times we will use heterogenous data types -- spreadsheet with name, age, gender, address, etc..\n",
    "\n",
    "This short section shows you how to use `NumPy’s structured arrays` to get around of this limitation. \n",
    "\n",
    "Let's started creating a some lists. Imagine these are columns on your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab151dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists\n",
    "name = ['Alice', 'Bob', 'Cathy', 'Doug']\n",
    "age = [25, 45, 37, 19]\n",
    "weight = [55.0, 85.5, 68.0, 61.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nest these lists\n",
    "nested_list = [name, age, weight]\n",
    "nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a numpy array\n",
    "array_nested_list = np.array(nested_list).T\n",
    "array_nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see data type - all data treated as strings. \n",
    "array_nested_list.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e18776",
   "metadata": {},
   "source": [
    "In case you which to preserve the preserve the data types for each variables, you could use structured arrays. These are almost like a less flexible dictionary. \n",
    "\n",
    "You need to follow three steps: \n",
    "\n",
    "- Create a empty structure with pre-defined size\n",
    "- Provide names for the 'collumns'\n",
    "- Provide types for the collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffe508",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(4, dtype={'names':('name', 'age', 'weight'),\n",
    "                             'formats':('U10', 'i', 'f')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5939ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the skeleton of the structure\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add information\n",
    "data['name'] = name\n",
    "data['age'] = age\n",
    "data['weight'] = weight\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then you can access prety much like dictions\n",
    "data[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5735ce",
   "metadata": {},
   "source": [
    "Though possible to deal with heterogeneous data frames using numpy, there is a lot of overhead to constructing a data object. \n",
    "\n",
    "**As such, we'll use Pandas series and DataFrames to deal with heterogeneous data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39f1cc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern '_week_5_numpy.ipynb' matched no files\r\n",
      "This application is used to convert notebook files (*.ipynb)\r\n",
      "        to various other formats.\r\n",
      "\r\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\r\n",
      "\r\n",
      "Options\r\n",
      "=======\r\n",
      "The options below are convenience aliases to configurable class-options,\r\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\r\n",
      "To see all configurable class-options for some <cmd>, use:\r\n",
      "    <cmd> --help-all\r\n",
      "\r\n",
      "--debug\r\n",
      "    set log level to logging.DEBUG (maximize logging output)\r\n",
      "    Equivalent to: [--Application.log_level=10]\r\n",
      "--show-config\r\n",
      "    Show the application's configuration (human-readable format)\r\n",
      "    Equivalent to: [--Application.show_config=True]\r\n",
      "--show-config-json\r\n",
      "    Show the application's configuration (json format)\r\n",
      "    Equivalent to: [--Application.show_config_json=True]\r\n",
      "--generate-config\r\n",
      "    generate default config file\r\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\r\n",
      "-y\r\n",
      "    Answer yes to any questions instead of prompting.\r\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\r\n",
      "--execute\r\n",
      "    Execute the notebook prior to export.\r\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\r\n",
      "--allow-errors\r\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\r\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\r\n",
      "--stdin\r\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\r\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\r\n",
      "--stdout\r\n",
      "    Write notebook output to stdout instead of files.\r\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\r\n",
      "--inplace\r\n",
      "    Run nbconvert in place, overwriting the existing notebook (only\r\n",
      "            relevant when converting to notebook format)\r\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\r\n",
      "--clear-output\r\n",
      "    Clear output of current file and save in place,\r\n",
      "            overwriting the existing notebook.\r\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\r\n",
      "--no-prompt\r\n",
      "    Exclude input and output prompts from converted document.\r\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\r\n",
      "--no-input\r\n",
      "    Exclude input cells and output prompts from converted document.\r\n",
      "            This mode is ideal for generating code-free reports.\r\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\r\n",
      "--allow-chromium-download\r\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\r\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\r\n",
      "--disable-chromium-sandbox\r\n",
      "    Disable chromium security sandbox when converting to PDF..\r\n",
      "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\r\n",
      "--show-input\r\n",
      "    Shows code input. This flag is only useful for dejavu users.\r\n",
      "    Equivalent to: [--TemplateExporter.exclude_input=False]\r\n",
      "--embed-images\r\n",
      "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\r\n",
      "    Equivalent to: [--HTMLExporter.embed_images=True]\r\n",
      "--sanitize-html\r\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\r\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html=True]\r\n",
      "--log-level=<Enum>\r\n",
      "    Set the log level by value or name.\r\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\r\n",
      "    Default: 30\r\n",
      "    Equivalent to: [--Application.log_level]\r\n",
      "--config=<Unicode>\r\n",
      "    Full path of a config file.\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--JupyterApp.config_file]\r\n",
      "--to=<Unicode>\r\n",
      "    The export format to be used, either one of the built-in formats\r\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\r\n",
      "            or a dotted object name that represents the import path for an\r\n",
      "            ``Exporter`` class\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--NbConvertApp.export_format]\r\n",
      "--template=<Unicode>\r\n",
      "    Name of the template to use\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--TemplateExporter.template_name]\r\n",
      "--template-file=<Unicode>\r\n",
      "    Name of the template file to use\r\n",
      "    Default: None\r\n",
      "    Equivalent to: [--TemplateExporter.template_file]\r\n",
      "--theme=<Unicode>\r\n",
      "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\r\n",
      "    as prebuilt extension for the lab template)\r\n",
      "    Default: 'light'\r\n",
      "    Equivalent to: [--HTMLExporter.theme]\r\n",
      "--sanitize_html=<Bool>\r\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\r\n",
      "    should be set to True by nbviewer or similar tools.\r\n",
      "    Default: False\r\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html]\r\n",
      "--writer=<DottedObjectName>\r\n",
      "    Writer class used to write the\r\n",
      "                                        results of the conversion\r\n",
      "    Default: 'FilesWriter'\r\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\r\n",
      "--post=<DottedOrNone>\r\n",
      "    PostProcessor class used to write the\r\n",
      "                                        results of the conversion\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\r\n",
      "--output=<Unicode>\r\n",
      "    overwrite base name use for output files.\r\n",
      "                can only be used when converting one notebook at a time.\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--NbConvertApp.output_base]\r\n",
      "--output-dir=<Unicode>\r\n",
      "    Directory to write output(s) to. Defaults\r\n",
      "                                  to output to the directory of each notebook. To recover\r\n",
      "                                  previous default behaviour (outputting to the current\r\n",
      "                                  working directory) use . as the flag value.\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--FilesWriter.build_directory]\r\n",
      "--reveal-prefix=<Unicode>\r\n",
      "    The URL prefix for reveal.js (version 3.x).\r\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy\r\n",
      "            of reveal.js.\r\n",
      "            For speaker notes to work, this must be a relative path to a local\r\n",
      "            copy of reveal.js: e.g., \"reveal.js\".\r\n",
      "            If a relative path is given, it must be a subdirectory of the\r\n",
      "            current directory (from which the server is run).\r\n",
      "            See the usage documentation\r\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\r\n",
      "            for more details.\r\n",
      "    Default: ''\r\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\r\n",
      "--nbformat=<Enum>\r\n",
      "    The nbformat version to write.\r\n",
      "            Use this to downgrade notebooks.\r\n",
      "    Choices: any of [1, 2, 3, 4]\r\n",
      "    Default: 4\r\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\r\n",
      "\r\n",
      "Examples\r\n",
      "--------\r\n",
      "\r\n",
      "    The simplest way to use nbconvert is\r\n",
      "\r\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\r\n",
      "\r\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\r\n",
      "\r\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\r\n",
      "\r\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\r\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\r\n",
      "            'classic'. You can specify the flavor of the format used.\r\n",
      "\r\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\r\n",
      "\r\n",
      "            You can also pipe the output to stdout, rather than a file\r\n",
      "\r\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\r\n",
      "\r\n",
      "            PDF is generated via latex\r\n",
      "\r\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\r\n",
      "\r\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\r\n",
      "\r\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\r\n",
      "\r\n",
      "            Multiple notebooks can be given at the command line in a couple of\r\n",
      "            different ways:\r\n",
      "\r\n",
      "            > jupyter nbconvert notebook*.ipynb\r\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\r\n",
      "\r\n",
      "            or you can specify the notebooks list in a config file, containing::\r\n",
      "\r\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\r\n",
      "\r\n",
      "            > jupyter nbconvert --config mycfg.py\r\n",
      "\r\n",
      "To see all available configurables, use `--help-all`.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert _week_5_numpy.ipynb --to html --template classic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
